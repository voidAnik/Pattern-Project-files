{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Mostahid_D.ipynb","provenance":[],"authorship_tag":"ABX9TyPkfxKyty0xTIa1tOKuaOt2"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"CRgkgaCwxDkg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605677650113,"user_tz":-360,"elapsed":38486,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"e5c3094b-f7ac-415f-ebd8-7829fafaa024"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EDDI2eyFxWOX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605677656284,"user_tz":-360,"elapsed":3048,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"d475b022-c92c-4fe9-a541-e8856486ab7e"},"source":["%cd /content/drive/My\\ Drive/Pattern\\ Lab/Datasets/Datasets\\ SL"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Pattern Lab/Datasets/Datasets SL\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xiZWQHe5xaAO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605677663673,"user_tz":-360,"elapsed":6426,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"928499ec-9372-4a1e-de64-55b824d13342"},"source":["path = \"/content/drive/My Drive/Pattern Lab/Datasets/Datasets SL\"\n","\n","# \"os.listdir()\" to get all the names of files inside the folder\n","import os\n","\n","Kmer_files = os.listdir(path+\"/Kmer\")\n","Kmer_files.pop(-1)\n","print(Kmer_files)\n","\n","binary_files = os.listdir(path+\"/binary\")\n","binary_files.pop(-1)\n","print(binary_files)\n","\n","CKSNAP_files = os.listdir(path+\"/CKSNAP\")\n","CKSNAP_files.pop(-1)\n","print(CKSNAP_files)\n","\n","\n","DAC_files = os.listdir(path+\"/DAC\")\n","DAC_files.pop(-1)\n","print(DAC_files)\n","\n","EIIP_files = os.listdir(path+\"/EIIP\")\n","EIIP_files.pop(-1)\n","print(EIIP_files)\n","\n","\n","ENAC_files = os.listdir(path+\"/ENAC\")\n","ENAC_files.pop(-1)\n","print(ENAC_files)\n","\n","\n","NCP_files = os.listdir(path+\"/NCP\")\n","NCP_files.pop(-1)\n","print(NCP_files)\n","\n","\n","PseEIIP_files = os.listdir(path+\"/PseEIIP\")\n","PseEIIP_files.pop(-1)\n","print(PseEIIP_files)\n","\n","\n","TAC_files = os.listdir(path+\"/TAC\")\n","TAC_files.pop(-1)\n","print(TAC_files)\n","\n","folder_Names = os.listdir(path)\n","print(folder_Names)\n","\n","folder_name_list = ['binary', 'CKSNAP', 'ENAC', 'DAC', 'EIIP', 'PseEIIP', 'NCP', 'Kmer', 'TAC']"],"execution_count":3,"outputs":[{"output_type":"stream","text":["['NA_test_special_Kmer1.csv', 'NA_test_special_Kmer2.csv', 'NA_test_special_Kmer4.csv', 'NA_test_special_Kmer3.csv', 'NA_test_special_Kmer5.csv', 'NC_train_special_Kmer1.csv', 'NC_train_special_Kmer2.csv', 'NC_train_special_Kmer3.csv', 'NC_train_special_Kmer4.csv', 'NC_train_special_Kmer5.csv', 'PA_test_special_Kmer2.csv', 'PA_test_special_Kmer1.csv', 'PA_test_special_Kmer3.csv', 'PA_test_special_Kmer5.csv', 'PA_test_special_Kmer4.csv', 'PC_train_special_Kmer1.csv', 'PC_train_special_Kmer2.csv', 'PC_train_special_Kmer3.csv', 'PC_train_special_Kmer4.csv', 'PC_train_special_Kmer5.csv', 'NA_train_special_Kmer2.csv', 'NA_train_special_Kmer1.csv', 'NA_train_special_Kmer3.csv', 'NA_train_special_Kmer4.csv', 'NA_train_special_Kmer5.csv', 'ND_test_special_Kmer2.csv', 'ND_test_special_Kmer1.csv', 'ND_test_special_Kmer3.csv', 'ND_test_special_Kmer4.csv', 'ND_test_special_Kmer5.csv', 'PA_train_special_Kmer2.csv', 'PA_train_special_Kmer1.csv', 'PA_train_special_Kmer3.csv', 'PA_train_special_Kmer4.csv', 'PA_train_special_Kmer5.csv', 'PD_test_special_Kmer2.csv', 'PD_test_special_Kmer1.csv', 'PD_test_special_Kmer3.csv', 'PD_test_special_Kmer4.csv', 'PD_test_special_Kmer5.csv', 'NC_test_special_Kmer1.csv', 'NC_test_special_Kmer2.csv', 'NC_test_special_Kmer3.csv', 'NC_test_special_Kmer4.csv', 'NC_test_special_Kmer5.csv', 'ND_train_special_Kmer1.csv', 'ND_train_special_Kmer2.csv', 'ND_train_special_Kmer3.csv', 'ND_train_special_Kmer4.csv', 'ND_train_special_Kmer5.csv', 'PC_test_special_Kmer2.csv', 'PC_test_special_Kmer1.csv', 'PC_test_special_Kmer4.csv', 'PC_test_special_Kmer3.csv', 'PC_test_special_Kmer5.csv', 'PD_train_special_Kmer2.csv', 'PD_train_special_Kmer1.csv', 'PD_train_special_Kmer3.csv', 'PD_train_special_Kmer4.csv', 'PD_train_special_Kmer5.csv']\n","['NA_test_special_binary.csv', 'NC_train_special_binary.csv', 'PA_test_special_binary.csv', 'PC_train_special_binary.csv', 'NA_train_special_binary.csv', 'ND_test_special_binary.csv', 'PA_train_special_binary.csv', 'PD_test_special_binary.csv', 'NC_test_special_binary.csv', 'ND_train_special_binary.csv', 'PC_test_special_binary.csv', 'PD_train_special_binary.csv']\n","['NA_test_special_CKSNAP1.csv', 'NA_test_special_CKSNAP3.csv', 'NA_test_special_CKSNAP5.csv', 'NA_test_special_CKSNAP7.csv', 'NA_test_special_CKSNAP9.csv', 'NC_train_special_CKSNAP1.csv', 'NC_train_special_CKSNAP5.csv', 'NC_train_special_CKSNAP3.csv', 'NC_train_special_CKSNAP9.csv', 'NC_train_special_CKSNAP7.csv', 'PA_test_special_CKSNAP1.csv', 'PA_test_special_CKSNAP3.csv', 'PA_test_special_CKSNAP5.csv', 'PA_test_special_CKSNAP9.csv', 'PA_test_special_CKSNAP7.csv', 'PC_train_special_CKSNAP1.csv', 'PC_train_special_CKSNAP3.csv', 'PC_train_special_CKSNAP5.csv', 'PC_train_special_CKSNAP9.csv', 'PC_train_special_CKSNAP7.csv', 'NA_train_special_CKSNAP3.csv', 'NA_train_special_CKSNAP1.csv', 'NA_train_special_CKSNAP7.csv', 'NA_train_special_CKSNAP5.csv', 'NA_train_special_CKSNAP9.csv', 'ND_test_special_CKSNAP1.csv', 'ND_test_special_CKSNAP3.csv', 'ND_test_special_CKSNAP5.csv', 'PA_train_special_CKSNAP1.csv', 'ND_test_special_CKSNAP9.csv', 'ND_test_special_CKSNAP7.csv', 'PA_train_special_CKSNAP5.csv', 'PA_train_special_CKSNAP3.csv', 'PA_train_special_CKSNAP9.csv', 'PA_train_special_CKSNAP7.csv', 'PD_test_special_CKSNAP1.csv', 'PD_test_special_CKSNAP5.csv', 'PD_test_special_CKSNAP3.csv', 'PD_test_special_CKSNAP7.csv', 'PD_test_special_CKSNAP9.csv', 'NC_test_special_CKSNAP1.csv', 'NC_test_special_CKSNAP5.csv', 'NC_test_special_CKSNAP3.csv', 'NC_test_special_CKSNAP7.csv', 'ND_train_special_CKSNAP1.csv', 'NC_test_special_CKSNAP9.csv', 'ND_train_special_CKSNAP3.csv', 'ND_train_special_CKSNAP5.csv', 'ND_train_special_CKSNAP7.csv', 'ND_train_special_CKSNAP9.csv', 'PC_test_special_CKSNAP3.csv', 'PC_test_special_CKSNAP5.csv', 'PC_test_special_CKSNAP1.csv', 'PD_train_special_CKSNAP1.csv', 'PC_test_special_CKSNAP9.csv', 'PC_test_special_CKSNAP7.csv', 'PD_train_special_CKSNAP5.csv', 'PD_train_special_CKSNAP3.csv', 'PD_train_special_CKSNAP9.csv', 'PD_train_special_CKSNAP7.csv']\n","['NA_test_special_DAC.csv', 'PA_test_special_DAC.csv', 'NC_train_special_DAC.csv', 'PC_train_special_DAC.csv', 'NA_train_special_DAC.csv', 'ND_test_special_DAC.csv', 'PA_train_special_DAC.csv', 'PD_test_special_DAC.csv', 'NC_test_special_DAC.csv', 'ND_train_special_DAC.csv', 'PC_test_special_DAC.csv', 'PD_train_special_DAC.csv']\n","['NA_test_special_EIIP.csv', 'NC_train_special_EIIP.csv', 'PC_train_special_EIIP.csv', 'PA_test_special_EIIP.csv', 'NA_train_special_EIIP.csv', 'ND_test_special_EIIP.csv', 'PA_train_special_EIIP.csv', 'PD_test_special_EIIP.csv', 'ND_train_special_EIIP.csv', 'NC_test_special_EIIP.csv', 'PC_test_special_EIIP.csv', 'PD_train_special_EIIP.csv']\n","['NA_test_special_ENAC5.csv', 'NA_test_special_ENAC10.csv', 'NC_train_special_ENAC5.csv', 'NC_train_special_ENAC10.csv', 'PA_test_special_ENAC5.csv', 'PA_test_special_ENAC10.csv', 'PC_train_special_ENAC5.csv', 'PC_train_special_ENAC10.csv', 'ND_test_special_ENAC10.csv', 'ND_test_special_ENAC5.csv', 'NA_train_special_ENAC5.csv', 'NA_train_special_ENAC10.csv', 'PA_train_special_ENAC5.csv', 'PA_train_special_ENAC10.csv', 'PD_test_special_ENAC5.csv', 'PD_test_special_ENAC10.csv', 'NC_test_special_ENAC5.csv', 'NC_test_special_ENAC10.csv', 'ND_train_special_ENAC5.csv', 'PC_test_special_ENAC5.csv', 'ND_train_special_ENAC10.csv', 'PC_test_special_ENAC10.csv', 'PD_train_special_ENAC5.csv', 'PD_train_special_ENAC10.csv']\n","['NA_test_special_NCP.csv', 'NC_train_special_NCP.csv', 'PA_test_special_NCP.csv', 'PC_train_special_NCP.csv', 'NA_train_special_NCP.csv', 'ND_test_special_NCP.csv', 'PA_train_special_NCP.csv', 'PD_test_special_NCP.csv', 'NC_test_special_NCP.csv', 'ND_train_special_NCP.csv', 'PC_test_special_NCP.csv', 'PD_train_special_NCP.csv']\n","['NA_test_special_PseEIIP.csv', 'NC_train_special_PseEIIP.csv', 'PA_test_special_PseEIIP.csv', 'NA_train_special_PseEIIP.csv', 'PC_train_special_PseEIIP.csv', 'ND_test_special_PseEIIP.csv', 'PA_train_special_PseEIIP.csv', 'NC_test_special_PseEIIP.csv', 'PD_test_special_PseEIIP.csv', 'ND_train_special_PseEIIP.csv', 'PD_train_special_PseEIIP.csv', 'PC_test_special_PseEIIP.csv']\n","['NA_test_special_TAC.csv', 'NC_train_special_TAC.csv', 'PA_test_special_TAC.csv', 'PC_train_special_TAC.csv', 'NA_train_special_TAC.csv', 'ND_test_special_TAC.csv', 'PA_train_special_TAC.csv', 'PD_test_special_TAC.csv', 'NC_test_special_TAC.csv', 'ND_train_special_TAC.csv', 'PC_test_special_TAC.csv', 'PD_train_special_TAC.csv']\n","['NC_train.fasta', 'PC_test.fasta', 'NC_test.fasta', 'PC_train.fasta', 'NA_train.fasta', 'PA_test.fasta', 'PA_train.fasta', 'NA_test.fasta', 'PD_test.fasta', 'PD_train.fasta', 'ND_test.fasta', 'ND_train.fasta', 'NC_test_special.txt', 'PD_test_special.txt', 'NA_train_special.txt', 'NA_test_special.txt', 'ND_train_special.txt', 'PC_test_special.txt', 'PA_test_special.txt', 'ND_test_special.txt', 'PC_train_special.txt', 'PA_train_special.txt', 'PD_train_special.txt', 'NC_train_special.txt', 'binary', 'CKSNAP', 'ENAC', 'DAC', 'EIIP', 'PseEIIP', 'NCP', 'Kmer', 'TAC', 'n_p_test_train', 'index_dictionary.pkl', 'f.txt', 'classified_datasets']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"92716qW3xe13","executionInfo":{"status":"ok","timestamp":1605677666573,"user_tz":-360,"elapsed":1911,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}}},"source":["# getting the all file names from the npy folder\n","import os\n","kmer_npy_files = os.listdir(path+\"/Kmer/npy\")\n","binary_npy_files = os.listdir(path+\"/binary/npy\")\n","cksnap_npy_files = os.listdir(path+\"/CKSNAP/npy\")\n","dac_npy_files = os.listdir(path+\"/DAC/npy\")\n","eiip_npy_files = os.listdir(path+\"/EIIP/npy\")\n","enac_npy_files = os.listdir(path+\"/ENAC/npy\")\n","ncp_npy_files = os.listdir(path+\"/NCP/npy\")\n","pseEiip_npy_files = os.listdir(path+\"/PseEIIP/npy\")\n","tac_npy_files = os.listdir(path+\"/TAC/npy\")"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"wh2FOO2yxgvo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605677720034,"user_tz":-360,"elapsed":50838,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"54d3f261-484c-4b05-8f33-319f844074cd"},"source":["import numpy as np\n","no_of_features = []\n","feature_name = ['binary', 'CKSNAP1', 'CKSNAP3', 'CKSNAP5', 'CKSNAP7', 'CKSNAP9', 'ENAC5', 'ENAC10', 'DAC', 'EIIP', 'PseEIIP', 'NCP', 'Kmer1', 'Kmer2', 'Kmer3', 'Kmer4', 'Kmer5', 'TAC']\n","for f_name in feature_name:\n","  if \"binary\" in f_name:\n","    n_path = path+\"/binary/npy/\"+binary_npy_files[0]\n","    dt = np.load(n_path, allow_pickle=True)\n","    no_of_features.append(dt.shape[1])\n","\n","  if \"CKSNAP1\" in f_name:\n","    n_path = path+\"/CKSNAP/npy/\"+cksnap_npy_files[0]\n","    dt = np.load(n_path, allow_pickle=True)\n","    no_of_features.append(dt.shape[1])\n","\n","  if \"CKSNAP3\" in f_name:\n","    n_path = path+\"/CKSNAP/npy/\"+cksnap_npy_files[0]\n","    dt = np.load(n_path, allow_pickle=True)\n","    no_of_features.append(dt.shape[1])\n","\n","  if \"CKSNAP5\" in f_name:\n","    n_path = path+\"/CKSNAP/npy/\"+cksnap_npy_files[0]\n","    dt = np.load(n_path, allow_pickle=True)\n","    no_of_features.append(dt.shape[1])\n","\n","  if \"CKSNAP7\" in f_name:\n","    n_path = path+\"/CKSNAP/npy/\"+cksnap_npy_files[0]\n","    dt = np.load(n_path, allow_pickle=True)\n","    no_of_features.append(dt.shape[1])\n","  \n","  if \"ENAC5\" in f_name:\n","    n_path = path+\"/ENAC/npy/\"+enac_npy_files[0]\n","    dt = np.load(n_path, allow_pickle=True)\n","    no_of_features.append(dt.shape[1])\n","\n","  if \"ENAC10\" in f_name:\n","    n_path = path+\"/ENAC/npy/\"+enac_npy_files[0]\n","    dt = np.load(n_path, allow_pickle=True)\n","    no_of_features.append(dt.shape[1])\n","\n","  if \"DAC\" in f_name:\n","    n_path = path+\"/DAC/npy/\"+dac_npy_files[0]\n","    dt = np.load(n_path, allow_pickle=True)\n","    no_of_features.append(dt.shape[1])\n","\n","  if \"EIIP\" in f_name:\n","    n_path = path+\"/EIIP/npy/\"+eiip_npy_files[0]\n","    dt = np.load(n_path, allow_pickle=True)\n","    no_of_features.append(dt.shape[1])\n","\n","  if \"PseEIIP\" in f_name:\n","      n_path = path+\"/PseEIIP/npy/\"+pseEiip_npy_files[0]\n","      dt = np.load(n_path, allow_pickle=True)\n","      no_of_features.append(dt.shape[1])\n","\n","  if \"NCP\" in f_name:\n","      n_path = path+\"/NCP/npy/\"+ncp_npy_files[0]\n","      dt = np.load(n_path, allow_pickle=True)\n","      no_of_features.append(dt.shape[1])\n","\n","  if \"Kmer1\" in f_name:\n","    for f in kmer_npy_files:\n","      if f_name in f:\n","        n_path = path+\"/Kmer/npy/\"+f\n","        dt = np.load(n_path, allow_pickle=True)\n","    no_of_features.append(dt.shape[1])\n","  if \"Kmer2\" in f_name:\n","    for f in kmer_npy_files:\n","      if f_name in f:\n","        n_path = path+\"/Kmer/npy/\"+f\n","        dt = np.load(n_path, allow_pickle=True)\n","    no_of_features.append(dt.shape[1])\n","\n","  if \"Kmer3\" in f_name:\n","    for f in kmer_npy_files:\n","      if f_name in f:\n","        n_path = path+\"/Kmer/npy/\"+f\n","        dt = np.load(n_path, allow_pickle=True)\n","    no_of_features.append(dt.shape[1])\n","  \n","  if \"Kmer4\" in f_name:\n","    for f in kmer_npy_files:\n","      if f_name in f:\n","        n_path = path+\"/Kmer/npy/\"+f\n","        dt = np.load(n_path, allow_pickle=True)\n","    no_of_features.append(dt.shape[1])\n","  \n","  if \"Kmer5\" in f_name:\n","    for f in kmer_npy_files:\n","      if f_name in f:\n","        n_path = path+\"/Kmer/npy/\"+f\n","        dt = np.load(n_path, allow_pickle=True)\n","    no_of_features.append(dt.shape[1])\n","\n","  if \"TAC\" in f_name:\n","    n_path = path+\"/TAC/npy/\"+tac_npy_files[0]\n","    dt = np.load(n_path, allow_pickle=True)\n","    no_of_features.append(dt.shape[1])\n","print(no_of_features)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 16, 64, 256, 1024, 1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nQi3Qdxyxkjv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605677724745,"user_tz":-360,"elapsed":1421,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"3f46ae43-b941-429b-d9aa-df5f3e32205d"},"source":["index_dictionary = {}\n","track = 0\n","for i,f_name in enumerate(feature_name):\n","  l = [track, track+no_of_features[i]-1]\n","  track = track + no_of_features[i]\n","  index_dictionary[f_name] = l\n","print(index_dictionary)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["{'binary': [0, 0], 'CKSNAP1': [1, 1], 'CKSNAP3': [2, 2], 'CKSNAP5': [3, 3], 'CKSNAP7': [4, 4], 'CKSNAP9': [5, 5], 'ENAC5': [6, 6], 'ENAC10': [7, 7], 'DAC': [8, 8], 'EIIP': [9, 9], 'PseEIIP': [10, 10], 'NCP': [11, 11], 'Kmer1': [12, 15], 'Kmer2': [16, 31], 'Kmer3': [32, 95], 'Kmer4': [96, 351], 'Kmer5': [352, 1375], 'TAC': [1376, 1376]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TPIHsE1SxmnP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605677758886,"user_tz":-360,"elapsed":31300,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"2ed5bc75-1198-4e99-aa83-c84ee7556935"},"source":["for f_name in feature_name:\n","  if \"binary\" in f_name:\n","    for f in binary_npy_files:\n","      if \"PD_\" in f and \"test\" in f:\n","        print(f)\n","        n_path = path+\"/binary/npy/\"+f\n","        pd_test = np.load(n_path, allow_pickle=True)\n","      if \"ND_\" in f and \"test\" in f:\n","        print(f)\n","        n_path = path+\"/binary/npy/\"+f\n","        nd_test = np.load(n_path, allow_pickle=True)\n","      if \"PD_\" in f and \"train\" in f:\n","        print(f)\n","        n_path = path+\"/binary/npy/\"+f\n","        pd_train = np.load(n_path, allow_pickle=True)\n","      if \"ND_\" in f and \"train\" in f:\n","        print(f)\n","        n_path = path+\"/binary/npy/\"+f\n","        nd_train = np.load(n_path, allow_pickle=True)\n","  if \"CKSNAP1\" in f_name:\n","    for f in cksnap_npy_files:\n","      if f_name in f:\n","        n_path = path+\"/CKSNAP/npy/\"+f\n","        if \"PD_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_test = np.concatenate((pd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_test.shape)\n","        if \"ND_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_test = np.concatenate((nd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_test.shape)\n","        if \"PD_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_train = np.concatenate((pd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_train.shape)\n","        if \"ND_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_train = np.concatenate((nd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_train.shape)\n","\n","  if \"CKSNAP3\" in f_name:\n","    for f in cksnap_npy_files:\n","      if f_name in f:\n","        n_path = path+\"/CKSNAP/npy/\"+f\n","        if \"PD_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_test = np.concatenate((pd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_test.shape)\n","        if \"ND_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_test = np.concatenate((nd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_test.shape)\n","        if \"PD_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_train = np.concatenate((pd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_train.shape)\n","        if \"ND_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_train = np.concatenate((nd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_train.shape)\n","\n","  if \"CKSNAP5\" in f_name:\n","    for f in cksnap_npy_files:\n","      if f_name in f:\n","        n_path = path+\"/CKSNAP/npy/\"+f\n","        if \"PD_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_test = np.concatenate((pd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_test.shape)\n","        if \"ND_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_test = np.concatenate((nd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_test.shape)\n","        if \"PD_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_train = np.concatenate((pd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_train.shape)\n","        if \"ND_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_train = np.concatenate((nd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_train.shape)\n","\n","  if \"CKSNAP7\" in f_name:\n","    for f in cksnap_npy_files:\n","      if f_name in f:\n","        n_path = path+\"/CKSNAP/npy/\"+f\n","        if \"PD_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_test = np.concatenate((pd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_test.shape)\n","        if \"ND_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_test = np.concatenate((nd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_test.shape)\n","        if \"PD_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_train = np.concatenate((pd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_train.shape)\n","        if \"ND_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_train = np.concatenate((nd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_train.shape)\n","\n","  if \"CKSNAP9\" in f_name:\n","    for f in cksnap_npy_files:\n","      if f_name in f:\n","        n_path = path+\"/CKSNAP/npy/\"+f\n","        if \"PD_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_test = np.concatenate((pd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_test.shape)\n","        if \"ND_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_test = np.concatenate((nd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_test.shape)\n","        if \"PD_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_train = np.concatenate((pd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_train.shape)\n","        if \"ND_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_train = np.concatenate((nd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_train.shape)\n","  \n","  if \"ENAC5\" in f_name:\n","    for f in enac_npy_files:\n","      if f_name in f:\n","        n_path = path+\"/ENAC/npy/\"+f\n","        if \"PD_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_test = np.concatenate((pd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_test.shape)\n","        if \"ND_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_test = np.concatenate((nd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_test.shape)\n","        if \"PD_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_train = np.concatenate((pd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_train.shape)\n","        if \"ND_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_train = np.concatenate((nd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_train.shape)\n","  \n","  if \"ENAC10\" in f_name:\n","    for f in enac_npy_files:\n","      if f_name in f:\n","        n_path = path+\"/ENAC/npy/\"+f\n","        if \"PD_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_test = np.concatenate((pd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_test.shape)\n","        if \"ND_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_test = np.concatenate((nd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_test.shape)\n","        if \"PD_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_train = np.concatenate((pd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_train.shape)\n","        if \"ND_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_train = np.concatenate((nd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_train.shape)\n","  \n","  if \"DAC\" in f_name:\n","    for f in dac_npy_files:\n","      if f_name in f:\n","        n_path = path+\"/DAC/npy/\"+f\n","        if \"PD_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_test = np.concatenate((pd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_test.shape)\n","        if \"ND_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_test = np.concatenate((nd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_test.shape)\n","        if \"PD_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_train = np.concatenate((pd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_train.shape)\n","        if \"ND_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_train = np.concatenate((nd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_train.shape)\n"," \n","  if \"EIIP\" in f_name:\n","    for f in eiip_npy_files:\n","      if f_name in f:\n","        n_path = path+\"/EIIP/npy/\"+f\n","        if \"PD_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_test = np.concatenate((pd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_test.shape)\n","        if \"ND_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_test = np.concatenate((nd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_test.shape)\n","        if \"PD_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_train = np.concatenate((pd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_train.shape)\n","        if \"ND_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_train = np.concatenate((nd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_train.shape)\n"," \n","  if \"PseEIIP\" in f_name:\n","      for f in pseEiip_npy_files:\n","        if f_name in f:\n","          n_path = path+\"/PseEIIP/npy/\"+f\n","          if \"PD_\" in f and \"test\" in f:\n","            print(f)\n","            dt = np.load(n_path, allow_pickle=True)\n","            pd_test = np.concatenate((pd_test, dt), axis=1)\n","            print(dt.shape[1])\n","            print(pd_test.shape)\n","          if \"ND_\" in f and \"test\" in f:\n","            print(f)\n","            dt = np.load(n_path, allow_pickle=True)\n","            nd_test = np.concatenate((nd_test, dt), axis=1)\n","            print(dt.shape[1])\n","            print(nd_test.shape)\n","          if \"PD_\" in f and \"train\" in f:\n","            print(f)\n","            dt = np.load(n_path, allow_pickle=True)\n","            pd_train = np.concatenate((pd_train, dt), axis=1)\n","            print(dt.shape[1])\n","            print(pd_train.shape)\n","          if \"ND_\" in f and \"train\" in f:\n","            print(f)\n","            dt = np.load(n_path, allow_pickle=True)\n","            nd_train = np.concatenate((nd_train, dt), axis=1)\n","            print(dt.shape[1])\n","            print(nd_train.shape)\n","          \n","    \n","  if \"NCP\" in f_name:\n","    for f in ncp_npy_files:\n","      if f_name in f:\n","        n_path = path+\"/NCP/npy/\"+f\n","        if \"PD_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_test = np.concatenate((pd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_test.shape)\n","        if \"ND_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_test = np.concatenate((nd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_test.shape)\n","        if \"PD_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_train = np.concatenate((pd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_train.shape)\n","        if \"ND_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_train = np.concatenate((nd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_train.shape)\n","  \n","  if \"Kmer1\" in f_name:\n","    for f in kmer_npy_files:\n","      if f_name in f:\n","        n_path = path+\"/Kmer/npy/\"+f\n","        if \"PD_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_test = np.concatenate((pd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_test.shape)\n","        if \"ND_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_test = np.concatenate((nd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_test.shape)\n","        if \"PD_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_train = np.concatenate((pd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_train.shape)\n","        if \"ND_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_train = np.concatenate((nd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_train.shape)\n","  \n","  if \"Kmer2\" in f_name:\n","    for f in kmer_npy_files:\n","      if f_name in f:\n","        n_path = path+\"/Kmer/npy/\"+f\n","        if \"PD_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_test = np.concatenate((pd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_test.shape)\n","        if \"ND_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_test = np.concatenate((nd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_test.shape)\n","        if \"PD_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_train = np.concatenate((pd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_train.shape)\n","        if \"ND_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_train = np.concatenate((nd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_train.shape)\n","  \n","  if \"Kmer3\" in f_name:\n","    for f in kmer_npy_files:\n","      if f_name in f:\n","        n_path = path+\"/Kmer/npy/\"+f\n","        if \"PD_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_test = np.concatenate((pd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_test.shape)\n","        if \"ND_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_test = np.concatenate((nd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_test.shape)\n","        if \"PD_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_train = np.concatenate((pd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_train.shape)\n","        if \"ND_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_train = np.concatenate((nd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_train.shape)\n","  \n","  if \"Kmer4\" in f_name:\n","    for f in kmer_npy_files:\n","      if f_name in f:\n","        n_path = path+\"/Kmer/npy/\"+f\n","        if \"PD_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_test = np.concatenate((pd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_test.shape)\n","        if \"ND_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_test = np.concatenate((nd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_test.shape)\n","        if \"PD_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_train = np.concatenate((pd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_train.shape)\n","        if \"ND_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_train = np.concatenate((nd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_train.shape)\n","  \n","  if \"Kmer5\" in f_name:\n","    for f in kmer_npy_files:\n","      if f_name in f:\n","        n_path = path+\"/Kmer/npy/\"+f\n","        if \"PD_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_test = np.concatenate((pd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_test.shape)\n","        if \"ND_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_test = np.concatenate((nd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_test.shape)\n","        if \"PD_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_train = np.concatenate((pd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_train.shape)\n","        if \"ND_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_train = np.concatenate((nd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_train.shape)\n","  \n","  if \"TAC\" in f_name:\n","    for f in tac_npy_files:\n","      if f_name in f:\n","        n_path = path+\"/TAC/npy/\"+f\n","        if \"PD_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_test = np.concatenate((pd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_test.shape)\n","        if \"ND_\" in f and \"test\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_test = np.concatenate((nd_test, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_test.shape)\n","        if \"PD_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          pd_train = np.concatenate((pd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(pd_train.shape)\n","        if \"ND_\" in f and \"train\" in f:\n","          print(f)\n","          dt = np.load(n_path, allow_pickle=True)\n","          nd_train = np.concatenate((nd_train, dt), axis=1)\n","          print(dt.shape[1])\n","          print(nd_train.shape)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["ND_test_special_binary.npy\n","PD_test_special_binary.npy\n","ND_train_special_binary.npy\n","PD_train_special_binary.npy\n","ND_test_special_CKSNAP1.npy\n","1\n","(117, 2)\n","PD_test_special_CKSNAP1.npy\n","1\n","(117, 2)\n","ND_train_special_CKSNAP1.npy\n","1\n","(1650, 2)\n","PD_train_special_CKSNAP1.npy\n","1\n","(1650, 2)\n","ND_test_special_CKSNAP3.npy\n","1\n","(117, 3)\n","PD_test_special_CKSNAP3.npy\n","1\n","(117, 3)\n","ND_train_special_CKSNAP3.npy\n","1\n","(1650, 3)\n","PD_train_special_CKSNAP3.npy\n","1\n","(1650, 3)\n","ND_test_special_CKSNAP5.npy\n","1\n","(117, 4)\n","PD_test_special_CKSNAP5.npy\n","1\n","(117, 4)\n","ND_train_special_CKSNAP5.npy\n","1\n","(1650, 4)\n","PD_train_special_CKSNAP5.npy\n","1\n","(1650, 4)\n","ND_test_special_CKSNAP7.npy\n","1\n","(117, 5)\n","PD_test_special_CKSNAP7.npy\n","1\n","(117, 5)\n","ND_train_special_CKSNAP7.npy\n","1\n","(1650, 5)\n","PD_train_special_CKSNAP7.npy\n","1\n","(1650, 5)\n","ND_test_special_CKSNAP9.npy\n","1\n","(117, 6)\n","PD_test_special_CKSNAP9.npy\n","1\n","(117, 6)\n","ND_train_special_CKSNAP9.npy\n","1\n","(1650, 6)\n","PD_train_special_CKSNAP9.npy\n","1\n","(1650, 6)\n","ND_test_special_ENAC5.npy\n","1\n","(117, 7)\n","PD_test_special_ENAC5.npy\n","1\n","(117, 7)\n","ND_train_special_ENAC5.npy\n","1\n","(1650, 7)\n","PD_train_special_ENAC5.npy\n","1\n","(1650, 7)\n","ND_test_special_ENAC10.npy\n","1\n","(117, 8)\n","PD_test_special_ENAC10.npy\n","1\n","(117, 8)\n","ND_train_special_ENAC10.npy\n","1\n","(1650, 8)\n","PD_train_special_ENAC10.npy\n","1\n","(1650, 8)\n","ND_test_special_DAC.npy\n","1\n","(117, 9)\n","PD_test_special_DAC.npy\n","1\n","(117, 9)\n","PD_train_special_DAC.npy\n","1\n","(1650, 9)\n","ND_train_special_DAC.npy\n","1\n","(1650, 9)\n","ND_test_special_EIIP.npy\n","1\n","(117, 10)\n","PD_test_special_EIIP.npy\n","1\n","(117, 10)\n","ND_train_special_EIIP.npy\n","1\n","(1650, 10)\n","PD_train_special_EIIP.npy\n","1\n","(1650, 10)\n","ND_test_special_PseEIIP.npy\n","1\n","(117, 11)\n","PD_test_special_PseEIIP.npy\n","1\n","(117, 11)\n","ND_train_special_PseEIIP.npy\n","1\n","(1650, 11)\n","PD_train_special_PseEIIP.npy\n","1\n","(1650, 11)\n","ND_test_special_NCP.npy\n","1\n","(117, 12)\n","PD_test_special_NCP.npy\n","1\n","(117, 12)\n","ND_train_special_NCP.npy\n","1\n","(1650, 12)\n","PD_train_special_NCP.npy\n","1\n","(1650, 12)\n","ND_test_special_Kmer1.npy\n","4\n","(117, 16)\n","PD_test_special_Kmer1.npy\n","4\n","(117, 16)\n","ND_train_special_Kmer1.npy\n","4\n","(1650, 16)\n","PD_train_special_Kmer1.npy\n","4\n","(1650, 16)\n","ND_test_special_Kmer2.npy\n","16\n","(117, 32)\n","PD_test_special_Kmer2.npy\n","16\n","(117, 32)\n","ND_train_special_Kmer2.npy\n","16\n","(1650, 32)\n","PD_train_special_Kmer2.npy\n","16\n","(1650, 32)\n","ND_test_special_Kmer3.npy\n","64\n","(117, 96)\n","PD_test_special_Kmer3.npy\n","64\n","(117, 96)\n","ND_train_special_Kmer3.npy\n","64\n","(1650, 96)\n","PD_train_special_Kmer3.npy\n","64\n","(1650, 96)\n","ND_test_special_Kmer4.npy\n","256\n","(117, 352)\n","PD_test_special_Kmer4.npy\n","256\n","(117, 352)\n","ND_train_special_Kmer4.npy\n","256\n","(1650, 352)\n","PD_train_special_Kmer4.npy\n","256\n","(1650, 352)\n","ND_test_special_Kmer5.npy\n","1024\n","(117, 1376)\n","PD_test_special_Kmer5.npy\n","1024\n","(117, 1376)\n","ND_train_special_Kmer5.npy\n","1024\n","(1650, 1376)\n","PD_train_special_Kmer5.npy\n","1024\n","(1650, 1376)\n","ND_test_special_TAC.npy\n","1\n","(117, 1377)\n","PD_test_special_TAC.npy\n","1\n","(117, 1377)\n","ND_train_special_TAC.npy\n","1\n","(1650, 1377)\n","PD_train_special_TAC.npy\n","1\n","(1650, 1377)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5CYFWNTNx8uv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605677770281,"user_tz":-360,"elapsed":1686,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"cc981395-9336-4374-adf0-73f55c73aa18"},"source":["import pickle\n","\n","# saving things\n","print(pd_test.shape)\n","print(pd_train.shape)\n","print(nd_test.shape)\n","print(nd_train.shape)\n","np.save(path+\"/n_p_test_train/\"+\"PD_test\",pd_test)\n","np.save(path+\"/n_p_test_train/\"+\"PD_train\",pd_train)\n","np.save(path+\"/n_p_test_train/\"+\"ND_test\",nd_test)\n","np.save(path+\"/n_p_test_train/\"+\"ND_train\",nd_train)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["(117, 1377)\n","(1650, 1377)\n","(117, 1377)\n","(1650, 1377)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_ociSkjjyEgP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605678086521,"user_tz":-360,"elapsed":2473,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"0fa4dadb-1504-4302-ea31-f8537d488c4c"},"source":["import pandas as pd\n","\n","n_p_test_train = os.listdir(path+\"/n_p_test_train\")\n","yd_train_list = []\n","yd_test_list = []\n","for f in n_p_test_train:\n","  if \"ND\" in f and \"train\" in f:\n","    nd_train_x = np.load(path+\"/n_p_test_train/\"+f, allow_pickle=True)\n","    print(nd_train_x.shape)\n","    for i in range(nd_train_x.shape[0]):\n","      yd_train_list.append(\"0\\n\")\n","  if \"PD\" in f and \"train\" in f:\n","    pd_train_x = np.load(path+\"/n_p_test_train/\"+f, allow_pickle=True)\n","    print(pd_train_x.shape)\n","    for i in range(pd_train_x.shape[0]):\n","      yd_train_list.append(\"1\\n\")\n","  if \"PD\" in f and \"test\" in f:\n","    pd_test_x = np.load(path+\"/n_p_test_train/\"+f, allow_pickle=True)\n","    print(pd_test_x.shape)\n","    for i in range(pd_test_x.shape[0]):\n","      yd_test_list.append(\"1\\n\")\n","  if \"ND\" in f and \"test\" in f:\n","    nd_test_x = np.load(path+\"/n_p_test_train/\"+f, allow_pickle=True)\n","    print(nd_test_x.shape)\n","    for i in range(nd_test_x.shape[0]):\n","      yd_test_list.append(\"0\\n\")\n","\n","# saving yd_train\n","yd_train = open(path+\"/classified_datasets/txt/yd_train.txt\", \"w\")\n","yd_train.writelines(yd_train_list)\n","yd_train.close()\n","yd_train_txt = pd.read_csv(path+\"/classified_datasets/txt/yd_train.txt\")\n","yd_train_txt = yd_train_txt.to_numpy()\n","np.save(path+\"/classified_datasets/yd_train.npy\", yd_train_txt)\n","\n","# saving yd_test\n","yd_test = open(path+\"/classified_datasets/txt/yd_test.txt\", \"w\")\n","yd_test.writelines(yd_test_list)\n","yd_test.close()\n","yd_test_txt = pd.read_csv(path+\"/classified_datasets/txt/yd_test.txt\")\n","yd_test_txt = yd_test_txt.to_numpy()\n","np.save(path+\"/classified_datasets/yd_test.npy\", yd_test_txt)\n","\n","# saving xd_train\n","xd_train = np.concatenate((pd_train_x, nd_train_x), axis=0)\n","print(xd_train.shape)\n","np.save(path+\"/classified_datasets/xd_train.npy\", xd_train)\n","\n","# saving xd_test\n","xd_test = np.concatenate((pd_test_x, nd_test_x), axis=0)\n","print(xd_test.shape)\n","np.save(path+\"/classified_datasets/xd_test.npy\", xd_test)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["(117, 1377)\n","(1650, 1377)\n","(117, 1377)\n","(1650, 1377)\n","(3300, 1377)\n","(234, 1377)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"87bJMTwN3Y9n"},"source":[""],"execution_count":null,"outputs":[]}]}