{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment_03_nafiz.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMCCCqyYfldwNmC06QOhGRm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"03t-4pXDhImc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608704250207,"user_tz":-360,"elapsed":2067,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"acebe17c-cbd4-4fc6-9aa6-ec6488b5cd74"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BUnd6gIQ44i8","executionInfo":{"status":"ok","timestamp":1608704250208,"user_tz":-360,"elapsed":2054,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"193e9741-3794-4481-b878-0837cf3f4b7f"},"source":["%cd /content/drive/My\\ Drive/Pattern\\ Lab/Datasets/Datasets\\ SL/classified_datasets\n","path = \"/content/drive/My\\ Drive/Pattern\\ Lab/Datasets/Datasets\\ SL/classified_datasets\""],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Pattern Lab/Datasets/Datasets SL/classified_datasets\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Atl0dezYkVH3","executionInfo":{"status":"ok","timestamp":1608704250209,"user_tz":-360,"elapsed":2047,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}}},"source":["# all library imports here\n","import pandas as pd\n","import numpy as np\n","import os\n","import pickle"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"_VSxpSQVkYhE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608704250210,"user_tz":-360,"elapsed":2041,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"1503865d-5d1f-44ef-b4be-65b4355be164"},"source":["a_file = open(\"index_dictionary.pkl\", \"rb\")\n","index_dictionary = pickle.load(a_file)\n","print(index_dictionary)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["{'binary': [0, 163], 'CKSNAP1': [164, 195], 'CKSNAP3': [196, 259], 'CKSNAP5': [260, 355], 'CKSNAP7': [356, 483], 'CKSNAP9': [484, 643], 'ENAC5': [644, 791], 'ENAC10': [792, 939], 'DAC': [940, 981], '_EIIP': [982, 1022], 'PseEIIP': [1023, 1086], 'NCP': [1087, 1209], 'Kmer1': [1210, 1213], 'Kmer2': [1214, 1229], 'Kmer3': [1230, 1293], 'Kmer4': [1294, 1549], 'Kmer5': [1550, 2573], 'TAC': [2574, 2587]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLGiaJ2w0930","executionInfo":{"status":"ok","timestamp":1608704250211,"user_tz":-360,"elapsed":2031,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"11eac528-f75c-4830-be8c-536d1898feff"},"source":["import random\n","\n","def getList(dict): \n","    return list(dict.keys()) \n","\n","       \n","keyList = getList(index_dictionary)\n","print(type(keyList))\n","\n","random_feature = [] \n","\n","for i in range(4):\n","  random_feature.append(random.sample(keyList, 5))\n","\n","print(random_feature )"],"execution_count":5,"outputs":[{"output_type":"stream","text":["<class 'list'>\n","[['Kmer4', 'ENAC10', 'DAC', '_EIIP', 'Kmer5'], ['binary', 'CKSNAP9', 'Kmer4', 'TAC', 'Kmer3'], ['PseEIIP', 'Kmer4', 'TAC', 'binary', 'Kmer3'], ['CKSNAP7', 'Kmer5', 'TAC', 'NCP', 'binary']]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l8cP5DzQyAEQ","executionInfo":{"status":"ok","timestamp":1608704250593,"user_tz":-360,"elapsed":2405,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"667014ca-7fd4-4a5d-93cf-65aa5750237e"},"source":["Xa_train, Xa_test, ya_train, ya_test = np.load(\"xa_train.npy\"), np.load(\"xa_test.npy\"), np.load(\"ya_train.npy\"), np.load(\"ya_test.npy\")\n","Xc_train, Xc_test, yc_train, yc_test = np.load(\"xc_train.npy\"), np.load(\"xc_test.npy\"), np.load(\"yc_train.npy\"), np.load(\"yc_test.npy\")\n","Xd_train, Xd_test, yd_train, yd_test = np.load(\"xd_train.npy\"), np.load(\"xd_test.npy\"), np.load(\"yd_train.npy\"), np.load(\"yd_test.npy\")\n","print(Xa_train.shape, Xa_test.shape, ya_train.shape, ya_test.shape)\n","print(Xc_train.shape, Xc_test.shape, yc_train.shape, yc_test.shape)\n","print(Xd_train.shape, Xd_test.shape, yd_train.shape, yd_test.shape)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["(3690, 2568) (262, 2568) (3690, 1) (262, 1)\n","(2898, 2568) (206, 2568) (2898, 1) (206, 1)\n","(3300, 2568) (234, 2568) (3300, 1) (234, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pbK2uOl3vwqV"},"source":["#pa_test = np.concatenate((pa_test, dt), axis=1)\n","for feature_groups in random_feature:\n","  #feature_groups = random_feature[0] \n","  no_of_features = 0\n","  for i in feature_groups:\n","    no_of_features = no_of_features + index_dictionary[i][1]-index_dictionary[i][0]+1\n","  print(no_of_features)\n","\n","  xa_train_n, xa_test_n, ya_train_n, ya_test_n = np.zeros((Xa_train.shape[0],no_of_features)), np.zeros((Xa_test.shape[0],no_of_features)), ya_train, ya_test\n","  starting_index = 0\n","  for i in feature_groups:\n","    ending_index = starting_index + index_dictionary[i][1]-index_dictionary[i][0]\n","    print(starting_index,ending_index)\n","    print(index_dictionary[i][1]+1, index_dictionary[i][0])\n","    xa_train_n[:,starting_index:ending_index+1] = Xa_train[:,index_dictionary[i][0]:index_dictionary[i][1]+1]\n","    xa_test_n[:,starting_index:ending_index+1] = Xa_test[:,index_dictionary[i][0]:index_dictionary[i][1]+1]\n","    starting_index = ending_index+1\n","  print(starting_index)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u4W6tlWbr0aB","executionInfo":{"status":"ok","timestamp":1608704250594,"user_tz":-360,"elapsed":2397,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"91004d33-9f43-4a6f-f9f4-37d21c929406"},"source":["#pa_test = np.concatenate((pa_test, dt), axis=1)\n","xc_trains = []\n","xc_tests = []\n","for i, feature_groups in enumerate(random_feature):\n","  #no_of_features = 0\n","  #for j in feature_groups:\n","   # no_of_features = no_of_features + index_dictionary[j][1]-index_dictionary[j][0]+1\n","  #print(no_of_features)\n","  xc_train_temp = np.concatenate([Xc_train[ : ,  index_dictionary[x][0] : index_dictionary[x][1]+1] for x in feature_groups], axis = 1)\n","  xc_trains.append(xc_train_temp)\n","  xc_test_temp = np.concatenate([Xc_test[ : ,  index_dictionary[x][0] : index_dictionary[x][1]+1] for x in feature_groups], axis = 1)\n","  xc_tests.append(xc_test_temp)\n","  print(xc_trains[i].shape)\n","  print(xc_tests[i].shape)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["(2898, 1505)\n","(206, 1505)\n","(2898, 644)\n","(206, 644)\n","(2898, 548)\n","(206, 548)\n","(2898, 1433)\n","(206, 1433)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h1Se67yDyx-p","executionInfo":{"status":"ok","timestamp":1608704250963,"user_tz":-360,"elapsed":2759,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}}},"source":["from sklearn.model_selection import train_test_split\n","from sklearn import svm\n","import numpy as np\n","import pickle\n","import random\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import cross_val_score, cross_val_predict\n","from sklearn.metrics import confusion_matrix, matthews_corrcoef\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","\n","from tabulate import tabulate"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"g9LXghVbYMht","executionInfo":{"status":"ok","timestamp":1608704250964,"user_tz":-360,"elapsed":2755,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}}},"source":["def avg(avg_list):\n","  return sum(avg_list)/len(avg_list)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"ttNexTG90g03","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608704584666,"user_tz":-360,"elapsed":336449,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"2dcaf1a9-2102-4814-dd90-a52948eabb94"},"source":["# for SVM\n","cv = StratifiedKFold( n_splits=5, shuffle=True)\n","svc = SVC() # Support vector classifier(SVC)\n","\n","train_accuracy=[]\n","train_specificity = []\n","train_sensitivity = []\n","train_mcc = []\n","test_accuracy=[]\n","test_specificity = []\n","test_sensitivity = []\n","test_mcc = []\n","ind_accuracy=[]\n","ind_specificity = []\n","ind_sensitivity = []\n","ind_mcc = []\n","\n","\n","svc_raws = []\n","headers = [ \"Random-Set\", \"Train-Accuracy\", \"Test-Accuracy\", \"Ind-Accuracy\",\"Train-Specificity\", \"Test-Specificity\", \"Ind-Specificity\", \"Train-Sensitivity\", \"Test-Sensitivity\", \"Ind-Sensitivity\", \"Train-MCC\", \"Test-MCC\", \"Ind-MCC\"]\n","\n","for i, x in enumerate(xc_trains):\n","  for train_index, test_index in cv.split(x, yc_train):\n","      x_train, x_test = x[train_index], x[test_index]\n","      y_train, y_test = yc_train[train_index], yc_train[test_index]\n","      svc.fit(x_train, y_train.ravel())\n","      test_pred = svc.predict(x_test)\n","      train_pred = svc.predict(x_train)\n","      ind_pred = svc.predict(xc_tests[i]) # prediction of independent test dataset\n","\n","      ## Accuracy\n","      train_accuracy.append(accuracy_score(y_train, train_pred))\n","      test_accuracy.append(accuracy_score(y_test, test_pred))\n","      ind_accuracy.append(accuracy_score(yc_test, ind_pred))\n","\n","      ## confusion metrics\n","      tn, fp, fn, tp = confusion_matrix(y_train, train_pred).ravel()\n","      train_specificity.append(tn / (tn + fp)) # Specificity\n","      train_sensitivity.append(tp / (tp + fp)) # Sensitivity\n","\n","      tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n","      test_specificity.append(tn / (tn + fp))\n","      test_sensitivity.append(tp / (tp + fp))\n","\n","      tn, fp, fn, tp = confusion_matrix(yc_test, ind_pred).ravel()\n","      ind_specificity.append(tn / (tn + fp))\n","      ind_sensitivity.append(tp / (tp + fn))\n","\n","      ## MCC\n","      train_mcc.append(matthews_corrcoef(y_train, train_pred))\n","      test_mcc.append(matthews_corrcoef(y_test, test_pred))\n","      ind_mcc.append(matthews_corrcoef(yc_test, ind_pred))\n","\n","  print(\"Random set -\", i+1)\n","  print(\"Train-Accuracy = \", avg(train_accuracy))\n","  print(\"Test-Accuracy = \",avg(test_accuracy))\n","  print(\"Train-Specificity = \", avg(train_specificity))\n","  print(\"Test-Specificity = \", avg(test_specificity))\n","  print(\"Train-Sensitivity = \", avg(train_sensitivity))\n","  print(\"Test-Sensitivity = \", avg(test_sensitivity))\n","  print(\"Train-MCC = \", avg(train_mcc))\n","  print(\"Test-MCC = \", avg(test_mcc))\n","  print(\"\\n\\n\")\n","  svc_raws.append([ \"Set0\"+str(i+1), avg(train_accuracy), avg(test_accuracy), avg(ind_accuracy), avg(train_specificity), avg(test_specificity), avg(ind_specificity), \n","                 avg(train_sensitivity), avg(test_sensitivity),  avg(ind_sensitivity), avg(train_mcc), avg(test_mcc),  avg(ind_mcc)])\n","\n","print(\" For SVM Classifier:\\n\")\n","table = tabulate(svc_raws, headers, tablefmt='simple')\n","print(table)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Random set - 1\n","Train-Accuracy =  0.7964122392167938\n","Test-Accuracy =  0.7132517420046453\n","Train-Specificity =  0.8083164737734669\n","Test-Specificity =  0.7281088175635365\n","Train-Sensitivity =  0.8036491690220273\n","Test-Sensitivity =  0.7208753964424931\n","Train-MCC =  0.5929990274746626\n","Test-MCC =  0.4273600760988794\n","\n","\n","\n","Random set - 2\n","Train-Accuracy =  0.8631389195530341\n","Test-Accuracy =  0.7468917872669882\n","Train-Specificity =  0.8718084853173067\n","Test-Specificity =  0.7605249970170623\n","Train-Sensitivity =  0.8691204199379949\n","Test-Sensitivity =  0.7545380792524167\n","Train-MCC =  0.7263918089373932\n","Test-MCC =  0.49455471115168254\n","\n","\n","\n","Random set - 3\n","Train-Accuracy =  0.8802338362749211\n","Test-Accuracy =  0.7532751672522978\n","Train-Specificity =  0.8882563744012375\n","Test-Specificity =  0.7685765421787375\n","Train-Sensitivity =  0.886106698532415\n","Test-Sensitivity =  0.7619554657118883\n","Train-MCC =  0.7605731812354677\n","Test-MCC =  0.5073017292389819\n","\n","\n","\n","Random set - 4\n","Train-Accuracy =  0.8852659372010712\n","Test-Accuracy =  0.7575906735751293\n","Train-Specificity =  0.893978496623129\n","Test-Specificity =  0.7720850733802649\n","Train-Sensitivity =  0.8918889051761539\n","Test-Sensitivity =  0.7657481379700309\n","Train-MCC =  0.7706670927996482\n","Test-MCC =  0.5158553467157514\n","\n","\n","\n"," For SVM Classifier:\n","\n","Random-Set      Train-Accuracy    Test-Accuracy    Ind-Accuracy    Train-Specificity    Test-Specificity    Ind-Accuracy    Train-Sensitivity    Test-Sensitivity    Ind-Accuracy    Train-MCC    Test-MCC    Ind-MCC\n","------------  ----------------  ---------------  --------------  -------------------  ------------------  --------------  -------------------  ------------------  --------------  -----------  ----------  ---------\n","Set01                 0.796412         0.713252        0.320388             0.808316            0.728109        0.316505             0.803649            0.720875        0.324272     0.592999    0.42736   -0.359362\n","Set02                 0.863139         0.746892        0.286408             0.871808            0.760525        0.299029             0.86912             0.754538        0.273786     0.726392    0.494555  -0.4277\n","Set03                 0.880234         0.753275        0.276375             0.888256            0.768577        0.288026             0.886107            0.761955        0.264725     0.760573    0.507302  -0.44764\n","Set04                 0.885266         0.757591        0.272573             0.893978            0.772085        0.288835             0.891889            0.765748        0.256311     0.770667    0.515855  -0.455413\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fsANFC7_LJkJ","executionInfo":{"status":"ok","timestamp":1608704596494,"user_tz":-360,"elapsed":348268,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"2cea1a7d-2ffc-44dc-89bf-cab878e52811"},"source":["###  for LogisticRegression\n","\n","logisticRegression = LogisticRegression(max_iter=500)\n","#cv = StratifiedKFold( n_splits=5, shuffle=True)\n","\n","train_accuracy=[]\n","train_specificity = []\n","train_sensitivity = []\n","train_mcc = []\n","test_accuracy=[]\n","test_specificity = []\n","test_sensitivity = []\n","test_mcc = []\n","\n","lg_raws = []\n","\n","for i, x in enumerate(xc_trains):\n","  for train_index, test_index in cv.split(x, yc_train):\n","      x_train, x_test = x[train_index], x[test_index]\n","      y_train, y_test = yc_train[train_index], yc_train[test_index]\n","      logisticRegression.fit(x_train, y_train.ravel())\n","      test_pred = logisticRegression.predict(x_test)\n","      train_pred = logisticRegression.predict(x_train)\n","      ind_pred = logisticRegression.predict(xc_tests[i]) # prediction of independent test dataset\n","\n","      ## Accuracy\n","      train_accuracy.append(accuracy_score(y_train, train_pred))\n","      test_accuracy.append(accuracy_score(y_test, test_pred))\n","      ind_accuracy.append(accuracy_score(yc_test, ind_pred))\n","\n","      ## confusion metrics\n","      tn, fp, fn, tp = confusion_matrix(y_train, train_pred).ravel()\n","      train_specificity.append(tn / (tn + fp)) # Specificity\n","      train_sensitivity.append(tp / (tp + fp)) # Sensitivity\n","\n","      tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n","      test_specificity.append(tn / (tn + fp))\n","      test_sensitivity.append(tp / (tp + fp))\n","\n","      tn, fp, fn, tp = confusion_matrix(yc_test, ind_pred).ravel()\n","      ind_specificity.append(tn / (tn + fp))\n","      ind_sensitivity.append(tp / (tp + fn))\n","\n","      ## MCC\n","      train_mcc.append(matthews_corrcoef(y_train, train_pred))\n","      test_mcc.append(matthews_corrcoef(y_test, test_pred))\n","      ind_mcc.append(matthews_corrcoef(yc_test, ind_pred))\n","\n","  print(\"Random set -\", i+1)\n","  print(\"Train-Accuracy = \", avg(train_accuracy))\n","  print(\"Test-Accuracy = \",avg(test_accuracy))\n","  print(\"Train-Specificity = \", avg(train_specificity))\n","  print(\"Test-Specificity = \", avg(test_specificity))\n","  print(\"Train-Sensitivity = \", avg(train_sensitivity))\n","  print(\"Test-Sensitivity = \", avg(test_sensitivity))\n","  print(\"Train-MCC = \", avg(train_mcc))\n","  print(\"Test-MCC = \", avg(test_mcc))\n","  print(\"\\n\\n\")\n","  lg_raws.append([ \"Set0\"+str(i+1), avg(train_accuracy), avg(test_accuracy), avg(ind_accuracy), avg(train_specificity), avg(test_specificity), avg(ind_specificity), \n","                 avg(train_sensitivity), avg(test_sensitivity),  avg(ind_sensitivity), avg(train_mcc), avg(test_mcc),  avg(ind_mcc)])\n","print(\" For LogisticRegression\\n\")\n","table = tabulate(lg_raws, headers, tablefmt='orgtbl')\n","print(table)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Random set - 1\n","Train-Accuracy =  0.7817460220015396\n","Test-Accuracy =  0.7443100470490143\n","Train-Specificity =  0.7850243967748654\n","Test-Specificity =  0.7467223481684763\n","Train-Sensitivity =  0.7835757599569737\n","Test-Sensitivity =  0.7460502285806758\n","Train-MCC =  0.5635435623202517\n","Test-MCC =  0.48903529001194224\n","\n","\n","\n","Random set - 2\n","Train-Accuracy =  0.7975759388716315\n","Test-Accuracy =  0.755695312965279\n","Train-Specificity =  0.8015012198387431\n","Test-Specificity =  0.7577663763274073\n","Train-Sensitivity =  0.7999325634022021\n","Test-Sensitivity =  0.7571758869348089\n","Train-MCC =  0.595196087748812\n","Test-MCC =  0.5117893062027189\n","\n","\n","\n","Random set - 3\n","Train-Accuracy =  0.7972741218303537\n","Test-Accuracy =  0.7567315823953307\n","Train-Specificity =  0.8023351978023066\n","Test-Specificity =  0.7591528457224676\n","Train-Sensitivity =  0.8003257750055481\n","Test-Sensitivity =  0.7583110377153902\n","Train-MCC =  0.5946051482237019\n","Test-MCC =  0.5137762913928717\n","\n","\n","\n","Random set - 4\n","Train-Accuracy =  0.8007031514803806\n","Test-Accuracy =  0.7567305401703293\n","Train-Specificity =  0.8055125554134062\n","Test-Specificity =  0.7610493974466055\n","Train-Sensitivity =  0.8036282039611133\n","Test-Sensitivity =  0.7592322943288597\n","Train-MCC =  0.6014544460993786\n","Test-MCC =  0.5137242435405682\n","\n","\n","\n"," For LogisticRegression\n","\n","| Random-Set   |   Train-Accuracy |   Test-Accuracy |   Ind-Accuracy |   Train-Specificity |   Test-Specificity |   Ind-Accuracy |   Train-Sensitivity |   Test-Sensitivity |   Ind-Accuracy |   Train-MCC |   Test-MCC |   Ind-MCC |\n","|--------------+------------------+-----------------+----------------+---------------------+--------------------+----------------+---------------------+--------------------+----------------+-------------+------------+-----------|\n","| Set01        |         0.781746 |        0.74431  |       0.272039 |            0.785024 |           0.746722 |       0.28699  |            0.783576 |           0.74605  |       0.257087 |    0.563544 |   0.489035 | -0.456454 |\n","| Set02        |         0.797576 |        0.755695 |       0.266828 |            0.801501 |           0.757766 |       0.283172 |            0.799933 |           0.757176 |       0.250485 |    0.595196 |   0.511789 | -0.466902 |\n","| Set03        |         0.797274 |        0.756732 |       0.266713 |            0.802335 |           0.759153 |       0.283218 |            0.800326 |           0.758311 |       0.250208 |    0.594605 |   0.513776 | -0.467105 |\n","| Set04        |         0.800703 |        0.756731 |       0.265291 |            0.805513 |           0.761049 |       0.283252 |            0.803628 |           0.759232 |       0.24733  |    0.601454 |   0.513724 | -0.469991 |\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dlHRxjbdOFz4","executionInfo":{"status":"ok","timestamp":1608704698786,"user_tz":-360,"elapsed":450554,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"1658ba49-30b8-4ad7-ee9a-488b0ca9b185"},"source":["###  for XGBClassifier\n","\n","xgbC = XGBClassifier()\n","\n","train_accuracy=[]\n","train_specificity = []\n","train_sensitivity = []\n","train_mcc = []\n","test_accuracy=[]\n","test_specificity = []\n","test_sensitivity = []\n","test_mcc = []\n","xgbc_rows = []\n","for i, x in enumerate(xc_trains):\n","  for train_index, test_index in cv.split(x, yc_train):\n","      x_train, x_test = x[train_index], x[test_index]\n","      y_train, y_test = yc_train[train_index], yc_train[test_index]\n","      xgbC.fit(x_train, y_train.ravel())\n","      test_pred = xgbC.predict(x_test)\n","      train_pred = xgbC.predict(x_train)\n","      ind_pred = xgbC.predict(xc_tests[i]) # prediction of independent test dataset\n","\n","      ## Accuracy\n","      train_accuracy.append(accuracy_score(y_train, train_pred))\n","      test_accuracy.append(accuracy_score(y_test, test_pred))\n","      ind_accuracy.append(accuracy_score(yc_test, ind_pred))\n","\n","      ## confusion metrics\n","      tn, fp, fn, tp = confusion_matrix(y_train, train_pred).ravel()\n","      train_specificity.append(tn / (tn + fp)) # Specificity\n","      train_sensitivity.append(tp / (tp + fp)) # Sensitivity\n","\n","\n","      tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n","      test_specificity.append(tn / (tn + fp))\n","      test_sensitivity.append(tp / (tp + fp))\n","\n","      tn, fp, fn, tp = confusion_matrix(yc_test, ind_pred).ravel()\n","      ind_specificity.append(tn / (tn + fp))\n","      ind_sensitivity.append(tp / (tp + fn))\n","\n","      ## MCC\n","      train_mcc.append(matthews_corrcoef(y_train, train_pred))\n","      test_mcc.append(matthews_corrcoef(y_test, test_pred))\n","      ind_mcc.append(matthews_corrcoef(yc_test, ind_pred))\n","\n","  print(\"Random set -:\", i+1)\n","  print(\"Train-Accuracy = \", avg(train_accuracy))\n","  print(\"Test-Accuracy = \",avg(test_accuracy))\n","  print(\"Train-Specificity = \", avg(train_specificity))\n","  print(\"Test-Specificity = \", avg(test_specificity))\n","  print(\"Train-Sensitivity = \", avg(train_sensitivity))\n","  print(\"Test-Sensitivity = \", avg(test_sensitivity))\n","  print(\"Train-MCC = \", avg(train_mcc))\n","  print(\"Test-MCC = \", avg(test_mcc))\n","  print(\"\\n\\n\")\n","  xgbc_rows.append([ \"Set0\"+str(i+1), avg(train_accuracy), avg(test_accuracy), avg(ind_accuracy), avg(train_specificity), avg(test_specificity), avg(ind_specificity), \n","                 avg(train_sensitivity), avg(test_sensitivity),  avg(ind_sensitivity), avg(train_mcc), avg(test_mcc),  avg(ind_mcc)])\n","\n","print(\"For XGBClassifier\\n\")\n","table = tabulate(xgbc_rows, headers, tablefmt='orgtbl')\n","print(table)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Random set -: 1\n","Train-Accuracy =  0.9021738491458005\n","Test-Accuracy =  0.7788136501697338\n","Train-Specificity =  0.8985513671119574\n","Test-Specificity =  0.7826202123851569\n","Train-Sensitivity =  0.8993313148007169\n","Test-Sensitivity =  0.7809974914158189\n","Train-MCC =  0.8044182394430915\n","Test-MCC =  0.5580126761224381\n","\n","\n","\n","Random set -: 2\n","Train-Accuracy =  0.9026483961690964\n","Test-Accuracy =  0.7874388065034841\n","Train-Specificity =  0.897687587396983\n","Test-Specificity =  0.7870910392554589\n","Train-Sensitivity =  0.8987316286171456\n","Test-Sensitivity =  0.7873277899611345\n","Train-MCC =  0.8053755760331613\n","Test-MCC =  0.5752494759525802\n","\n","\n","\n","Random set -: 3\n","Train-Accuracy =  0.8994425016584683\n","Test-Accuracy =  0.7931931788855141\n","Train-Specificity =  0.8955600844961469\n","Test-Specificity =  0.7950260509883468\n","Train-Sensitivity =  0.8963814366658677\n","Test-Sensitivity =  0.7944759525203416\n","Train-MCC =  0.7989453457635528\n","Test-MCC =  0.5867526398291939\n","\n","\n","\n","Random set -: 4\n","Train-Accuracy =  0.9007938044908679\n","Test-Accuracy =  0.7918429515812042\n","Train-Specificity =  0.8971271681889856\n","Test-Specificity =  0.793469753012767\n","Train-Sensitivity =  0.8978900927349016\n","Test-Sensitivity =  0.793049634327126\n","Train-MCC =  0.8016371715153868\n","Test-MCC =  0.5841051601081108\n","\n","\n","\n","For XGBClassifier\n","\n","| Random-Set   |   Train-Accuracy |   Test-Accuracy |   Ind-Accuracy |   Train-Specificity |   Test-Specificity |   Ind-Accuracy |   Train-Sensitivity |   Test-Sensitivity |   Ind-Accuracy |   Train-MCC |   Test-MCC |   Ind-MCC |\n","|--------------+------------------+-----------------+----------------+---------------------+--------------------+----------------+---------------------+--------------------+----------------+-------------+------------+-----------|\n","| Set01        |         0.902174 |        0.778814 |       0.260518 |            0.898551 |           0.78262  |       0.279827 |            0.899331 |           0.780997 |       0.241208 |    0.804418 |   0.558013 | -0.479618 |\n","| Set02        |         0.902648 |        0.787439 |       0.255146 |            0.897688 |           0.787091 |       0.274757 |            0.898732 |           0.787328 |       0.235534 |    0.805376 |   0.575249 | -0.490395 |\n","| Set03        |         0.899443 |        0.793193 |       0.25075  |            0.89556  |           0.795026 |       0.271315 |            0.896381 |           0.794476 |       0.230185 |    0.798945 |   0.586753 | -0.499242 |\n","| Set04        |         0.900794 |        0.791843 |       0.246359 |            0.897127 |           0.79347  |       0.269094 |            0.89789  |           0.79305  |       0.223625 |    0.801637 |   0.584105 | -0.508197 |\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2eWcELcSOnZd","executionInfo":{"status":"ok","timestamp":1608704758605,"user_tz":-360,"elapsed":510368,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"0e66dd25-070c-4175-e7a5-e4ade3559918"},"source":["###  for AdaBoostClassifier\n","\n","adaBC = AdaBoostClassifier()\n","\n","train_accuracy=[]\n","train_specificity = []\n","train_sensitivity = []\n","train_mcc = []\n","test_accuracy=[]\n","test_specificity = []\n","test_sensitivity = []\n","test_mcc = []\n","adabc_rows = []\n","\n","for i, x in enumerate(xc_trains):\n","  for train_index, test_index in cv.split(x, yc_train):\n","      x_train, x_test = x[train_index], x[test_index]\n","      y_train, y_test = yc_train[train_index], yc_train[test_index]\n","      adaBC.fit(x_train, y_train.ravel())\n","      test_pred = adaBC.predict(x_test)\n","      train_pred = adaBC.predict(x_train)\n","      ind_pred = adaBC.predict(xc_tests[i]) # prediction of independent test dataset\n","\n","      ## Accuracy\n","      train_accuracy.append(accuracy_score(y_train, train_pred))\n","      test_accuracy.append(accuracy_score(y_test, test_pred))\n","      ind_accuracy.append(accuracy_score(yc_test, ind_pred))\n","\n","      ## confusion metrics\n","      tn, fp, fn, tp = confusion_matrix(y_train, train_pred).ravel()\n","      train_specificity.append(tn / (tn + fp)) # Specificity\n","      train_sensitivity.append(tp / (tp + fp)) # Sensitivity\n","\n","\n","      tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n","      test_specificity.append(tn / (tn + fp))\n","      test_sensitivity.append(tp / (tp + fp))\n","\n","      tn, fp, fn, tp = confusion_matrix(yc_test, ind_pred).ravel()\n","      ind_specificity.append(tn / (tn + fp))\n","      ind_sensitivity.append(tp / (tp + fn))\n","\n","      ## MCC\n","      train_mcc.append(matthews_corrcoef(y_train, train_pred))\n","      test_mcc.append(matthews_corrcoef(y_test, test_pred))\n","      ind_mcc.append(matthews_corrcoef(yc_test, ind_pred))\n","\n","  print(\"Random set -:\", i+1)\n","  print(\"Train-Accuracy = \", avg(train_accuracy))\n","  print(\"Test-Accuracy = \",avg(test_accuracy))\n","  print(\"Train-Specificity = \", avg(train_specificity))\n","  print(\"Test-Specificity = \", avg(test_specificity))\n","  print(\"Train-Sensitivity = \", avg(train_sensitivity))\n","  print(\"Test-Sensitivity = \", avg(test_sensitivity))\n","  print(\"Train-MCC = \", avg(train_mcc))\n","  print(\"Test-MCC = \", avg(test_mcc))\n","  print(\"\\n\\n\")\n","  adabc_rows.append([ \"Set0\"+str(i+1), avg(train_accuracy), avg(test_accuracy), avg(ind_accuracy), avg(train_specificity), avg(test_specificity), avg(ind_specificity), \n","                 avg(train_sensitivity), avg(test_sensitivity),  avg(ind_sensitivity), avg(train_mcc), avg(test_mcc),  avg(ind_mcc)])\n","\n","print(\"For AdaBoostClassifier\\n\")\n","table = tabulate(adabc_rows, headers, tablefmt='orgtbl')\n","print(table)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Random set -: 1\n","Train-Accuracy =  0.8026224076085278\n","Test-Accuracy =  0.7432779465189684\n","Train-Specificity =  0.8015886168218737\n","Test-Specificity =  0.7329340174203556\n","Train-Sensitivity =  0.8020537613434747\n","Test-Sensitivity =  0.7386285634373702\n","Train-MCC =  0.6053015884720152\n","Test-MCC =  0.4872278720104329\n","\n","\n","\n","Random set -: 2\n","Train-Accuracy =  0.8026657900875872\n","Test-Accuracy =  0.7475832291108332\n","Train-Specificity =  0.8030540596828419\n","Test-Specificity =  0.736713995943205\n","Train-Sensitivity =  0.8029383406325561\n","Test-Sensitivity =  0.7424939115561112\n","Train-MCC =  0.6053845348221236\n","Test-MCC =  0.49582617097183\n","\n","\n","\n","Random set -: 3\n","Train-Accuracy =  0.8004948430287219\n","Test-Accuracy =  0.7510926488396561\n","Train-Specificity =  0.8002066287822439\n","Test-Specificity =  0.7425780535337868\n","Train-Sensitivity =  0.8003698353135591\n","Test-Sensitivity =  0.7471008493781547\n","Train-MCC =  0.6010404003975724\n","Test-MCC =  0.5026948462248411\n","\n","\n","\n","Random set -: 4\n","Train-Accuracy =  0.8017168913737697\n","Test-Accuracy =  0.7506890596152701\n","Train-Specificity =  0.8015436538633187\n","Test-Specificity =  0.7462009306765303\n","Train-Sensitivity =  0.8016756993752221\n","Test-Sensitivity =  0.7486293225497092\n","Train-MCC =  0.6034901161281196\n","Test-MCC =  0.5018096072937949\n","\n","\n","\n","For AdaBoostClassifier\n","\n","| Random-Set   |   Train-Accuracy |   Test-Accuracy |   Ind-Accuracy |   Train-Specificity |   Test-Specificity |   Ind-Accuracy |   Train-Sensitivity |   Test-Sensitivity |   Ind-Accuracy |   Train-MCC |   Test-MCC |   Ind-MCC |\n","|--------------+------------------+-----------------+----------------+---------------------+--------------------+----------------+---------------------+--------------------+----------------+-------------+------------+-----------|\n","| Set01        |         0.802622 |        0.743278 |       0.249365 |            0.801589 |           0.732934 |       0.2705   |            0.802054 |           0.738629 |       0.22823  |    0.605302 |   0.487228 | -0.502152 |\n","| Set02        |         0.802666 |        0.747583 |       0.248821 |            0.803054 |           0.736714 |       0.2681   |            0.802938 |           0.742494 |       0.229542 |    0.605385 |   0.495826 | -0.503212 |\n","| Set03        |         0.800495 |        0.751093 |       0.248479 |            0.800207 |           0.742578 |       0.26589  |            0.80037  |           0.747101 |       0.231068 |    0.60104  |   0.502695 | -0.503853 |\n","| Set04        |         0.801717 |        0.750689 |       0.249393 |            0.801544 |           0.746201 |       0.265777 |            0.801676 |           0.748629 |       0.23301  |    0.60349  |   0.50181  | -0.501992 |\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"id":"TftJNtg5O_jO","executionInfo":{"status":"error","timestamp":1608704760766,"user_tz":-360,"elapsed":512523,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"583f727b-080e-414f-e020-6f629be85f23"},"source":["###  for RandomForestClassifier\n","\n","rfC = RandomForestClassifier()\n","\n","train_accuracy=[]\n","train_specificity = []\n","train_sensitivity = []\n","train_mcc = []\n","test_accuracy=[]\n","test_specificity = []\n","test_sensitivity = []\n","test_mcc = []\n","rfc_rows = []\n","\n","for i, x in enumerate(xc_trains):\n","  for train_index, test_index in cv.split(x, yc_train):\n","      x_train, x_test = x[train_index], x[test_index]\n","      y_train, y_test = yc_train[train_index], yc_train[test_index]\n","      rfC.fit(x_train, y_train.ravel())\n","      test_pred = rfC.predict(x_test)\n","      train_pred = rfC.predict(x_train)\n","      ind_pred = rfC.predict(xc_tests[i]) # prediction of independent test dataset\n","\n","      ## Accuracy\n","      train_accuracy.append(accuracy_score(y_train, train_pred))\n","      test_accuracy.append(accuracy_score(y_test, test_pred))\n","      ind_accuracy.append(accuracy_score(yc_test, ind_pred))\n","\n","      ## confusion metrics\n","      tn, fp, fn, tp = confusion_matrix(y_train, train_pred).ravel()\n","      train_specificity.append(tn / (tn + fp)) # Specificity\n","      train_sensitivity.append(tp / (tp + fp)) # Sensitivity\n","\n","\n","      tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n","      test_specificity.append(tn / (tn + fp))\n","      test_sensitivity.append(tp / (tp + fp))\n","\n","      tn, fp, fn, tp = confusion_matrix(yc_test, ind_pred).ravel()\n","      ind_specificity.append(tn / (tn + fp))\n","      ind_sensitivity.append(tp / (tp + fn))\n","\n","      ## MCC\n","      train_mcc.append(matthews_corrcoef(y_train, train_pred))\n","      test_mcc.append(matthews_corrcoef(y_test, test_pred))\n","      ind_mcc.append(matthews_corrcoef(ya_test, ind_pred))\n","\n","\n","  print(\"Random set -:\", i+1)\n","  print(\"Train-Accuracy = \", avg(train_accuracy))\n","  print(\"Test-Accuracy = \",avg(test_accuracy))\n","  print(\"Train-Specificity = \", avg(train_specificity))\n","  print(\"Test-Specificity = \", avg(test_specificity))\n","  print(\"Train-Sensitivity = \", avg(train_sensitivity))\n","  print(\"Test-Sensitivity = \", avg(test_sensitivity))\n","  print(\"Train-MCC = \", avg(train_mcc))\n","  print(\"Test-MCC = \", avg(test_mcc))\n","  print(\"\\n\\n\")\n","  rfc_rows.append([ \"Set0\"+str(i+1), avg(train_accuracy), avg(test_accuracy), avg(ind_accuracy), avg(train_specificity), avg(test_specificity), avg(ind_specificity), \n","                 avg(train_sensitivity), avg(test_sensitivity),  avg(ind_sensitivity), avg(train_mcc), avg(test_mcc),  avg(ind_mcc)])\n","\n","print(\"For RandomForestClassifier\\n\")\n","table = tabulate(rfc_rows, headers, tablefmt='orgtbl')\n","print(table)"],"execution_count":14,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-074ef0bb3223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m       \u001b[0mtrain_mcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatthews_corrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0mtest_mcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatthews_corrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m       \u001b[0mind_mcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatthews_corrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mya_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mmatthews_corrcoef\u001b[0;34m(y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    880\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \"\"\"\n\u001b[0;32m--> 882\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [262, 206]"]}]},{"cell_type":"code","metadata":{"id":"FKGNOljHv3yH","executionInfo":{"status":"aborted","timestamp":1608704760764,"user_tz":-360,"elapsed":512516,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}}},"source":[""],"execution_count":null,"outputs":[]}]}