{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Omar_dataset_A_npy.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPPejLPzME+qKPITkOT9Wfj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/voidAnik/Pattern_LAB/blob/master/Omar_dataset_A_npy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa2L4QRPXL2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f72c57a3-a63a-403a-ad83-fa05f8af394a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbREXcIJFs_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "788196c0-abbe-4e7b-9e25-55839ce3e1a7"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/Pattern\\ Lab/Datasets/Datasets\\ SL\n",
        "path = \"/content/drive/My Drive/Pattern Lab/Datasets/Datasets SL\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Pattern Lab/Datasets/Datasets SL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_AdVuA-dUEa"
      },
      "source": [
        "# all library imports here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJb--s-3YAcs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c28bc412-9e09-4a90-ea0c-1bd50b6804da"
      },
      "source": [
        "# getting the all file names from the folder\n",
        "kmer_files = os.listdir(path+\"/Kmer\")\n",
        "kmer_files.pop(0)\n",
        "print(kmer_files)\n",
        "binary_files = os.listdir(path+\"/binary\")\n",
        "binary_files.pop(0)\n",
        "print(binary_files)\n",
        "cksnap_files = os.listdir(path+\"/CKSNAP\")\n",
        "cksnap_files.pop(0)\n",
        "print(cksnap_files)\n",
        "dac_files = os.listdir(path+\"/DAC\")\n",
        "dac_files.pop(0)\n",
        "print(dac_files)\n",
        "eiip_files = os.listdir(path+\"/EIIP\")\n",
        "eiip_files.pop(0)\n",
        "print(eiip_files)\n",
        "enac_files = os.listdir(path+\"/ENAC\")\n",
        "enac_files.pop(0)\n",
        "print(enac_files)\n",
        "ncp_files = os.listdir(path+\"/NCP\")\n",
        "ncp_files.pop(0)\n",
        "print(ncp_files)\n",
        "pseEiip_files = os.listdir(path+\"/PseEIIP\")\n",
        "pseEiip_files.pop(0)\n",
        "print(pseEiip_files)\n",
        "tac_files = os.listdir(path+\"/TAC\")\n",
        "tac_files.pop(0)\n",
        "print(tac_files)\n",
        "#dataset_folder = ['binary', 'CKSNAP', 'ENAC', 'DAC', 'EIIP', 'PseEIIP', 'NCP', 'Kmer', 'TAC']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NA_test_special_Kmer3.csv', 'NA_test_special_Kmer2.csv', 'NA_test_special_Kmer1.csv', 'NA_test_special_Kmer4.csv', 'NA_test_special_Kmer5.csv', 'NC_train_special_Kmer1.csv', 'NC_train_special_Kmer2.csv', 'NC_train_special_Kmer3.csv', 'NC_train_special_Kmer4.csv', 'NC_train_special_Kmer5.csv', 'PA_test_special_Kmer2.csv', 'PA_test_special_Kmer1.csv', 'PA_test_special_Kmer4.csv', 'PA_test_special_Kmer3.csv', 'PA_test_special_Kmer5.csv', 'PC_train_special_Kmer1.csv', 'PC_train_special_Kmer2.csv', 'PC_train_special_Kmer3.csv', 'PC_train_special_Kmer4.csv', 'PC_train_special_Kmer5.csv', 'NA_train_special_Kmer1.csv', 'NA_train_special_Kmer2.csv', 'NA_train_special_Kmer3.csv', 'NA_train_special_Kmer4.csv', 'NA_train_special_Kmer5.csv', 'ND_test_special_Kmer1.csv', 'ND_test_special_Kmer3.csv', 'ND_test_special_Kmer2.csv', 'ND_test_special_Kmer4.csv', 'ND_test_special_Kmer5.csv', 'PA_train_special_Kmer1.csv', 'PA_train_special_Kmer2.csv', 'PA_train_special_Kmer3.csv', 'PA_train_special_Kmer4.csv', 'PA_train_special_Kmer5.csv', 'PD_test_special_Kmer1.csv', 'PD_test_special_Kmer2.csv', 'PD_test_special_Kmer3.csv', 'PD_test_special_Kmer4.csv', 'PD_test_special_Kmer5.csv', 'NC_test_special_Kmer1.csv', 'NC_test_special_Kmer2.csv', 'NC_test_special_Kmer3.csv', 'NC_test_special_Kmer4.csv', 'NC_test_special_Kmer5.csv', 'ND_train_special_Kmer1.csv', 'ND_train_special_Kmer2.csv', 'ND_train_special_Kmer3.csv', 'ND_train_special_Kmer4.csv', 'ND_train_special_Kmer5.csv', 'PC_test_special_Kmer1.csv', 'PC_test_special_Kmer2.csv', 'PC_test_special_Kmer3.csv', 'PC_test_special_Kmer4.csv', 'PC_test_special_Kmer5.csv', 'PD_train_special_Kmer1.csv', 'PD_train_special_Kmer2.csv', 'PD_train_special_Kmer3.csv', 'PD_train_special_Kmer4.csv', 'PD_train_special_Kmer5.csv']\n",
            "['NA_test_special_binary.csv', 'NC_train_special_binary.csv', 'PA_test_special_binary.csv', 'PC_train_special_binary.csv', 'NA_train_special_binary.csv', 'ND_test_special_binary.csv', 'PA_train_special_binary.csv', 'PD_test_special_binary.csv', 'NC_test_special_binary.csv', 'ND_train_special_binary.csv', 'PC_test_special_binary.csv', 'PD_train_special_binary.csv']\n",
            "['NA_test_special_CKSNAP1.csv', 'NA_test_special_CKSNAP3.csv', 'NA_test_special_CKSNAP5.csv', 'NA_test_special_CKSNAP7.csv', 'NA_test_special_CKSNAP9.csv', 'NC_train_special_CKSNAP1.csv', 'NC_train_special_CKSNAP3.csv', 'NC_train_special_CKSNAP5.csv', 'NC_train_special_CKSNAP7.csv', 'NC_train_special_CKSNAP9.csv', 'PA_test_special_CKSNAP1.csv', 'PA_test_special_CKSNAP3.csv', 'PA_test_special_CKSNAP5.csv', 'PA_test_special_CKSNAP7.csv', 'PA_test_special_CKSNAP9.csv', 'PC_train_special_CKSNAP1.csv', 'PC_train_special_CKSNAP3.csv', 'PC_train_special_CKSNAP5.csv', 'PC_train_special_CKSNAP7.csv', 'NA_train_special_CKSNAP1.csv', 'PC_train_special_CKSNAP9.csv', 'NA_train_special_CKSNAP3.csv', 'NA_train_special_CKSNAP5.csv', 'NA_train_special_CKSNAP7.csv', 'ND_test_special_CKSNAP1.csv', 'NA_train_special_CKSNAP9.csv', 'ND_test_special_CKSNAP3.csv', 'ND_test_special_CKSNAP5.csv', 'ND_test_special_CKSNAP7.csv', 'ND_test_special_CKSNAP9.csv', 'PA_train_special_CKSNAP1.csv', 'PA_train_special_CKSNAP3.csv', 'PA_train_special_CKSNAP5.csv', 'PD_test_special_CKSNAP3.csv', 'PD_test_special_CKSNAP1.csv', 'PA_train_special_CKSNAP9.csv', 'PA_train_special_CKSNAP7.csv', 'PD_test_special_CKSNAP5.csv', 'PD_test_special_CKSNAP7.csv', 'PD_test_special_CKSNAP9.csv', 'NC_test_special_CKSNAP1.csv', 'NC_test_special_CKSNAP3.csv', 'NC_test_special_CKSNAP5.csv', 'NC_test_special_CKSNAP7.csv', 'NC_test_special_CKSNAP9.csv', 'ND_train_special_CKSNAP1.csv', 'ND_train_special_CKSNAP3.csv', 'ND_train_special_CKSNAP5.csv', 'ND_train_special_CKSNAP7.csv', 'ND_train_special_CKSNAP9.csv', 'PC_test_special_CKSNAP1.csv', 'PC_test_special_CKSNAP3.csv', 'PC_test_special_CKSNAP5.csv', 'PC_test_special_CKSNAP9.csv', 'PC_test_special_CKSNAP7.csv', 'PD_train_special_CKSNAP1.csv', 'PD_train_special_CKSNAP3.csv', 'PD_train_special_CKSNAP5.csv', 'PD_train_special_CKSNAP7.csv', 'PD_train_special_CKSNAP9.csv']\n",
            "['NA_test_special_DAC.csv', 'NC_train_special_DAC.csv', 'PA_test_special_DAC.csv', 'PC_train_special_DAC.csv', 'ND_test_special_DAC.csv', 'NA_train_special_DAC.csv', 'PA_train_special_DAC.csv', 'NC_test_special_DAC.csv', 'PD_test_special_DAC.csv', 'ND_train_special_DAC.csv', 'PC_test_special_DAC.csv', 'PD_train_special_DAC.csv']\n",
            "['NA_test_special_EIIP.csv', 'NC_train_special_EIIP.csv', 'PA_test_special_EIIP.csv', 'NA_train_special_EIIP.csv', 'PC_train_special_EIIP.csv', 'ND_test_special_EIIP.csv', 'PA_train_special_EIIP.csv', 'PD_test_special_EIIP.csv', 'ND_train_special_EIIP.csv', 'NC_test_special_EIIP.csv', 'PC_test_special_EIIP.csv', 'PD_train_special_EIIP.csv']\n",
            "['NA_test_special_ENAC5.csv', 'NA_test_special_ENAC10.csv', 'NC_train_special_ENAC5.csv', 'NC_train_special_ENAC10.csv', 'PA_test_special_ENAC5.csv', 'PA_test_special_ENAC10.csv', 'PC_train_special_ENAC5.csv', 'NA_train_special_ENAC5.csv', 'PC_train_special_ENAC10.csv', 'NA_train_special_ENAC10.csv', 'ND_test_special_ENAC5.csv', 'ND_test_special_ENAC10.csv', 'PD_test_special_ENAC5.csv', 'PA_train_special_ENAC5.csv', 'PA_train_special_ENAC10.csv', 'PD_test_special_ENAC10.csv', 'NC_test_special_ENAC5.csv', 'NC_test_special_ENAC10.csv', 'ND_train_special_ENAC5.csv', 'PC_test_special_ENAC10.csv', 'ND_train_special_ENAC10.csv', 'PC_test_special_ENAC5.csv', 'PD_train_special_ENAC5.csv', 'PD_train_special_ENAC10.csv']\n",
            "['PA_test_special_NCP.csv', 'NC_train_special_NCP.csv', 'NA_test_special_NCP.csv', 'PC_train_special_NCP.csv', 'NA_train_special_NCP.csv', 'ND_test_special_NCP.csv', 'PD_test_special_NCP.csv', 'PA_train_special_NCP.csv', 'ND_train_special_NCP.csv', 'NC_test_special_NCP.csv', 'PD_train_special_NCP.csv', 'PC_test_special_NCP.csv']\n",
            "['NA_test_special_PseEIIP.csv', 'NC_train_special_PseEIIP.csv', 'PA_test_special_PseEIIP.csv', 'PC_train_special_PseEIIP.csv', 'NA_train_special_PseEIIP.csv', 'ND_test_special_PseEIIP.csv', 'PA_train_special_PseEIIP.csv', 'PD_test_special_PseEIIP.csv', 'NC_test_special_PseEIIP.csv', 'ND_train_special_PseEIIP.csv', 'PC_test_special_PseEIIP.csv', 'PD_train_special_PseEIIP.csv']\n",
            "['NA_test_special_TAC.csv', 'NC_train_special_TAC.csv', 'PA_test_special_TAC.csv', 'PC_train_special_TAC.csv', 'NA_train_special_TAC.csv', 'ND_test_special_TAC.csv', 'PA_train_special_TAC.csv', 'PD_test_special_TAC.csv', 'NC_test_special_TAC.csv', 'PC_test_special_TAC.csv', 'ND_train_special_TAC.csv', 'PD_train_special_TAC.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFZNkeAriYGp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca3adc06-cbc5-4f88-d624-84d8407ec0a4"
      },
      "source": [
        "print(\"Kmer\")\n",
        "for f in kmer_files:\n",
        "  data = pd.read_csv(path+\"/Kmer/\"+f)\n",
        "  data = data.to_numpy()[:,1:]\n",
        "  np.save(path+\"/Kmer/\"+\"/npy/\"+f[:-4],data)\n",
        "  print(data.shape)\n",
        "\n",
        "print(\"binary\")\n",
        "for f in binary_files:\n",
        "  data = pd.read_csv(path+\"/binary/\"+f)\n",
        "  data = data.to_numpy()[:,1:]\n",
        "  np.save(path+\"/binary/\"+\"/npy/\"+f[:-4],data)\n",
        "  print(data.shape)\n",
        "\n",
        "print(\"CKSNAP\")\n",
        "for f in cksnap_files:\n",
        "  data = pd.read_csv(path+\"/CKSNAP/\"+f)\n",
        "  data = data.to_numpy()[:,1:]\n",
        "  np.save(path+\"/CKSNAP/\"+\"/npy/\"+f[:-4],data)\n",
        "  print(data.shape)\n",
        "\n",
        "print(\"ENAC\")\n",
        "for f in enac_files:\n",
        "  data = pd.read_csv(path+\"/ENAC/\"+f)\n",
        "  data = data.to_numpy()[:,1:]\n",
        "  np.save(path+\"/ENAC/\"+\"/npy/\"+f[:-4],data)\n",
        "  print(data.shape)\n",
        "\n",
        "print(\"DAC\")\n",
        "for f in dac_files:\n",
        "  data = pd.read_csv(path+\"/DAC/\"+f)\n",
        "  data = data.to_numpy()[:,1:]\n",
        "  np.save(path+\"/DAC/\"+\"/npy/\"+f[:-4],data)\n",
        "  print(data.shape)\n",
        "\n",
        "print(\"EIIP\")\n",
        "for f in eiip_files:\n",
        "  data = pd.read_csv(path+\"/EIIP/\"+f)\n",
        "  data = data.to_numpy()[:,1:]\n",
        "  np.save(path+\"/EIIP/\"+\"/npy/\"+f[:-4],data)\n",
        "  print(data.shape)\n",
        "\n",
        "print(\"PseEIIP\")\n",
        "for f in pseEiip_files:\n",
        "  data = pd.read_csv(path+\"/PseEIIP/\"+f)\n",
        "  data = data.to_numpy()[:,1:]\n",
        "  np.save(path+\"/PseEIIP/\"+\"/npy/\"+f[:-4],data)\n",
        "  print(data.shape)\n",
        "\n",
        "print(\"NCP\")\n",
        "for f in ncp_files:\n",
        "  data = pd.read_csv(path+\"/NCP/\"+f)\n",
        "  data = data.to_numpy()[:,1:]\n",
        "  np.save(path+\"/NCP/\"+\"/npy/\"+f[:-4],data)\n",
        "  print(data.shape)\n",
        "\n",
        "print(\"TAC\") \n",
        "for f in tac_files:\n",
        "  data = pd.read_csv(path+\"/TAC/\"+f)\n",
        "  data = data.to_numpy()[:,1:]\n",
        "  np.save(path+\"/TAC/\"+\"/npy/\"+f[:-4],data)\n",
        "  print(data.shape)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kmer\n",
            "(131, 64)\n",
            "(131, 16)\n",
            "(131, 4)\n",
            "(131, 256)\n",
            "(131, 1024)\n",
            "(1449, 4)\n",
            "(1449, 16)\n",
            "(1449, 64)\n",
            "(1449, 256)\n",
            "(1449, 1024)\n",
            "(131, 16)\n",
            "(131, 4)\n",
            "(131, 256)\n",
            "(131, 64)\n",
            "(131, 1024)\n",
            "(1449, 4)\n",
            "(1449, 16)\n",
            "(1449, 64)\n",
            "(1449, 256)\n",
            "(1449, 1024)\n",
            "(1845, 4)\n",
            "(1845, 16)\n",
            "(1845, 64)\n",
            "(1845, 256)\n",
            "(1845, 1024)\n",
            "(117, 4)\n",
            "(117, 64)\n",
            "(117, 16)\n",
            "(117, 256)\n",
            "(117, 1024)\n",
            "(1845, 4)\n",
            "(1845, 16)\n",
            "(1845, 64)\n",
            "(1845, 256)\n",
            "(1845, 1024)\n",
            "(117, 4)\n",
            "(117, 16)\n",
            "(117, 64)\n",
            "(117, 256)\n",
            "(117, 1024)\n",
            "(103, 4)\n",
            "(103, 16)\n",
            "(103, 64)\n",
            "(103, 256)\n",
            "(103, 1024)\n",
            "(1650, 4)\n",
            "(1650, 16)\n",
            "(1650, 64)\n",
            "(1650, 256)\n",
            "(1650, 1024)\n",
            "(103, 4)\n",
            "(103, 16)\n",
            "(103, 64)\n",
            "(103, 256)\n",
            "(103, 1024)\n",
            "(1650, 4)\n",
            "(1650, 16)\n",
            "(1650, 64)\n",
            "(1650, 256)\n",
            "(1650, 1024)\n",
            "binary\n",
            "(131, 164)\n",
            "(1449, 164)\n",
            "(131, 164)\n",
            "(1449, 164)\n",
            "(1845, 164)\n",
            "(117, 164)\n",
            "(1845, 164)\n",
            "(117, 164)\n",
            "(103, 164)\n",
            "(1650, 164)\n",
            "(103, 164)\n",
            "(1650, 164)\n",
            "CKSNAP\n",
            "(131, 32)\n",
            "(131, 64)\n",
            "(131, 96)\n",
            "(131, 128)\n",
            "(131, 160)\n",
            "(1449, 32)\n",
            "(1449, 64)\n",
            "(1449, 96)\n",
            "(1449, 128)\n",
            "(1449, 160)\n",
            "(131, 32)\n",
            "(131, 64)\n",
            "(131, 96)\n",
            "(131, 128)\n",
            "(131, 160)\n",
            "(1449, 32)\n",
            "(1449, 64)\n",
            "(1449, 96)\n",
            "(1449, 128)\n",
            "(1845, 32)\n",
            "(1449, 160)\n",
            "(1845, 64)\n",
            "(1845, 96)\n",
            "(1845, 128)\n",
            "(117, 32)\n",
            "(1845, 160)\n",
            "(117, 64)\n",
            "(117, 96)\n",
            "(117, 128)\n",
            "(117, 160)\n",
            "(1845, 32)\n",
            "(1845, 64)\n",
            "(1845, 96)\n",
            "(117, 64)\n",
            "(117, 32)\n",
            "(1845, 160)\n",
            "(1845, 128)\n",
            "(117, 96)\n",
            "(117, 128)\n",
            "(117, 160)\n",
            "(103, 32)\n",
            "(103, 64)\n",
            "(103, 96)\n",
            "(103, 128)\n",
            "(103, 160)\n",
            "(1650, 32)\n",
            "(1650, 64)\n",
            "(1650, 96)\n",
            "(1650, 128)\n",
            "(1650, 160)\n",
            "(103, 32)\n",
            "(103, 64)\n",
            "(103, 96)\n",
            "(103, 160)\n",
            "(103, 128)\n",
            "(1650, 32)\n",
            "(1650, 64)\n",
            "(1650, 96)\n",
            "(1650, 128)\n",
            "(1650, 160)\n",
            "ENAC\n",
            "(131, 148)\n",
            "(131, 128)\n",
            "(1449, 148)\n",
            "(1449, 128)\n",
            "(131, 148)\n",
            "(131, 128)\n",
            "(1449, 148)\n",
            "(1845, 148)\n",
            "(1449, 128)\n",
            "(1845, 128)\n",
            "(117, 148)\n",
            "(117, 128)\n",
            "(117, 148)\n",
            "(1845, 148)\n",
            "(1845, 128)\n",
            "(117, 128)\n",
            "(103, 148)\n",
            "(103, 128)\n",
            "(1650, 148)\n",
            "(103, 128)\n",
            "(1650, 128)\n",
            "(103, 148)\n",
            "(1650, 148)\n",
            "(1650, 128)\n",
            "DAC\n",
            "(131, 42)\n",
            "(1449, 42)\n",
            "(131, 42)\n",
            "(1449, 42)\n",
            "(117, 42)\n",
            "(1845, 42)\n",
            "(1845, 42)\n",
            "(103, 42)\n",
            "(117, 42)\n",
            "(1650, 42)\n",
            "(103, 42)\n",
            "(1650, 42)\n",
            "EIIP\n",
            "(131, 41)\n",
            "(1449, 41)\n",
            "(131, 41)\n",
            "(1845, 41)\n",
            "(1449, 41)\n",
            "(117, 41)\n",
            "(1845, 41)\n",
            "(117, 41)\n",
            "(1650, 41)\n",
            "(103, 41)\n",
            "(103, 41)\n",
            "(1650, 41)\n",
            "PseEIIP\n",
            "(131, 64)\n",
            "(1449, 64)\n",
            "(131, 64)\n",
            "(1449, 64)\n",
            "(1845, 64)\n",
            "(117, 64)\n",
            "(1845, 64)\n",
            "(117, 64)\n",
            "(103, 64)\n",
            "(1650, 64)\n",
            "(103, 64)\n",
            "(1650, 64)\n",
            "NCP\n",
            "(131, 123)\n",
            "(1449, 123)\n",
            "(131, 123)\n",
            "(1449, 123)\n",
            "(1845, 123)\n",
            "(117, 123)\n",
            "(117, 123)\n",
            "(1845, 123)\n",
            "(1650, 123)\n",
            "(103, 123)\n",
            "(1650, 123)\n",
            "(103, 123)\n",
            "TAC\n",
            "(131, 14)\n",
            "(1449, 14)\n",
            "(131, 14)\n",
            "(1449, 14)\n",
            "(1845, 14)\n",
            "(117, 14)\n",
            "(1845, 14)\n",
            "(117, 14)\n",
            "(103, 14)\n",
            "(103, 14)\n",
            "(1650, 14)\n",
            "(1650, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfsw7KTb5YoY"
      },
      "source": [
        "# getting the all file names from the folder\n",
        "kmer_npy_files = os.listdir(path+\"/Kmer/npy\")\n",
        "binary_npy_files = os.listdir(path+\"/binary/npy\")\n",
        "cksnap_npy_files = os.listdir(path+\"/CKSNAP/npy\")\n",
        "dac_npy_files = os.listdir(path+\"/DAC/npy\")\n",
        "eiip_npy_files = os.listdir(path+\"/EIIP/npy\")\n",
        "enac_npy_files = os.listdir(path+\"/ENAC/npy\")\n",
        "ncp_npy_files = os.listdir(path+\"/NCP/npy\")\n",
        "pseEiip_npy_files = os.listdir(path+\"/PseEIIP/npy\")\n",
        "tac_npy_files = os.listdir(path+\"/TAC/npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fahZHdpUJk0h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ca6cf5-0655-4e1f-a7ae-d1112ce9f64b"
      },
      "source": [
        "no_of_features = []\n",
        "feature_name = ['binary', 'CKSNAP1', 'CKSNAP3', 'CKSNAP5', 'CKSNAP7', 'CKSNAP9', 'ENAC5', 'ENAC10', 'DAC', '_EIIP', 'PseEIIP', 'NCP', 'Kmer1', 'Kmer2', 'Kmer3', 'Kmer4', 'Kmer5', 'TAC']\n",
        "for f_name in feature_name:\n",
        "  if \"binary\" in f_name:\n",
        "    n_path = path+\"/binary/npy/\"+binary_npy_files[0]\n",
        "    dt = np.load(n_path, allow_pickle=True)\n",
        "    no_of_features.append(dt.shape[1])\n",
        "\n",
        "  if \"CKSNAP1\" in f_name:\n",
        "    for f in cksnap_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/CKSNAP/npy/\"+f\n",
        "        dt = np.load(n_path, allow_pickle=True)\n",
        "    no_of_features.append(dt.shape[1])\n",
        "\n",
        "  if \"CKSNAP3\" in f_name:\n",
        "    for f in cksnap_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/CKSNAP/npy/\"+f\n",
        "        dt = np.load(n_path, allow_pickle=True)\n",
        "    no_of_features.append(dt.shape[1])\n",
        "\n",
        "  if \"CKSNAP5\" in f_name:\n",
        "    for f in cksnap_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/CKSNAP/npy/\"+f\n",
        "        dt = np.load(n_path, allow_pickle=True)\n",
        "    no_of_features.append(dt.shape[1])\n",
        "\n",
        "  if \"CKSNAP7\" in f_name:\n",
        "    for f in cksnap_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/CKSNAP/npy/\"+f\n",
        "        dt = np.load(n_path, allow_pickle=True)\n",
        "    no_of_features.append(dt.shape[1])\n",
        "  \n",
        "  if \"CKSNAP9\" in f_name:\n",
        "    for f in cksnap_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/CKSNAP/npy/\"+f\n",
        "        dt = np.load(n_path, allow_pickle=True)\n",
        "    no_of_features.append(dt.shape[1])\n",
        "  \n",
        "  if \"ENAC5\" in f_name:\n",
        "    for f in enac_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/ENAC/npy/\"+enac_npy_files[0]\n",
        "        dt = np.load(n_path, allow_pickle=True)\n",
        "    no_of_features.append(dt.shape[1])\n",
        "\n",
        "  if \"ENAC10\" in f_name:\n",
        "    for f in enac_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/ENAC/npy/\"+enac_npy_files[0]\n",
        "        dt = np.load(n_path, allow_pickle=True)\n",
        "    no_of_features.append(dt.shape[1])\n",
        "\n",
        "  if \"DAC\" in f_name:\n",
        "    n_path = path+\"/DAC/npy/\"+dac_npy_files[0]\n",
        "    dt = np.load(n_path, allow_pickle=True)\n",
        "    no_of_features.append(dt.shape[1])\n",
        "\n",
        "  if \"_EIIP\" in f_name:\n",
        "    n_path = path+\"/EIIP/npy/\"+eiip_npy_files[0]\n",
        "    dt = np.load(n_path, allow_pickle=True)\n",
        "    no_of_features.append(dt.shape[1])\n",
        "    \n",
        "  if \"PseEIIP\" in f_name:\n",
        "    n_path = path+\"/PseEIIP/npy/\"+pseEiip_npy_files[0]\n",
        "    dt = np.load(n_path, allow_pickle=True)\n",
        "    no_of_features.append(dt.shape[1])\n",
        "    \n",
        "  if \"NCP\" in f_name:\n",
        "    n_path = path+\"/NCP/npy/\"+ncp_npy_files[0]\n",
        "    dt = np.load(n_path, allow_pickle=True)\n",
        "    no_of_features.append(dt.shape[1])\n",
        "\n",
        "  if \"Kmer1\" in f_name:\n",
        "    for f in kmer_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/Kmer/npy/\"+f\n",
        "        dt = np.load(n_path, allow_pickle=True)\n",
        "    no_of_features.append(dt.shape[1])\n",
        "  if \"Kmer2\" in f_name:\n",
        "    for f in kmer_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/Kmer/npy/\"+f\n",
        "        dt = np.load(n_path, allow_pickle=True)\n",
        "    no_of_features.append(dt.shape[1])\n",
        "\n",
        "  if \"Kmer3\" in f_name:\n",
        "    for f in kmer_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/Kmer/npy/\"+f\n",
        "        dt = np.load(n_path, allow_pickle=True)\n",
        "    no_of_features.append(dt.shape[1])\n",
        "  \n",
        "  if \"Kmer4\" in f_name:\n",
        "    for f in kmer_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/Kmer/npy/\"+f\n",
        "        dt = np.load(n_path, allow_pickle=True)\n",
        "    no_of_features.append(dt.shape[1])\n",
        "  \n",
        "  if \"Kmer5\" in f_name:\n",
        "    for f in kmer_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/Kmer/npy/\"+f\n",
        "        dt = np.load(n_path, allow_pickle=True)\n",
        "    no_of_features.append(dt.shape[1])\n",
        "\n",
        "  if \"TAC\" in f_name:\n",
        "    n_path = path+\"/TAC/npy/\"+tac_npy_files[0]\n",
        "    dt = np.load(n_path, allow_pickle=True)\n",
        "    no_of_features.append(dt.shape[1])\n",
        "\n",
        "print(no_of_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[164, 32, 64, 96, 128, 160, 148, 148, 42, 41, 64, 123, 4, 16, 64, 256, 1024, 14]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1Fql-gc6ljx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0865fda2-d2f4-48e6-d924-defbeacb9ea1"
      },
      "source": [
        "# making dictionary with all the features starting an ending index\n",
        "index_dictionary = {}\n",
        "track = 0\n",
        "for i,f_name in enumerate(feature_name):\n",
        "  l = [track, track+no_of_features[i]-1]\n",
        "  track = track + no_of_features[i]\n",
        "  index_dictionary[f_name] = l\n",
        "print(index_dictionary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'binary': [0, 163], 'CKSNAP1': [164, 195], 'CKSNAP3': [196, 259], 'CKSNAP5': [260, 355], 'CKSNAP7': [356, 483], 'CKSNAP9': [484, 643], 'ENAC5': [644, 791], 'ENAC10': [792, 939], 'DAC': [940, 981], '_EIIP': [982, 1022], 'PseEIIP': [1023, 1086], 'NCP': [1087, 1209], 'Kmer1': [1210, 1213], 'Kmer2': [1214, 1229], 'Kmer3': [1230, 1293], 'Kmer4': [1294, 1549], 'Kmer5': [1550, 2573], 'TAC': [2574, 2587]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X2ttlHo9-tW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08ce0e1d-59f1-4899-bab2-a9baa0f34d01"
      },
      "source": [
        "for f_name in feature_name:\n",
        "  if \"binary\" in f_name:\n",
        "    for f in binary_npy_files:\n",
        "      if \"PA_\" in f and \"test\" in f:\n",
        "        print(f)\n",
        "        n_path = path+\"/binary/npy/\"+f\n",
        "        pa_test = np.load(n_path, allow_pickle=True)\n",
        "      if \"NA_\" in f and \"test\" in f:\n",
        "        print(f)\n",
        "        n_path = path+\"/binary/npy/\"+f\n",
        "        na_test = np.load(n_path, allow_pickle=True)\n",
        "      if \"PA_\" in f and \"train\" in f:\n",
        "        print(f)\n",
        "        n_path = path+\"/binary/npy/\"+f\n",
        "        pa_train = np.load(n_path, allow_pickle=True)\n",
        "      if \"NA_\" in f and \"train\" in f:\n",
        "        print(f)\n",
        "        n_path = path+\"/binary/npy/\"+f\n",
        "        na_train = np.load(n_path, allow_pickle=True)\n",
        "  if \"CKSNAP1\" in f_name:\n",
        "    for f in cksnap_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/CKSNAP/npy/\"+f\n",
        "        if \"PA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_test = np.concatenate((pa_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_test.shape)\n",
        "        if \"NA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_test = np.concatenate((na_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_test.shape)\n",
        "        if \"PA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_train = np.concatenate((pa_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_train.shape)\n",
        "        if \"NA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_train = np.concatenate((na_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_train.shape)\n",
        "\n",
        "  if \"CKSNAP3\" in f_name:\n",
        "    for f in cksnap_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/CKSNAP/npy/\"+f\n",
        "        if \"PA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_test = np.concatenate((pa_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_test.shape)\n",
        "        if \"NA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_test = np.concatenate((na_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_test.shape)\n",
        "        if \"PA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_train = np.concatenate((pa_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_train.shape)\n",
        "        if \"NA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_train = np.concatenate((na_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_train.shape)\n",
        "\n",
        "  if \"CKSNAP5\" in f_name:\n",
        "    for f in cksnap_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/CKSNAP/npy/\"+f\n",
        "        if \"PA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_test = np.concatenate((pa_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_test.shape)\n",
        "        if \"NA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_test = np.concatenate((na_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_test.shape)\n",
        "        if \"PA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_train = np.concatenate((pa_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_train.shape)\n",
        "        if \"NA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_train = np.concatenate((na_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_train.shape)\n",
        "\n",
        "  if \"CKSNAP7\" in f_name:\n",
        "    for f in cksnap_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/CKSNAP/npy/\"+f\n",
        "        if \"PA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_test = np.concatenate((pa_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_test.shape)\n",
        "        if \"NA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_test = np.concatenate((na_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_test.shape)\n",
        "        if \"PA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_train = np.concatenate((pa_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_train.shape)\n",
        "        if \"NA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_train = np.concatenate((na_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_train.shape)\n",
        "\n",
        "  if \"CKSNAP9\" in f_name:\n",
        "    for f in cksnap_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/CKSNAP/npy/\"+f\n",
        "        if \"PA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_test = np.concatenate((pa_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_test.shape)\n",
        "        if \"NA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_test = np.concatenate((na_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_test.shape)\n",
        "        if \"PA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_train = np.concatenate((pa_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_train.shape)\n",
        "        if \"NA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_train = np.concatenate((na_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_train.shape)\n",
        "  \n",
        "  if \"ENAC5\" in f_name:\n",
        "    for f in enac_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/ENAC/npy/\"+f\n",
        "        if \"PA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_test = np.concatenate((pa_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_test.shape)\n",
        "        if \"NA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_test = np.concatenate((na_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_test.shape)\n",
        "        if \"PA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_train = np.concatenate((pa_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_train.shape)\n",
        "        if \"NA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_train = np.concatenate((na_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_train.shape)\n",
        "  \n",
        "  if \"ENAC10\" in f_name:\n",
        "    for f in enac_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/ENAC/npy/\"+f\n",
        "        if \"PA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_test = np.concatenate((pa_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_test.shape)\n",
        "        if \"NA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_test = np.concatenate((na_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_test.shape)\n",
        "        if \"PA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_train = np.concatenate((pa_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_train.shape)\n",
        "        if \"NA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_train = np.concatenate((na_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_train.shape)\n",
        "  \n",
        "  if \"DAC\" in f_name:\n",
        "    for f in dac_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/DAC/npy/\"+f\n",
        "        if \"PA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_test = np.concatenate((pa_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_test.shape)\n",
        "        if \"NA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_test = np.concatenate((na_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_test.shape)\n",
        "        if \"PA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_train = np.concatenate((pa_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_train.shape)\n",
        "        if \"NA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_train = np.concatenate((na_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_train.shape)\n",
        " \n",
        "  if \"_EIIP\" in f_name:\n",
        "    for f in eiip_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/EIIP/npy/\"+f\n",
        "        if \"PA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_test = np.concatenate((pa_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_test.shape)\n",
        "        if \"NA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_test = np.concatenate((na_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_test.shape)\n",
        "        if \"PA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_train = np.concatenate((pa_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_train.shape)\n",
        "        if \"NA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_train = np.concatenate((na_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_train.shape)\n",
        " \n",
        "  if \"PseEIIP\" in f_name:\n",
        "      for f in pseEiip_npy_files:\n",
        "        if f_name in f:\n",
        "          n_path = path+\"/PseEIIP/npy/\"+f\n",
        "          if \"PA_\" in f and \"test\" in f:\n",
        "            print(f)\n",
        "            dt = np.load(n_path, allow_pickle=True)\n",
        "            pa_test = np.concatenate((pa_test, dt), axis=1)\n",
        "            print(dt.shape[1])\n",
        "            print(pa_test.shape)\n",
        "          if \"NA_\" in f and \"test\" in f:\n",
        "            print(f)\n",
        "            dt = np.load(n_path, allow_pickle=True)\n",
        "            na_test = np.concatenate((na_test, dt), axis=1)\n",
        "            print(dt.shape[1])\n",
        "            print(na_test.shape)\n",
        "          if \"PA_\" in f and \"train\" in f:\n",
        "            print(f)\n",
        "            dt = np.load(n_path, allow_pickle=True)\n",
        "            pa_train = np.concatenate((pa_train, dt), axis=1)\n",
        "            print(dt.shape[1])\n",
        "            print(pa_train.shape)\n",
        "          if \"NA_\" in f and \"train\" in f:\n",
        "            print(f)\n",
        "            dt = np.load(n_path, allow_pickle=True)\n",
        "            na_train = np.concatenate((na_train, dt), axis=1)\n",
        "            print(dt.shape[1])\n",
        "            print(na_train.shape)\n",
        "          \n",
        "    \n",
        "  if \"NCP\" in f_name:\n",
        "    for f in ncp_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/NCP/npy/\"+f\n",
        "        if \"PA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_test = np.concatenate((pa_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_test.shape)\n",
        "        if \"NA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_test = np.concatenate((na_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_test.shape)\n",
        "        if \"PA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_train = np.concatenate((pa_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_train.shape)\n",
        "        if \"NA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_train = np.concatenate((na_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_train.shape)\n",
        "  \n",
        "  if \"Kmer1\" in f_name:\n",
        "    for f in kmer_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/Kmer/npy/\"+f\n",
        "        if \"PA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_test = np.concatenate((pa_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_test.shape)\n",
        "        if \"NA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_test = np.concatenate((na_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_test.shape)\n",
        "        if \"PA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_train = np.concatenate((pa_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_train.shape)\n",
        "        if \"NA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_train = np.concatenate((na_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_train.shape)\n",
        "  \n",
        "  if \"Kmer2\" in f_name:\n",
        "    for f in kmer_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/Kmer/npy/\"+f\n",
        "        if \"PA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_test = np.concatenate((pa_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_test.shape)\n",
        "        if \"NA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_test = np.concatenate((na_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_test.shape)\n",
        "        if \"PA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_train = np.concatenate((pa_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_train.shape)\n",
        "        if \"NA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_train = np.concatenate((na_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_train.shape)\n",
        "  \n",
        "  if \"Kmer3\" in f_name:\n",
        "    for f in kmer_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/Kmer/npy/\"+f\n",
        "        if \"PA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_test = np.concatenate((pa_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_test.shape)\n",
        "        if \"NA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_test = np.concatenate((na_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_test.shape)\n",
        "        if \"PA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_train = np.concatenate((pa_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_train.shape)\n",
        "        if \"NA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_train = np.concatenate((na_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_train.shape)\n",
        "  \n",
        "  if \"Kmer4\" in f_name:\n",
        "    for f in kmer_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/Kmer/npy/\"+f\n",
        "        if \"PA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_test = np.concatenate((pa_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_test.shape)\n",
        "        if \"NA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_test = np.concatenate((na_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_test.shape)\n",
        "        if \"PA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_train = np.concatenate((pa_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_train.shape)\n",
        "        if \"NA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_train = np.concatenate((na_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_train.shape)\n",
        "  \n",
        "  if \"Kmer5\" in f_name:\n",
        "    for f in kmer_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/Kmer/npy/\"+f\n",
        "        if \"PA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_test = np.concatenate((pa_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_test.shape)\n",
        "        if \"NA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_test = np.concatenate((na_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_test.shape)\n",
        "        if \"PA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_train = np.concatenate((pa_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_train.shape)\n",
        "        if \"NA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_train = np.concatenate((na_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_train.shape)\n",
        "  \n",
        "  if \"TAC\" in f_name:\n",
        "    for f in tac_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/TAC/npy/\"+f\n",
        "        if \"PA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_test = np.concatenate((pa_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_test.shape)\n",
        "        if \"NA_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_test = np.concatenate((na_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_test.shape)\n",
        "        if \"PA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pa_train = np.concatenate((pa_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pa_train.shape)\n",
        "        if \"NA_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          na_train = np.concatenate((na_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(na_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NA_test_special_binary.npy\n",
            "PA_test_special_binary.npy\n",
            "NA_train_special_binary.npy\n",
            "PA_train_special_binary.npy\n",
            "NA_test_special_CKSNAP1.npy\n",
            "32\n",
            "(131, 196)\n",
            "PA_test_special_CKSNAP1.npy\n",
            "32\n",
            "(131, 196)\n",
            "NA_train_special_CKSNAP1.npy\n",
            "32\n",
            "(1845, 196)\n",
            "PA_train_special_CKSNAP1.npy\n",
            "32\n",
            "(1845, 196)\n",
            "NA_test_special_CKSNAP3.npy\n",
            "64\n",
            "(131, 260)\n",
            "PA_test_special_CKSNAP3.npy\n",
            "64\n",
            "(131, 260)\n",
            "NA_train_special_CKSNAP3.npy\n",
            "64\n",
            "(1845, 260)\n",
            "PA_train_special_CKSNAP3.npy\n",
            "64\n",
            "(1845, 260)\n",
            "NA_test_special_CKSNAP5.npy\n",
            "96\n",
            "(131, 356)\n",
            "PA_test_special_CKSNAP5.npy\n",
            "96\n",
            "(131, 356)\n",
            "NA_train_special_CKSNAP5.npy\n",
            "96\n",
            "(1845, 356)\n",
            "PA_train_special_CKSNAP5.npy\n",
            "96\n",
            "(1845, 356)\n",
            "NA_test_special_CKSNAP7.npy\n",
            "128\n",
            "(131, 484)\n",
            "PA_test_special_CKSNAP7.npy\n",
            "128\n",
            "(131, 484)\n",
            "NA_train_special_CKSNAP7.npy\n",
            "128\n",
            "(1845, 484)\n",
            "PA_train_special_CKSNAP7.npy\n",
            "128\n",
            "(1845, 484)\n",
            "NA_test_special_CKSNAP9.npy\n",
            "160\n",
            "(131, 644)\n",
            "PA_test_special_CKSNAP9.npy\n",
            "160\n",
            "(131, 644)\n",
            "NA_train_special_CKSNAP9.npy\n",
            "160\n",
            "(1845, 644)\n",
            "PA_train_special_CKSNAP9.npy\n",
            "160\n",
            "(1845, 644)\n",
            "NA_test_special_ENAC5.npy\n",
            "148\n",
            "(131, 792)\n",
            "PA_test_special_ENAC5.npy\n",
            "148\n",
            "(131, 792)\n",
            "NA_train_special_ENAC5.npy\n",
            "148\n",
            "(1845, 792)\n",
            "PA_train_special_ENAC5.npy\n",
            "148\n",
            "(1845, 792)\n",
            "NA_test_special_ENAC10.npy\n",
            "128\n",
            "(131, 920)\n",
            "PA_test_special_ENAC10.npy\n",
            "128\n",
            "(131, 920)\n",
            "NA_train_special_ENAC10.npy\n",
            "128\n",
            "(1845, 920)\n",
            "PA_train_special_ENAC10.npy\n",
            "128\n",
            "(1845, 920)\n",
            "NA_test_special_DAC.npy\n",
            "42\n",
            "(131, 962)\n",
            "PA_test_special_DAC.npy\n",
            "42\n",
            "(131, 962)\n",
            "NA_train_special_DAC.npy\n",
            "42\n",
            "(1845, 962)\n",
            "PA_train_special_DAC.npy\n",
            "42\n",
            "(1845, 962)\n",
            "NA_test_special_EIIP.npy\n",
            "41\n",
            "(131, 1003)\n",
            "PA_test_special_EIIP.npy\n",
            "41\n",
            "(131, 1003)\n",
            "NA_train_special_EIIP.npy\n",
            "41\n",
            "(1845, 1003)\n",
            "PA_train_special_EIIP.npy\n",
            "41\n",
            "(1845, 1003)\n",
            "NA_test_special_PseEIIP.npy\n",
            "64\n",
            "(131, 1067)\n",
            "PA_test_special_PseEIIP.npy\n",
            "64\n",
            "(131, 1067)\n",
            "NA_train_special_PseEIIP.npy\n",
            "64\n",
            "(1845, 1067)\n",
            "PA_train_special_PseEIIP.npy\n",
            "64\n",
            "(1845, 1067)\n",
            "PA_test_special_NCP.npy\n",
            "123\n",
            "(131, 1190)\n",
            "NA_test_special_NCP.npy\n",
            "123\n",
            "(131, 1190)\n",
            "NA_train_special_NCP.npy\n",
            "123\n",
            "(1845, 1190)\n",
            "PA_train_special_NCP.npy\n",
            "123\n",
            "(1845, 1190)\n",
            "NA_test_special_Kmer1.npy\n",
            "4\n",
            "(131, 1194)\n",
            "PA_test_special_Kmer1.npy\n",
            "4\n",
            "(131, 1194)\n",
            "NA_train_special_Kmer1.npy\n",
            "4\n",
            "(1845, 1194)\n",
            "PA_train_special_Kmer1.npy\n",
            "4\n",
            "(1845, 1194)\n",
            "NA_test_special_Kmer2.npy\n",
            "16\n",
            "(131, 1210)\n",
            "PA_test_special_Kmer2.npy\n",
            "16\n",
            "(131, 1210)\n",
            "NA_train_special_Kmer2.npy\n",
            "16\n",
            "(1845, 1210)\n",
            "PA_train_special_Kmer2.npy\n",
            "16\n",
            "(1845, 1210)\n",
            "NA_test_special_Kmer3.npy\n",
            "64\n",
            "(131, 1274)\n",
            "PA_test_special_Kmer3.npy\n",
            "64\n",
            "(131, 1274)\n",
            "NA_train_special_Kmer3.npy\n",
            "64\n",
            "(1845, 1274)\n",
            "PA_train_special_Kmer3.npy\n",
            "64\n",
            "(1845, 1274)\n",
            "NA_test_special_Kmer4.npy\n",
            "256\n",
            "(131, 1530)\n",
            "PA_test_special_Kmer4.npy\n",
            "256\n",
            "(131, 1530)\n",
            "NA_train_special_Kmer4.npy\n",
            "256\n",
            "(1845, 1530)\n",
            "PA_train_special_Kmer4.npy\n",
            "256\n",
            "(1845, 1530)\n",
            "NA_test_special_Kmer5.npy\n",
            "1024\n",
            "(131, 2554)\n",
            "PA_test_special_Kmer5.npy\n",
            "1024\n",
            "(131, 2554)\n",
            "NA_train_special_Kmer5.npy\n",
            "1024\n",
            "(1845, 2554)\n",
            "PA_train_special_Kmer5.npy\n",
            "1024\n",
            "(1845, 2554)\n",
            "NA_test_special_TAC.npy\n",
            "14\n",
            "(131, 2568)\n",
            "PA_test_special_TAC.npy\n",
            "14\n",
            "(131, 2568)\n",
            "NA_train_special_TAC.npy\n",
            "14\n",
            "(1845, 2568)\n",
            "PA_train_special_TAC.npy\n",
            "14\n",
            "(1845, 2568)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9OMxaO_AMF9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a37c43a2-c646-4116-8fe3-cc837703ebf7"
      },
      "source": [
        "import pickle\n",
        "\n",
        "# saving things\n",
        "print(pa_test.shape)\n",
        "print(pa_train.shape)\n",
        "print(na_test.shape)\n",
        "print(na_train.shape)\n",
        "np.save(path+\"/n_p_test_train/\"+\"PA_test\",pa_test)\n",
        "np.save(path+\"/n_p_test_train/\"+\"PA_train\",pa_train)\n",
        "np.save(path+\"/n_p_test_train/\"+\"NA_test\",na_test)\n",
        "np.save(path+\"/n_p_test_train/\"+\"NA_train\",na_train)\n",
        "\n",
        "a_file = open(path+\"/classified_datasets/index_dictionary.pkl\", \"wb\")\n",
        "pickle.dump(index_dictionary, a_file)\n",
        "a_file.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(131, 2568)\n",
            "(1845, 2568)\n",
            "(131, 2568)\n",
            "(1845, 2568)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya4ZQquVJ4OY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7b408a1-acd4-4ea2-e8b8-d3b2a4b3ab17"
      },
      "source": [
        "a_file = open(path+\"/classified_datasets/index_dictionary.pkl\", \"rb\")\n",
        "output = pickle.load(a_file)\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'binary': [0, 163], 'CKSNAP1': [164, 195], 'CKSNAP3': [196, 259], 'CKSNAP5': [260, 355], 'CKSNAP7': [356, 483], 'CKSNAP9': [484, 643], 'ENAC5': [644, 791], 'ENAC10': [792, 939], 'DAC': [940, 981], '_EIIP': [982, 1022], 'PseEIIP': [1023, 1086], 'NCP': [1087, 1209], 'Kmer1': [1210, 1213], 'Kmer2': [1214, 1229], 'Kmer3': [1230, 1293], 'Kmer4': [1294, 1549], 'Kmer5': [1550, 2573], 'TAC': [2574, 2587]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2v3aSiaqBb_s",
        "outputId": "c39730e1-3245-4efd-ed59-e9fbaae20e66"
      },
      "source": [
        "n_p_test_train = os.listdir(path+\"/n_p_test_train\")\n",
        "ya_train_list = []\n",
        "ya_test_list = []\n",
        "for f in n_p_test_train:\n",
        "  if \"NA\" in f and \"train\" in f:\n",
        "    na_train_x = np.load(path+\"/n_p_test_train/\"+f, allow_pickle=True)\n",
        "    print(na_train_x.shape)\n",
        "    for i in range(na_train_x.shape[0]):\n",
        "      ya_train_list.append([0])\n",
        "  if \"PA\" in f and \"train\" in f:\n",
        "    pa_train_x = np.load(path+\"/n_p_test_train/\"+f, allow_pickle=True)\n",
        "    print(pa_train_x.shape)\n",
        "    for i in range(pa_train_x.shape[0]):\n",
        "      ya_train_list.append([1])\n",
        "  if \"PA\" in f and \"test\" in f:\n",
        "    pa_test_x = np.load(path+\"/n_p_test_train/\"+f, allow_pickle=True)\n",
        "    print(pa_test_x.shape)\n",
        "    for i in range(pa_test_x.shape[0]):\n",
        "      ya_test_list.append([1])\n",
        "  if \"NA\" in f and \"test\" in f:\n",
        "    na_test_x = np.load(path+\"/n_p_test_train/\"+f, allow_pickle=True)\n",
        "    print(na_test_x.shape)\n",
        "    for i in range(na_test_x.shape[0]):\n",
        "      ya_test_list.append([0])\n",
        "\n",
        "# saving ya_train)\n",
        "ya_train = np.array(ya_train_list)\n",
        "print(ya_train.shape)\n",
        "np.save(path+\"/classified_datasets/ya_train.npy\", ya_train)\n",
        "\n",
        "# saving ya_test\n",
        "ya_test = np.array(ya_test_list)\n",
        "print(ya_test.shape)\n",
        "np.save(path+\"/classified_datasets/ya_test.npy\", ya_test)\n",
        "\n",
        "# saving xa_train\n",
        "xa_train = np.concatenate((pa_train_x, na_train_x), axis=0)\n",
        "print(xa_train.shape)\n",
        "np.save(path+\"/classified_datasets/xa_train.npy\", xa_train)\n",
        "\n",
        "# saving xa_test\n",
        "xa_test = np.concatenate((pa_test_x, na_test_x), axis=0)\n",
        "print(xa_test.shape)\n",
        "np.save(path+\"/classified_datasets/xa_test.npy\", xa_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(131, 2568)\n",
            "(1845, 2568)\n",
            "(131, 2568)\n",
            "(1845, 2568)\n",
            "(3690, 1)\n",
            "(262, 1)\n",
            "(3690, 2568)\n",
            "(262, 2568)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN3sY4Y-csTR"
      },
      "source": [
        "For Dataset C"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS-dx3D2ig-L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b78fe2-d298-4c45-cb7f-67b9d2083315"
      },
      "source": [
        "# for datasets c\n",
        "for f_name in feature_name:\n",
        "  if \"binary\" in f_name:\n",
        "    for f in binary_npy_files:\n",
        "      if \"PC_\" in f and \"test\" in f:\n",
        "        print(f)\n",
        "        n_path = path+\"/binary/npy/\"+f\n",
        "        pc_test = np.load(n_path, allow_pickle=True)\n",
        "      if \"NC_\" in f and \"test\" in f:\n",
        "        print(f)\n",
        "        n_path = path+\"/binary/npy/\"+f\n",
        "        nc_test = np.load(n_path, allow_pickle=True)\n",
        "      if \"PC_\" in f and \"train\" in f:\n",
        "        print(f)\n",
        "        n_path = path+\"/binary/npy/\"+f\n",
        "        pc_train = np.load(n_path, allow_pickle=True)\n",
        "      if \"NC_\" in f and \"train\" in f:\n",
        "        print(f)\n",
        "        n_path = path+\"/binary/npy/\"+f\n",
        "        nc_train = np.load(n_path, allow_pickle=True)\n",
        "  if \"CKSNAP1\" in f_name:\n",
        "    for f in cksnap_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/CKSNAP/npy/\"+f\n",
        "        if \"PC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_test = np.concatenate((pc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_test.shape)\n",
        "        if \"NC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_test = np.concatenate((nc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_test.shape)\n",
        "        if \"PC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_train = np.concatenate((pc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_train.shape)\n",
        "        if \"NC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_train = np.concatenate((nc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_train.shape)\n",
        "\n",
        "  if \"CKSNAP3\" in f_name:\n",
        "    for f in cksnap_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/CKSNAP/npy/\"+f\n",
        "        if \"PC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_test = np.concatenate((pc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_test.shape)\n",
        "        if \"NC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_test = np.concatenate((nc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_test.shape)\n",
        "        if \"PC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_train = np.concatenate((pc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_train.shape)\n",
        "        if \"NC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_train = np.concatenate((nc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_train.shape)\n",
        "\n",
        "  if \"CKSNAP5\" in f_name:\n",
        "    for f in cksnap_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/CKSNAP/npy/\"+f\n",
        "        if \"PC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_test = np.concatenate((pc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_test.shape)\n",
        "        if \"NC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_test = np.concatenate((nc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_test.shape)\n",
        "        if \"PC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_train = np.concatenate((pc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_train.shape)\n",
        "        if \"NC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_train = np.concatenate((nc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_train.shape)\n",
        "\n",
        "  if \"CKSNAP7\" in f_name:\n",
        "    for f in cksnap_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/CKSNAP/npy/\"+f\n",
        "        if \"PC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_test = np.concatenate((pc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_test.shape)\n",
        "        if \"NC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_test = np.concatenate((nc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_test.shape)\n",
        "        if \"PC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_train = np.concatenate((pc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_train.shape)\n",
        "        if \"NC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_train = np.concatenate((nc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_train.shape)\n",
        "\n",
        "  if \"CKSNAP9\" in f_name:\n",
        "    for f in cksnap_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/CKSNAP/npy/\"+f\n",
        "        if \"PC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_test = np.concatenate((pc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_test.shape)\n",
        "        if \"NC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_test = np.concatenate((nc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_test.shape)\n",
        "        if \"PC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_train = np.concatenate((pc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_train.shape)\n",
        "        if \"NC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_train = np.concatenate((nc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_train.shape)\n",
        "  \n",
        "  if \"ENAC5\" in f_name:\n",
        "    for f in enac_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/ENAC/npy/\"+f\n",
        "        if \"PC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_test = np.concatenate((pc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_test.shape)\n",
        "        if \"NC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_test = np.concatenate((nc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_test.shape)\n",
        "        if \"PC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_train = np.concatenate((pc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_train.shape)\n",
        "        if \"NC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_train = np.concatenate((nc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_train.shape)\n",
        "  \n",
        "  if \"ENAC10\" in f_name:\n",
        "    for f in enac_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/ENAC/npy/\"+f\n",
        "        if \"PC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_test = np.concatenate((pc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_test.shape)\n",
        "        if \"NC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_test = np.concatenate((nc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_test.shape)\n",
        "        if \"PC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_train = np.concatenate((pc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_train.shape)\n",
        "        if \"NC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_train = np.concatenate((nc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_train.shape)\n",
        "  \n",
        "  if \"DAC\" in f_name:\n",
        "    for f in dac_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/DAC/npy/\"+f\n",
        "        if \"PC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_test = np.concatenate((pc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_test.shape)\n",
        "        if \"NC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_test = np.concatenate((nc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_test.shape)\n",
        "        if \"PC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_train = np.concatenate((pc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_train.shape)\n",
        "        if \"NC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_train = np.concatenate((nc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_train.shape)\n",
        " \n",
        "  if \"_EIIP\" in f_name:\n",
        "    for f in eiip_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/EIIP/npy/\"+f\n",
        "        if \"PC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_test = np.concatenate((pc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_test.shape)\n",
        "        if \"NC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_test = np.concatenate((nc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_test.shape)\n",
        "        if \"PC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_train = np.concatenate((pc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_train.shape)\n",
        "        if \"NC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_train = np.concatenate((nc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_train.shape)\n",
        " \n",
        "  if \"PseEIIP\" in f_name:\n",
        "      for f in pseEiip_npy_files:\n",
        "        if f_name in f:\n",
        "          n_path = path+\"/PseEIIP/npy/\"+f\n",
        "          if \"PC_\" in f and \"test\" in f:\n",
        "            print(f)\n",
        "            dt = np.load(n_path, allow_pickle=True)\n",
        "            pc_test = np.concatenate((pc_test, dt), axis=1)\n",
        "            print(dt.shape[1])\n",
        "            print(pc_test.shape)\n",
        "          if \"NC_\" in f and \"test\" in f:\n",
        "            print(f)\n",
        "            dt = np.load(n_path, allow_pickle=True)\n",
        "            nc_test = np.concatenate((nc_test, dt), axis=1)\n",
        "            print(dt.shape[1])\n",
        "            print(nc_test.shape)\n",
        "          if \"PC_\" in f and \"train\" in f:\n",
        "            print(f)\n",
        "            dt = np.load(n_path, allow_pickle=True)\n",
        "            pc_train = np.concatenate((pc_train, dt), axis=1)\n",
        "            print(dt.shape[1])\n",
        "            print(pc_train.shape)\n",
        "          if \"NC_\" in f and \"train\" in f:\n",
        "            print(f)\n",
        "            dt = np.load(n_path, allow_pickle=True)\n",
        "            nc_train = np.concatenate((nc_train, dt), axis=1)\n",
        "            print(dt.shape[1])\n",
        "            print(nc_train.shape)\n",
        "          \n",
        "    \n",
        "  if \"NCP\" in f_name:\n",
        "    for f in ncp_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/NCP/npy/\"+f\n",
        "        if \"PC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_test = np.concatenate((pc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_test.shape)\n",
        "        if \"NC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_test = np.concatenate((nc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_test.shape)\n",
        "        if \"PC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_train = np.concatenate((pc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_train.shape)\n",
        "        if \"NC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_train = np.concatenate((nc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_train.shape)\n",
        "  \n",
        "  if \"Kmer1\" in f_name:\n",
        "    for f in kmer_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/Kmer/npy/\"+f\n",
        "        if \"PC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_test = np.concatenate((pc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_test.shape)\n",
        "        if \"NC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_test = np.concatenate((nc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_test.shape)\n",
        "        if \"PC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_train = np.concatenate((pc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_train.shape)\n",
        "        if \"NC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_train = np.concatenate((nc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_train.shape)\n",
        "  \n",
        "  if \"Kmer2\" in f_name:\n",
        "    for f in kmer_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/Kmer/npy/\"+f\n",
        "        if \"PC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_test = np.concatenate((pc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_test.shape)\n",
        "        if \"NC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_test = np.concatenate((nc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_test.shape)\n",
        "        if \"PC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_train = np.concatenate((pc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_train.shape)\n",
        "        if \"NC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_train = np.concatenate((nc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_train.shape)\n",
        "  \n",
        "  if \"Kmer3\" in f_name:\n",
        "    for f in kmer_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/Kmer/npy/\"+f\n",
        "        if \"PC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_test = np.concatenate((pc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_test.shape)\n",
        "        if \"NC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_test = np.concatenate((nc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_test.shape)\n",
        "        if \"PC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_train = np.concatenate((pc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_train.shape)\n",
        "        if \"NC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_train = np.concatenate((nc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_train.shape)\n",
        "  \n",
        "  if \"Kmer4\" in f_name:\n",
        "    for f in kmer_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/Kmer/npy/\"+f\n",
        "        if \"PC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_test = np.concatenate((pc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_test.shape)\n",
        "        if \"NC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_test = np.concatenate((nc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_test.shape)\n",
        "        if \"PC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_train = np.concatenate((pc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_train.shape)\n",
        "        if \"NC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_train = np.concatenate((nc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_train.shape)\n",
        "  \n",
        "  if \"Kmer5\" in f_name:\n",
        "    for f in kmer_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/Kmer/npy/\"+f\n",
        "        if \"PC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_test = np.concatenate((pc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_test.shape)\n",
        "        if \"NC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_test = np.concatenate((nc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_test.shape)\n",
        "        if \"PC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_train = np.concatenate((pc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_train.shape)\n",
        "        if \"NC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_train = np.concatenate((nc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_train.shape)\n",
        "  \n",
        "  if \"TAC\" in f_name:\n",
        "    for f in tac_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/TAC/npy/\"+f\n",
        "        if \"PC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_test = np.concatenate((pc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_test.shape)\n",
        "        if \"NC_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_test = np.concatenate((nc_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_test.shape)\n",
        "        if \"PC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pc_train = np.concatenate((pc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pc_train.shape)\n",
        "        if \"NC_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nc_train = np.concatenate((nc_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nc_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NC_train_special_binary.npy\n",
            "PC_train_special_binary.npy\n",
            "NC_test_special_binary.npy\n",
            "PC_test_special_binary.npy\n",
            "NC_train_special_CKSNAP1.npy\n",
            "32\n",
            "(1449, 196)\n",
            "PC_train_special_CKSNAP1.npy\n",
            "32\n",
            "(1449, 196)\n",
            "NC_test_special_CKSNAP1.npy\n",
            "32\n",
            "(103, 196)\n",
            "PC_test_special_CKSNAP1.npy\n",
            "32\n",
            "(103, 196)\n",
            "NC_train_special_CKSNAP3.npy\n",
            "64\n",
            "(1449, 260)\n",
            "PC_train_special_CKSNAP3.npy\n",
            "64\n",
            "(1449, 260)\n",
            "NC_test_special_CKSNAP3.npy\n",
            "64\n",
            "(103, 260)\n",
            "PC_test_special_CKSNAP3.npy\n",
            "64\n",
            "(103, 260)\n",
            "NC_train_special_CKSNAP5.npy\n",
            "96\n",
            "(1449, 356)\n",
            "PC_train_special_CKSNAP5.npy\n",
            "96\n",
            "(1449, 356)\n",
            "NC_test_special_CKSNAP5.npy\n",
            "96\n",
            "(103, 356)\n",
            "PC_test_special_CKSNAP5.npy\n",
            "96\n",
            "(103, 356)\n",
            "NC_train_special_CKSNAP7.npy\n",
            "128\n",
            "(1449, 484)\n",
            "PC_train_special_CKSNAP7.npy\n",
            "128\n",
            "(1449, 484)\n",
            "NC_test_special_CKSNAP7.npy\n",
            "128\n",
            "(103, 484)\n",
            "PC_test_special_CKSNAP7.npy\n",
            "128\n",
            "(103, 484)\n",
            "NC_train_special_CKSNAP9.npy\n",
            "160\n",
            "(1449, 644)\n",
            "PC_train_special_CKSNAP9.npy\n",
            "160\n",
            "(1449, 644)\n",
            "NC_test_special_CKSNAP9.npy\n",
            "160\n",
            "(103, 644)\n",
            "PC_test_special_CKSNAP9.npy\n",
            "160\n",
            "(103, 644)\n",
            "NC_train_special_ENAC5.npy\n",
            "148\n",
            "(1449, 792)\n",
            "PC_train_special_ENAC5.npy\n",
            "148\n",
            "(1449, 792)\n",
            "NC_test_special_ENAC5.npy\n",
            "148\n",
            "(103, 792)\n",
            "PC_test_special_ENAC5.npy\n",
            "148\n",
            "(103, 792)\n",
            "NC_train_special_ENAC10.npy\n",
            "128\n",
            "(1449, 920)\n",
            "PC_train_special_ENAC10.npy\n",
            "128\n",
            "(1449, 920)\n",
            "NC_test_special_ENAC10.npy\n",
            "128\n",
            "(103, 920)\n",
            "PC_test_special_ENAC10.npy\n",
            "128\n",
            "(103, 920)\n",
            "NC_train_special_DAC.npy\n",
            "42\n",
            "(1449, 962)\n",
            "PC_train_special_DAC.npy\n",
            "42\n",
            "(1449, 962)\n",
            "NC_test_special_DAC.npy\n",
            "42\n",
            "(103, 962)\n",
            "PC_test_special_DAC.npy\n",
            "42\n",
            "(103, 962)\n",
            "NC_train_special_EIIP.npy\n",
            "41\n",
            "(1449, 1003)\n",
            "PC_train_special_EIIP.npy\n",
            "41\n",
            "(1449, 1003)\n",
            "NC_test_special_EIIP.npy\n",
            "41\n",
            "(103, 1003)\n",
            "PC_test_special_EIIP.npy\n",
            "41\n",
            "(103, 1003)\n",
            "NC_train_special_PseEIIP.npy\n",
            "64\n",
            "(1449, 1067)\n",
            "PC_train_special_PseEIIP.npy\n",
            "64\n",
            "(1449, 1067)\n",
            "NC_test_special_PseEIIP.npy\n",
            "64\n",
            "(103, 1067)\n",
            "PC_test_special_PseEIIP.npy\n",
            "64\n",
            "(103, 1067)\n",
            "NC_train_special_NCP.npy\n",
            "123\n",
            "(1449, 1190)\n",
            "PC_train_special_NCP.npy\n",
            "123\n",
            "(1449, 1190)\n",
            "NC_test_special_NCP.npy\n",
            "123\n",
            "(103, 1190)\n",
            "PC_test_special_NCP.npy\n",
            "123\n",
            "(103, 1190)\n",
            "NC_train_special_Kmer1.npy\n",
            "4\n",
            "(1449, 1194)\n",
            "PC_train_special_Kmer1.npy\n",
            "4\n",
            "(1449, 1194)\n",
            "NC_test_special_Kmer1.npy\n",
            "4\n",
            "(103, 1194)\n",
            "PC_test_special_Kmer1.npy\n",
            "4\n",
            "(103, 1194)\n",
            "NC_train_special_Kmer2.npy\n",
            "16\n",
            "(1449, 1210)\n",
            "PC_train_special_Kmer2.npy\n",
            "16\n",
            "(1449, 1210)\n",
            "NC_test_special_Kmer2.npy\n",
            "16\n",
            "(103, 1210)\n",
            "PC_test_special_Kmer2.npy\n",
            "16\n",
            "(103, 1210)\n",
            "NC_train_special_Kmer3.npy\n",
            "64\n",
            "(1449, 1274)\n",
            "PC_train_special_Kmer3.npy\n",
            "64\n",
            "(1449, 1274)\n",
            "NC_test_special_Kmer3.npy\n",
            "64\n",
            "(103, 1274)\n",
            "PC_test_special_Kmer3.npy\n",
            "64\n",
            "(103, 1274)\n",
            "NC_train_special_Kmer4.npy\n",
            "256\n",
            "(1449, 1530)\n",
            "PC_train_special_Kmer4.npy\n",
            "256\n",
            "(1449, 1530)\n",
            "NC_test_special_Kmer4.npy\n",
            "256\n",
            "(103, 1530)\n",
            "PC_test_special_Kmer4.npy\n",
            "256\n",
            "(103, 1530)\n",
            "NC_train_special_Kmer5.npy\n",
            "1024\n",
            "(1449, 2554)\n",
            "PC_train_special_Kmer5.npy\n",
            "1024\n",
            "(1449, 2554)\n",
            "NC_test_special_Kmer5.npy\n",
            "1024\n",
            "(103, 2554)\n",
            "PC_test_special_Kmer5.npy\n",
            "1024\n",
            "(103, 2554)\n",
            "NC_train_special_TAC.npy\n",
            "14\n",
            "(1449, 2568)\n",
            "PC_train_special_TAC.npy\n",
            "14\n",
            "(1449, 2568)\n",
            "NC_test_special_TAC.npy\n",
            "14\n",
            "(103, 2568)\n",
            "PC_test_special_TAC.npy\n",
            "14\n",
            "(103, 2568)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc2nFkRdchbL",
        "outputId": "2ffd65fe-f716-479b-9fc7-7f2647edd73a"
      },
      "source": [
        "# saving things\n",
        "print(pc_test.shape)\n",
        "print(pc_train.shape)\n",
        "print(nc_test.shape)\n",
        "print(nc_train.shape)\n",
        "np.save(path+\"/n_p_test_train/\"+\"PC_test\",pc_test)\n",
        "np.save(path+\"/n_p_test_train/\"+\"PC_train\",pc_train)\n",
        "np.save(path+\"/n_p_test_train/\"+\"NC_test\",nc_test)\n",
        "np.save(path+\"/n_p_test_train/\"+\"NC_train\",nc_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(103, 2568)\n",
            "(1449, 2568)\n",
            "(103, 2568)\n",
            "(1449, 2568)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXxCxLuvckW5",
        "outputId": "af235f81-bdfe-4288-cf0b-58f185890d38"
      },
      "source": [
        "n_p_test_train = os.listdir(path+\"/n_p_test_train\")\n",
        "yc_train_list = []\n",
        "yc_test_list = []\n",
        "for f in n_p_test_train:\n",
        "  if \"NC\" in f and \"train\" in f:\n",
        "    nc_train_x = np.load(path+\"/n_p_test_train/\"+f, allow_pickle=True)\n",
        "    print(nc_train_x.shape)\n",
        "    for i in range(nc_train_x.shape[0]):\n",
        "      yc_train_list.append([0])\n",
        "  if \"PC\" in f and \"train\" in f:\n",
        "    pc_train_x = np.load(path+\"/n_p_test_train/\"+f, allow_pickle=True)\n",
        "    print(pc_train_x.shape)\n",
        "    for i in range(pc_train_x.shape[0]):\n",
        "      yc_train_list.append([1])\n",
        "  if \"PC\" in f and \"test\" in f:\n",
        "    pc_test_x = np.load(path+\"/n_p_test_train/\"+f, allow_pickle=True)\n",
        "    print(pc_test_x.shape)\n",
        "    for i in range(pc_test_x.shape[0]):\n",
        "      yc_test_list.append([1])\n",
        "  if \"NC\" in f and \"test\" in f:\n",
        "    nc_test_x = np.load(path+\"/n_p_test_train/\"+f, allow_pickle=True)\n",
        "    print(nc_test_x.shape)\n",
        "    for i in range(nc_test_x.shape[0]):\n",
        "      yc_test_list.append([0])\n",
        "\n",
        "# saving yc_train\n",
        "yc_train = np.array(yc_train_list)\n",
        "print(yc_train.shape)\n",
        "np.save(path+\"/classified_datasets/yc_train.npy\", yc_train)\n",
        "\n",
        "# saving yc_test\n",
        "yc_test = np.array(yc_test_list)\n",
        "print(yc_test.shape)\n",
        "np.save(path+\"/classified_datasets/yc_test.npy\", yc_test)\n",
        "\n",
        "# saving xc_train\n",
        "xc_train = np.concatenate((pc_train_x, nc_train_x), axis=0)\n",
        "print(xc_train.shape)\n",
        "np.save(path+\"/classified_datasets/xc_train.npy\", xc_train)\n",
        "\n",
        "# saving xa_test\n",
        "xc_test = np.concatenate((pc_test_x, nc_test_x), axis=0)\n",
        "print(xc_test.shape)\n",
        "np.save(path+\"/classified_datasets/xc_test.npy\", xc_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(103, 2568)\n",
            "(103, 2568)\n",
            "(1449, 2568)\n",
            "(1449, 2568)\n",
            "(2898, 1)\n",
            "(206, 1)\n",
            "(2898, 2568)\n",
            "(206, 2568)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwzpw-aSc51B"
      },
      "source": [
        "For Dataset D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c44n_Lt8coGp",
        "outputId": "884bd854-e822-43e1-fcee-9f0d2251926a"
      },
      "source": [
        "for f_name in feature_name:\n",
        "  if \"binary\" in f_name:\n",
        "    for f in binary_npy_files:\n",
        "      if \"PD_\" in f and \"test\" in f:\n",
        "        print(f)\n",
        "        n_path = path+\"/binary/npy/\"+f\n",
        "        pd_test = np.load(n_path, allow_pickle=True)\n",
        "      if \"ND_\" in f and \"test\" in f:\n",
        "        print(f)\n",
        "        n_path = path+\"/binary/npy/\"+f\n",
        "        nd_test = np.load(n_path, allow_pickle=True)\n",
        "      if \"PD_\" in f and \"train\" in f:\n",
        "        print(f)\n",
        "        n_path = path+\"/binary/npy/\"+f\n",
        "        pd_train = np.load(n_path, allow_pickle=True)\n",
        "      if \"ND_\" in f and \"train\" in f:\n",
        "        print(f)\n",
        "        n_path = path+\"/binary/npy/\"+f\n",
        "        nd_train = np.load(n_path, allow_pickle=True)\n",
        "  if \"CKSNAP1\" in f_name:\n",
        "    for f in cksnap_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/CKSNAP/npy/\"+f\n",
        "        if \"PD_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_test = np.concatenate((pd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_test.shape)\n",
        "        if \"ND_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_test = np.concatenate((nd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_test.shape)\n",
        "        if \"PD_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_train = np.concatenate((pd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_train.shape)\n",
        "        if \"ND_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_train = np.concatenate((nd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_train.shape)\n",
        "\n",
        "  if \"CKSNAP3\" in f_name:\n",
        "    for f in cksnap_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/CKSNAP/npy/\"+f\n",
        "        if \"PD_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_test = np.concatenate((pd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_test.shape)\n",
        "        if \"ND_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_test = np.concatenate((nd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_test.shape)\n",
        "        if \"PD_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_train = np.concatenate((pd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_train.shape)\n",
        "        if \"ND_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_train = np.concatenate((nd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_train.shape)\n",
        "\n",
        "  if \"CKSNAP5\" in f_name:\n",
        "    for f in cksnap_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/CKSNAP/npy/\"+f\n",
        "        if \"PD_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_test = np.concatenate((pd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_test.shape)\n",
        "        if \"ND_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_test = np.concatenate((nd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_test.shape)\n",
        "        if \"PD_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_train = np.concatenate((pd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_train.shape)\n",
        "        if \"ND_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_train = np.concatenate((nd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_train.shape)\n",
        "\n",
        "  if \"CKSNAP7\" in f_name:\n",
        "    for f in cksnap_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/CKSNAP/npy/\"+f\n",
        "        if \"PD_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_test = np.concatenate((pd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_test.shape)\n",
        "        if \"ND_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_test = np.concatenate((nd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_test.shape)\n",
        "        if \"PD_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_train = np.concatenate((pd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_train.shape)\n",
        "        if \"ND_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_train = np.concatenate((nd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_train.shape)\n",
        "\n",
        "  if \"CKSNAP9\" in f_name:\n",
        "    for f in cksnap_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/CKSNAP/npy/\"+f\n",
        "        if \"PD_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_test = np.concatenate((pd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_test.shape)\n",
        "        if \"ND_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_test = np.concatenate((nd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_test.shape)\n",
        "        if \"PD_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_train = np.concatenate((pd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_train.shape)\n",
        "        if \"ND_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_train = np.concatenate((nd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_train.shape)\n",
        "  \n",
        "  if \"ENAC5\" in f_name:\n",
        "    for f in enac_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/ENAC/npy/\"+f\n",
        "        if \"PD_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_test = np.concatenate((pd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_test.shape)\n",
        "        if \"ND_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_test = np.concatenate((nd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_test.shape)\n",
        "        if \"PD_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_train = np.concatenate((pd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_train.shape)\n",
        "        if \"ND_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_train = np.concatenate((nd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_train.shape)\n",
        "  \n",
        "  if \"ENAC10\" in f_name:\n",
        "    for f in enac_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/ENAC/npy/\"+f\n",
        "        if \"PD_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_test = np.concatenate((pd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_test.shape)\n",
        "        if \"ND_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_test = np.concatenate((nd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_test.shape)\n",
        "        if \"PD_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_train = np.concatenate((pd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_train.shape)\n",
        "        if \"ND_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_train = np.concatenate((nd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_train.shape)\n",
        "  \n",
        "  if \"DAC\" in f_name:\n",
        "    for f in dac_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/DAC/npy/\"+f\n",
        "        if \"PD_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_test = np.concatenate((pd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_test.shape)\n",
        "        if \"ND_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_test = np.concatenate((nd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_test.shape)\n",
        "        if \"PD_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_train = np.concatenate((pd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_train.shape)\n",
        "        if \"ND_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_train = np.concatenate((nd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_train.shape)\n",
        " \n",
        "  if \"EIIP\" in f_name:\n",
        "    for f in eiip_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/EIIP/npy/\"+f\n",
        "        if \"PD_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_test = np.concatenate((pd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_test.shape)\n",
        "        if \"ND_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_test = np.concatenate((nd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_test.shape)\n",
        "        if \"PD_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_train = np.concatenate((pd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_train.shape)\n",
        "        if \"ND_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_train = np.concatenate((nd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_train.shape)\n",
        " \n",
        "  if \"PseEIIP\" in f_name:\n",
        "      for f in pseEiip_npy_files:\n",
        "        if f_name in f:\n",
        "          n_path = path+\"/PseEIIP/npy/\"+f\n",
        "          if \"PD_\" in f and \"test\" in f:\n",
        "            print(f)\n",
        "            dt = np.load(n_path, allow_pickle=True)\n",
        "            pd_test = np.concatenate((pd_test, dt), axis=1)\n",
        "            print(dt.shape[1])\n",
        "            print(pd_test.shape)\n",
        "          if \"ND_\" in f and \"test\" in f:\n",
        "            print(f)\n",
        "            dt = np.load(n_path, allow_pickle=True)\n",
        "            nd_test = np.concatenate((nd_test, dt), axis=1)\n",
        "            print(dt.shape[1])\n",
        "            print(nd_test.shape)\n",
        "          if \"PD_\" in f and \"train\" in f:\n",
        "            print(f)\n",
        "            dt = np.load(n_path, allow_pickle=True)\n",
        "            pd_train = np.concatenate((pd_train, dt), axis=1)\n",
        "            print(dt.shape[1])\n",
        "            print(pd_train.shape)\n",
        "          if \"ND_\" in f and \"train\" in f:\n",
        "            print(f)\n",
        "            dt = np.load(n_path, allow_pickle=True)\n",
        "            nd_train = np.concatenate((nd_train, dt), axis=1)\n",
        "            print(dt.shape[1])\n",
        "            print(nd_train.shape)\n",
        "          \n",
        "    \n",
        "  if \"NCP\" in f_name:\n",
        "    for f in ncp_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/NCP/npy/\"+f\n",
        "        if \"PD_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_test = np.concatenate((pd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_test.shape)\n",
        "        if \"ND_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_test = np.concatenate((nd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_test.shape)\n",
        "        if \"PD_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_train = np.concatenate((pd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_train.shape)\n",
        "        if \"ND_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_train = np.concatenate((nd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_train.shape)\n",
        "  \n",
        "  if \"Kmer1\" in f_name:\n",
        "    for f in kmer_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/Kmer/npy/\"+f\n",
        "        if \"PD_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_test = np.concatenate((pd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_test.shape)\n",
        "        if \"ND_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_test = np.concatenate((nd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_test.shape)\n",
        "        if \"PD_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_train = np.concatenate((pd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_train.shape)\n",
        "        if \"ND_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_train = np.concatenate((nd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_train.shape)\n",
        "  \n",
        "  if \"Kmer2\" in f_name:\n",
        "    for f in kmer_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/Kmer/npy/\"+f\n",
        "        if \"PD_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_test = np.concatenate((pd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_test.shape)\n",
        "        if \"ND_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_test = np.concatenate((nd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_test.shape)\n",
        "        if \"PD_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_train = np.concatenate((pd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_train.shape)\n",
        "        if \"ND_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_train = np.concatenate((nd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_train.shape)\n",
        "  \n",
        "  if \"Kmer3\" in f_name:\n",
        "    for f in kmer_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/Kmer/npy/\"+f\n",
        "        if \"PD_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_test = np.concatenate((pd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_test.shape)\n",
        "        if \"ND_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_test = np.concatenate((nd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_test.shape)\n",
        "        if \"PD_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_train = np.concatenate((pd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_train.shape)\n",
        "        if \"ND_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_train = np.concatenate((nd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_train.shape)\n",
        "  \n",
        "  if \"Kmer4\" in f_name:\n",
        "    for f in kmer_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/Kmer/npy/\"+f\n",
        "        if \"PD_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_test = np.concatenate((pd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_test.shape)\n",
        "        if \"ND_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_test = np.concatenate((nd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_test.shape)\n",
        "        if \"PD_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_train = np.concatenate((pd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_train.shape)\n",
        "        if \"ND_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_train = np.concatenate((nd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_train.shape)\n",
        "  \n",
        "  if \"Kmer5\" in f_name:\n",
        "    for f in kmer_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/Kmer/npy/\"+f\n",
        "        if \"PD_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_test = np.concatenate((pd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_test.shape)\n",
        "        if \"ND_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_test = np.concatenate((nd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_test.shape)\n",
        "        if \"PD_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_train = np.concatenate((pd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_train.shape)\n",
        "        if \"ND_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_train = np.concatenate((nd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_train.shape)\n",
        "  \n",
        "  if \"TAC\" in f_name:\n",
        "    for f in tac_npy_files:\n",
        "      if f_name in f:\n",
        "        n_path = path+\"/TAC/npy/\"+f\n",
        "        if \"PD_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_test = np.concatenate((pd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_test.shape)\n",
        "        if \"ND_\" in f and \"test\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_test = np.concatenate((nd_test, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_test.shape)\n",
        "        if \"PD_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          pd_train = np.concatenate((pd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(pd_train.shape)\n",
        "        if \"ND_\" in f and \"train\" in f:\n",
        "          print(f)\n",
        "          dt = np.load(n_path, allow_pickle=True)\n",
        "          nd_train = np.concatenate((nd_train, dt), axis=1)\n",
        "          print(dt.shape[1])\n",
        "          print(nd_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ND_test_special_binary.npy\n",
            "PD_test_special_binary.npy\n",
            "ND_train_special_binary.npy\n",
            "PD_train_special_binary.npy\n",
            "ND_test_special_CKSNAP1.npy\n",
            "32\n",
            "(117, 196)\n",
            "PD_test_special_CKSNAP1.npy\n",
            "32\n",
            "(117, 196)\n",
            "ND_train_special_CKSNAP1.npy\n",
            "32\n",
            "(1650, 196)\n",
            "PD_train_special_CKSNAP1.npy\n",
            "32\n",
            "(1650, 196)\n",
            "ND_test_special_CKSNAP3.npy\n",
            "64\n",
            "(117, 260)\n",
            "PD_test_special_CKSNAP3.npy\n",
            "64\n",
            "(117, 260)\n",
            "ND_train_special_CKSNAP3.npy\n",
            "64\n",
            "(1650, 260)\n",
            "PD_train_special_CKSNAP3.npy\n",
            "64\n",
            "(1650, 260)\n",
            "ND_test_special_CKSNAP5.npy\n",
            "96\n",
            "(117, 356)\n",
            "PD_test_special_CKSNAP5.npy\n",
            "96\n",
            "(117, 356)\n",
            "ND_train_special_CKSNAP5.npy\n",
            "96\n",
            "(1650, 356)\n",
            "PD_train_special_CKSNAP5.npy\n",
            "96\n",
            "(1650, 356)\n",
            "ND_test_special_CKSNAP7.npy\n",
            "128\n",
            "(117, 484)\n",
            "PD_test_special_CKSNAP7.npy\n",
            "128\n",
            "(117, 484)\n",
            "ND_train_special_CKSNAP7.npy\n",
            "128\n",
            "(1650, 484)\n",
            "PD_train_special_CKSNAP7.npy\n",
            "128\n",
            "(1650, 484)\n",
            "ND_test_special_CKSNAP9.npy\n",
            "160\n",
            "(117, 644)\n",
            "PD_test_special_CKSNAP9.npy\n",
            "160\n",
            "(117, 644)\n",
            "ND_train_special_CKSNAP9.npy\n",
            "160\n",
            "(1650, 644)\n",
            "PD_train_special_CKSNAP9.npy\n",
            "160\n",
            "(1650, 644)\n",
            "ND_test_special_ENAC5.npy\n",
            "148\n",
            "(117, 792)\n",
            "PD_test_special_ENAC5.npy\n",
            "148\n",
            "(117, 792)\n",
            "ND_train_special_ENAC5.npy\n",
            "148\n",
            "(1650, 792)\n",
            "PD_train_special_ENAC5.npy\n",
            "148\n",
            "(1650, 792)\n",
            "ND_test_special_ENAC10.npy\n",
            "128\n",
            "(117, 920)\n",
            "PD_test_special_ENAC10.npy\n",
            "128\n",
            "(117, 920)\n",
            "ND_train_special_ENAC10.npy\n",
            "128\n",
            "(1650, 920)\n",
            "PD_train_special_ENAC10.npy\n",
            "128\n",
            "(1650, 920)\n",
            "ND_test_special_DAC.npy\n",
            "42\n",
            "(117, 962)\n",
            "PD_test_special_DAC.npy\n",
            "42\n",
            "(117, 962)\n",
            "ND_train_special_DAC.npy\n",
            "42\n",
            "(1650, 962)\n",
            "PD_train_special_DAC.npy\n",
            "42\n",
            "(1650, 962)\n",
            "ND_test_special_EIIP.npy\n",
            "41\n",
            "(117, 1003)\n",
            "PD_test_special_EIIP.npy\n",
            "41\n",
            "(117, 1003)\n",
            "ND_train_special_EIIP.npy\n",
            "41\n",
            "(1650, 1003)\n",
            "PD_train_special_EIIP.npy\n",
            "41\n",
            "(1650, 1003)\n",
            "ND_test_special_PseEIIP.npy\n",
            "64\n",
            "(117, 1067)\n",
            "PD_test_special_PseEIIP.npy\n",
            "64\n",
            "(117, 1067)\n",
            "ND_train_special_PseEIIP.npy\n",
            "64\n",
            "(1650, 1067)\n",
            "PD_train_special_PseEIIP.npy\n",
            "64\n",
            "(1650, 1067)\n",
            "ND_test_special_NCP.npy\n",
            "123\n",
            "(117, 1190)\n",
            "PD_test_special_NCP.npy\n",
            "123\n",
            "(117, 1190)\n",
            "ND_train_special_NCP.npy\n",
            "123\n",
            "(1650, 1190)\n",
            "PD_train_special_NCP.npy\n",
            "123\n",
            "(1650, 1190)\n",
            "ND_test_special_Kmer1.npy\n",
            "4\n",
            "(117, 1194)\n",
            "PD_test_special_Kmer1.npy\n",
            "4\n",
            "(117, 1194)\n",
            "ND_train_special_Kmer1.npy\n",
            "4\n",
            "(1650, 1194)\n",
            "PD_train_special_Kmer1.npy\n",
            "4\n",
            "(1650, 1194)\n",
            "ND_test_special_Kmer2.npy\n",
            "16\n",
            "(117, 1210)\n",
            "PD_test_special_Kmer2.npy\n",
            "16\n",
            "(117, 1210)\n",
            "ND_train_special_Kmer2.npy\n",
            "16\n",
            "(1650, 1210)\n",
            "PD_train_special_Kmer2.npy\n",
            "16\n",
            "(1650, 1210)\n",
            "ND_test_special_Kmer3.npy\n",
            "64\n",
            "(117, 1274)\n",
            "PD_test_special_Kmer3.npy\n",
            "64\n",
            "(117, 1274)\n",
            "ND_train_special_Kmer3.npy\n",
            "64\n",
            "(1650, 1274)\n",
            "PD_train_special_Kmer3.npy\n",
            "64\n",
            "(1650, 1274)\n",
            "ND_test_special_Kmer4.npy\n",
            "256\n",
            "(117, 1530)\n",
            "PD_test_special_Kmer4.npy\n",
            "256\n",
            "(117, 1530)\n",
            "ND_train_special_Kmer4.npy\n",
            "256\n",
            "(1650, 1530)\n",
            "PD_train_special_Kmer4.npy\n",
            "256\n",
            "(1650, 1530)\n",
            "ND_test_special_Kmer5.npy\n",
            "1024\n",
            "(117, 2554)\n",
            "PD_test_special_Kmer5.npy\n",
            "1024\n",
            "(117, 2554)\n",
            "ND_train_special_Kmer5.npy\n",
            "1024\n",
            "(1650, 2554)\n",
            "PD_train_special_Kmer5.npy\n",
            "1024\n",
            "(1650, 2554)\n",
            "ND_test_special_TAC.npy\n",
            "14\n",
            "(117, 2568)\n",
            "PD_test_special_TAC.npy\n",
            "14\n",
            "(117, 2568)\n",
            "ND_train_special_TAC.npy\n",
            "14\n",
            "(1650, 2568)\n",
            "PD_train_special_TAC.npy\n",
            "14\n",
            "(1650, 2568)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO0IHi6tdB5g",
        "outputId": "a307bed9-50f0-49c6-d55b-4119fcfd8285"
      },
      "source": [
        "# saving things\n",
        "print(pd_test.shape)\n",
        "print(pd_train.shape)\n",
        "print(nd_test.shape)\n",
        "print(nd_train.shape)\n",
        "np.save(path+\"/n_p_test_train/\"+\"PD_test\",pd_test)\n",
        "np.save(path+\"/n_p_test_train/\"+\"PD_train\",pd_train)\n",
        "np.save(path+\"/n_p_test_train/\"+\"ND_test\",nd_test)\n",
        "np.save(path+\"/n_p_test_train/\"+\"ND_train\",nd_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(117, 2568)\n",
            "(1650, 2568)\n",
            "(117, 2568)\n",
            "(1650, 2568)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpH92Zr4dJDH",
        "outputId": "274406ee-936e-48cb-9d3f-354497a79977"
      },
      "source": [
        "n_p_test_train = os.listdir(path+\"/n_p_test_train\")\n",
        "yd_train_list = []\n",
        "yd_test_list = []\n",
        "for f in n_p_test_train:\n",
        "  if \"ND\" in f and \"train\" in f:\n",
        "    nd_train_x = np.load(path+\"/n_p_test_train/\"+f, allow_pickle=True)\n",
        "    print(nd_train_x.shape)\n",
        "    for i in range(nd_train_x.shape[0]):\n",
        "      yd_train_list.append([0])\n",
        "  if \"PD\" in f and \"train\" in f:\n",
        "    pd_train_x = np.load(path+\"/n_p_test_train/\"+f, allow_pickle=True)\n",
        "    print(pd_train_x.shape)\n",
        "    for i in range(pd_train_x.shape[0]):\n",
        "      yd_train_list.append([1])\n",
        "  if \"PD\" in f and \"test\" in f:\n",
        "    pd_test_x = np.load(path+\"/n_p_test_train/\"+f, allow_pickle=True)\n",
        "    print(pd_test_x.shape)\n",
        "    for i in range(pd_test_x.shape[0]):\n",
        "      yd_test_list.append([1])\n",
        "  if \"ND\" in f and \"test\" in f:\n",
        "    nd_test_x = np.load(path+\"/n_p_test_train/\"+f, allow_pickle=True)\n",
        "    print(nd_test_x.shape)\n",
        "    for i in range(nd_test_x.shape[0]):\n",
        "      yd_test_list.append([0])\n",
        "\n",
        "# saving yd_train\n",
        "yd_train = np.array(yd_train_list)\n",
        "print(yd_train.shape)\n",
        "np.save(path+\"/classified_datasets/yd_train.npy\", yd_train)\n",
        "\n",
        "# saving yd_test\n",
        "yd_test = np.array(yd_test_list)\n",
        "print(yd_test.shape)\n",
        "np.save(path+\"/classified_datasets/yd_test.npy\", yd_test)\n",
        "\n",
        "# saving xd_train\n",
        "xd_train = np.concatenate((pd_train_x, nd_train_x), axis=0)\n",
        "print(xd_train.shape)\n",
        "np.save(path+\"/classified_datasets/xd_train.npy\", xd_train)\n",
        "\n",
        "# saving xd_test\n",
        "xd_test = np.concatenate((pd_test_x, nd_test_x), axis=0)\n",
        "print(xd_test.shape)\n",
        "np.save(path+\"/classified_datasets/xd_test.npy\", xd_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(117, 2568)\n",
            "(1650, 2568)\n",
            "(117, 2568)\n",
            "(1650, 2568)\n",
            "(3300, 1)\n",
            "(234, 1)\n",
            "(3300, 2568)\n",
            "(234, 2568)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}