{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment_03_DatasetA.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPq4Nh3824yl8azvj1Uv+qa"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"03t-4pXDhImc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606887302153,"user_tz":-360,"elapsed":2429,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"d10576f6-93e0-4dba-82fa-aecdf93cdbe5"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BUnd6gIQ44i8","executionInfo":{"status":"ok","timestamp":1606887302157,"user_tz":-360,"elapsed":2398,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"7de2ec6a-04ed-4fd1-b542-e3811707037b"},"source":["%cd /content/drive/My\\ Drive/Pattern\\ Lab/Datasets/Datasets\\ SL/classified_datasets\n","path = \"/content/drive/My\\ Drive/Pattern\\ Lab/Datasets/Datasets\\ SL/classified_datasets\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Pattern Lab/Datasets/Datasets SL/classified_datasets\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Atl0dezYkVH3"},"source":["# all library imports here\n","import pandas as pd\n","import numpy as np\n","import os\n","import pickle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_VSxpSQVkYhE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606887302160,"user_tz":-360,"elapsed":2365,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"b164708c-a5a9-44d1-a434-755996255fad"},"source":["a_file = open(\"index_dictionary.pkl\", \"rb\")\n","index_dictionary = pickle.load(a_file)\n","print(index_dictionary)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'binary': [0, 163], 'CKSNAP1': [164, 195], 'CKSNAP3': [196, 259], 'CKSNAP5': [260, 355], 'CKSNAP7': [356, 483], 'CKSNAP9': [484, 643], 'ENAC5': [644, 791], 'ENAC10': [792, 939], 'DAC': [940, 981], '_EIIP': [982, 1022], 'PseEIIP': [1023, 1086], 'NCP': [1087, 1209], 'Kmer1': [1210, 1213], 'Kmer2': [1214, 1229], 'Kmer3': [1230, 1293], 'Kmer4': [1294, 1549], 'Kmer5': [1550, 2573], 'TAC': [2574, 2587]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLGiaJ2w0930","executionInfo":{"status":"ok","timestamp":1606887302161,"user_tz":-360,"elapsed":2340,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"177375d0-a00a-4740-d95d-5766d4fe52a3"},"source":["import random\n","\n","def getList(dict): \n","    return list(dict.keys()) \n","\n","       \n","keyList = getList(index_dictionary)\n","print(type(keyList))\n","\n","random_feature = [] \n","\n","for i in range(4):\n","  random_feature.append(random.sample(keyList, 5))\n","\n","print(random_feature )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'list'>\n","[['_EIIP', 'Kmer4', 'NCP', 'CKSNAP7', 'ENAC5'], ['DAC', 'ENAC10', 'ENAC5', 'Kmer1', 'CKSNAP3'], ['_EIIP', 'CKSNAP9', 'DAC', 'PseEIIP', 'ENAC5'], ['Kmer1', 'Kmer4', 'Kmer2', 'PseEIIP', 'Kmer3']]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l8cP5DzQyAEQ","executionInfo":{"status":"ok","timestamp":1606887302830,"user_tz":-360,"elapsed":2983,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"ba0ab3b2-7617-4eec-b846-573e3d1d188d"},"source":["Xa_train, Xa_test, ya_train, ya_test = np.load(\"xa_train.npy\"), np.load(\"xa_test.npy\"), np.load(\"ya_train.npy\"), np.load(\"ya_test.npy\")\n","Xc_train, Xc_test, yc_train, yc_test = np.load(\"xc_train.npy\"), np.load(\"xc_test.npy\"), np.load(\"yc_train.npy\"), np.load(\"yc_test.npy\")\n","Xd_train, Xd_test, yd_train, yd_test = np.load(\"xd_train.npy\"), np.load(\"xd_test.npy\"), np.load(\"yd_train.npy\"), np.load(\"yd_test.npy\")\n","print(Xa_train.shape, Xa_test.shape, ya_train.shape, ya_test.shape)\n","print(Xc_train.shape, Xc_test.shape, yc_train.shape, yc_test.shape)\n","print(Xd_train.shape, Xd_test.shape, yd_train.shape, yd_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(3690, 2568) (262, 2568) (3690, 1) (262, 1)\n","(2898, 2568) (206, 2568) (2898, 1) (206, 1)\n","(3300, 2568) (234, 2568) (3300, 1) (234, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pbK2uOl3vwqV"},"source":["#pa_test = np.concatenate((pa_test, dt), axis=1)\n","for feature_groups in random_feature:\n","  #feature_groups = random_feature[0] \n","  no_of_features = 0\n","  for i in feature_groups:\n","    no_of_features = no_of_features + index_dictionary[i][1]-index_dictionary[i][0]+1\n","  print(no_of_features)\n","\n","  xa_train_n, xa_test_n, ya_train_n, ya_test_n = np.zeros((Xa_train.shape[0],no_of_features)), np.zeros((Xa_test.shape[0],no_of_features)), ya_train, ya_test\n","  starting_index = 0\n","  for i in feature_groups:\n","    ending_index = starting_index + index_dictionary[i][1]-index_dictionary[i][0]\n","    print(starting_index,ending_index)\n","    print(index_dictionary[i][1]+1, index_dictionary[i][0])\n","    xa_train_n[:,starting_index:ending_index+1] = Xa_train[:,index_dictionary[i][0]:index_dictionary[i][1]+1]\n","    xa_test_n[:,starting_index:ending_index+1] = Xa_test[:,index_dictionary[i][0]:index_dictionary[i][1]+1]\n","    starting_index = ending_index+1\n","  print(starting_index)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u4W6tlWbr0aB","executionInfo":{"status":"ok","timestamp":1606887302832,"user_tz":-360,"elapsed":2960,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"c3054746-7f72-409c-f3ec-4b1269600fbd"},"source":["#pa_test = np.concatenate((pa_test, dt), axis=1)\n","xa_trains = []\n","for i, feature_groups in enumerate(random_feature):\n","  #no_of_features = 0\n","  #for j in feature_groups:\n","   # no_of_features = no_of_features + index_dictionary[j][1]-index_dictionary[j][0]+1\n","  #print(no_of_features)\n","  xa_train_temp = np.concatenate([Xa_train[ : ,  index_dictionary[x][0] : index_dictionary[x][1]+1] for x in feature_groups], axis = 1)\n","  xa_trains.append(xa_train_temp)\n","  xa_test_temp = np.concatenate([Xa_test[ : ,  index_dictionary[x][0] : index_dictionary[x][1]+1] for x in feature_groups], axis = 1)\n","  xa_tests.append(xa_test_temp)\n","  print(xa_trains[i].shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(3690, 696)\n","(3690, 406)\n","(3690, 455)\n","(3690, 404)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h1Se67yDyx-p"},"source":["from sklearn.model_selection import train_test_split\n","from sklearn import svm\n","import numpy as np\n","import pickle\n","import random\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import cross_val_score, cross_val_predict\n","from sklearn.metrics import confusion_matrix, matthews_corrcoef\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","\n","from tabulate import tabulate\n","from IPython.display import clear_output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g9LXghVbYMht"},"source":["def avg(avg_list):\n","  return sum(avg_list)/len(avg_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ttNexTG90g03","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606887544102,"user_tz":-360,"elapsed":244147,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"f94e327a-2eb2-47e6-cc8f-2cd1949afbf3"},"source":["# for SVM\n","cv = StratifiedKFold( n_splits=5, shuffle=True)\n","svc = SVC() # Support vector classifier(SVC)\n","\n","train_accuracy=[]\n","train_specificity = []\n","train_sensitivity = []\n","train_mcc = []\n","test_accuracy=[]\n","test_specificity = []\n","test_sensitivity = []\n","test_mcc = []\n","\n","svc_rows = []\n","headers = [\"Random-Set\", \"Classifier\", \"Train-Accuracy\", \"Test-Accuracy\", \"Train-Specificity\", \"Test-Specificity\", \"Train-Sensitivity\", \"Test-Sensitivity\", \"Train-MCC\", \"Test-MCC\"]\n","\n","for i, x in enumerate(xa_trains):\n","  for train_index, test_index in cv.split(x, ya_train):\n","      x_train, x_test = x[train_index], x[test_index]\n","      y_train, y_test = ya_train[train_index], ya_train[test_index]\n","      svc.fit(x_train, y_train.ravel())\n","      test_pred = svc.predict(x_test)\n","      train_pred = svc.predict(x_train)\n","\n","      ## Accuracy\n","      train_accuracy.append(accuracy_score(y_train, train_pred))\n","      test_accuracy.append(accuracy_score(y_test, test_pred))\n","\n","      ## confusion metrics\n","      tn, fp, fn, tp = confusion_matrix(y_train, train_pred).ravel()\n","      train_specificity.append(tn / (tn + fp)) # Specificity\n","      train_sensitivity.append(tp / (tp + fp)) # Sensitivity\n","      tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n","      test_specificity.append(tn / (tn + fp))\n","      test_sensitivity.append(tp / (tp + fp))\n","\n","      ## MCC\n","      train_mcc.append(matthews_corrcoef(y_train, train_pred))\n","      test_mcc.append(matthews_corrcoef(y_test, test_pred))\n","\n","  print(\"Random set -\", i+1)\n","  print(\"Train-Accuracy = \", avg(train_accuracy))\n","  print(\"Test-Accuracy = \",avg(test_accuracy))\n","  print(\"Train-Specificity = \", avg(train_specificity))\n","  print(\"Test-Specificity = \", avg(test_specificity))\n","  print(\"Train-Sensitivity = \", avg(train_sensitivity))\n","  print(\"Test-Sensitivity = \", avg(test_sensitivity))\n","  print(\"Train-MCC = \", avg(train_mcc))\n","  print(\"Test-MCC = \", avg(test_mcc))\n","  print(\"\\n\\n\")\n","  svc_rows.append([\"Set0\"+str(i+1), \"SVM\", avg(train_accuracy), avg(test_accuracy), avg(train_specificity), avg(test_specificity), avg(train_sensitivity), avg(test_sensitivity),\n","                  avg(train_mcc), avg(test_mcc)])\n","clear_output()\n","print(\"For SVM Classifier:\\n\")\n","table = tabulate(svc_rows, headers, tablefmt='simple')\n","print(table)"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" For SVM Classifier:\n","\n","Random-Set    Classifier      Train-Accuracy    Test-Accuracy    Train-Specificity    Test-Specificity    Train-Sensitivity    Test-Sensitivity    Train-MCC    Test-MCC\n","------------  ------------  ----------------  ---------------  -------------------  ------------------  -------------------  ------------------  -----------  ----------\n","Set01         SVM                   0.869919         0.77019              0.875745            0.77019              0.87429             0.770323     0.739894    0.540518\n","Set02         SVM                   0.859756         0.757859             0.870461            0.762873             0.867569            0.76063      0.719719    0.515978\n","Set03         SVM                   0.855059         0.751581             0.866576            0.757724             0.863382            0.7549       0.710354    0.503512\n","Set04         SVM                   0.809299         0.707724             0.830047            0.722629             0.820203            0.711988     0.619222    0.415873\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fsANFC7_LJkJ","executionInfo":{"status":"ok","timestamp":1606887552913,"user_tz":-360,"elapsed":252931,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"1609a1bf-f830-4f62-f320-7824a372e4ab"},"source":["###  for LogisticRegression\n","\n","logisticRegression = LogisticRegression(max_iter=500)\n","#cv = StratifiedKFold( n_splits=5, shuffle=True)\n","\n","train_accuracy=[]\n","train_specificity = []\n","train_sensitivity = []\n","train_mcc = []\n","test_accuracy=[]\n","test_specificity = []\n","test_sensitivity = []\n","test_mcc = []\n","\n","lg_rows = []\n","\n","for i, x in enumerate(xa_trains):\n","  for train_index, test_index in cv.split(x, ya_train):\n","      x_train, x_test = x[train_index], x[test_index]\n","      y_train, y_test = ya_train[train_index], ya_train[test_index]\n","      logisticRegression.fit(x_train, y_train.ravel())\n","      test_pred = logisticRegression.predict(x_test)\n","      train_pred = logisticRegression.predict(x_train)\n","\n","      ## Accuracy\n","      train_accuracy.append(accuracy_score(y_train, train_pred))\n","      test_accuracy.append(accuracy_score(y_test, test_pred))\n","\n","      ## confusion metrics\n","      tn, fp, fn, tp = confusion_matrix(y_train, train_pred).ravel()\n","      train_specificity.append(tn / (tn + fp)) # Specificity\n","      train_sensitivity.append(tp / (tp + fp)) # Sensitivity\n","      tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n","      test_specificity.append(tn / (tn + fp))\n","      test_sensitivity.append(tp / (tp + fp))\n","\n","      ## MCC\n","      train_mcc.append(matthews_corrcoef(y_train, train_pred))\n","      test_mcc.append(matthews_corrcoef(y_test, test_pred))\n","\n","  print(\"Random set -\", i+1)\n","  print(\"Train-Accuracy = \", avg(train_accuracy))\n","  print(\"Test-Accuracy = \",avg(test_accuracy))\n","  print(\"Train-Specificity = \", avg(train_specificity))\n","  print(\"Test-Specificity = \", avg(test_specificity))\n","  print(\"Train-Sensitivity = \", avg(train_sensitivity))\n","  print(\"Test-Sensitivity = \", avg(test_sensitivity))\n","  print(\"Train-MCC = \", avg(train_mcc))\n","  print(\"Test-MCC = \", avg(test_mcc))\n","  print(\"\\n\\n\")\n","  lg_rows.append([\"Set0\"+str(i+1), \"LogisticRegression\", avg(train_accuracy), avg(test_accuracy), avg(train_specificity), avg(test_specificity), avg(train_sensitivity), avg(test_sensitivity),\n","\n","                  avg(train_mcc), avg(test_mcc)])\n","  \n","clear_output()\n","print(\"For LogisticRegression:\\n\")\n","table = tabulate(lg_rows, headers, tablefmt='simple')\n","print(table)"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" For LogisticRegression\n","\n","Random-Set    Classifier            Train-Accuracy    Test-Accuracy    Train-Specificity    Test-Specificity    Train-Sensitivity    Test-Sensitivity    Train-MCC    Test-MCC\n","------------  ------------------  ----------------  ---------------  -------------------  ------------------  -------------------  ------------------  -----------  ----------\n","Set01         LogisticRegression          0.805894         0.77019              0.802846            0.768564             0.804059            0.769666     0.611804    0.540814\n","Set02         LogisticRegression          0.798713         0.767344             0.799255            0.765583             0.799015            0.766798     0.597444    0.535087\n","Set03         LogisticRegression          0.797945         0.764408             0.798735            0.764408             0.798401            0.764614     0.595904    0.529107\n","Set04         LogisticRegression          0.771443         0.73977              0.774255            0.743631             0.772653            0.741335     0.542916    0.47983\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dlHRxjbdOFz4","executionInfo":{"status":"ok","timestamp":1606887619241,"user_tz":-360,"elapsed":319245,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"a06ae125-7a52-4aed-be4b-c67fdb0aa004"},"source":["###  for XGBClassifier\n","\n","xgbC = XGBClassifier()\n","\n","train_accuracy=[]\n","train_specificity = []\n","train_sensitivity = []\n","train_mcc = []\n","test_accuracy=[]\n","test_specificity = []\n","test_sensitivity = []\n","test_mcc = []\n","xgbc_rows = []\n","for i, x in enumerate(xa_trains):\n","  for train_index, test_index in cv.split(x, ya_train):\n","      x_train, x_test = x[train_index], x[test_index]\n","      y_train, y_test = ya_train[train_index], ya_train[test_index]\n","      xgbC.fit(x_train, y_train.ravel())\n","      test_pred = xgbC.predict(x_test)\n","      train_pred = xgbC.predict(x_train)\n","\n","      ## Accuracy\n","      train_accuracy.append(accuracy_score(y_train, train_pred))\n","      test_accuracy.append(accuracy_score(y_test, test_pred))\n","\n","      ## confusion metrics\n","      tn, fp, fn, tp = confusion_matrix(y_train, train_pred).ravel()\n","      train_specificity.append(tn / (tn + fp)) # Specificity\n","      train_sensitivity.append(tp / (tp + fp)) # Sensitivity\n","      tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n","      test_specificity.append(tn / (tn + fp))\n","      test_sensitivity.append(tp / (tp + fp))\n","\n","      ## MCC\n","      train_mcc.append(matthews_corrcoef(y_train, train_pred))\n","      test_mcc.append(matthews_corrcoef(y_test, test_pred))\n","\n","  print(\"Random set -:\", i+1)\n","  print(\"Train-Accuracy = \", avg(train_accuracy))\n","  print(\"Test-Accuracy = \",avg(test_accuracy))\n","  print(\"Train-Specificity = \", avg(train_specificity))\n","  print(\"Test-Specificity = \", avg(test_specificity))\n","  print(\"Train-Sensitivity = \", avg(train_sensitivity))\n","  print(\"Test-Sensitivity = \", avg(test_sensitivity))\n","  print(\"Train-MCC = \", avg(train_mcc))\n","  print(\"Test-MCC = \", avg(test_mcc))\n","  print(\"\\n\\n\")\n","  xgbc_rows.append([\"Set0\"+str(i+1), \"XGB\", avg(train_accuracy), avg(test_accuracy), avg(train_specificity), avg(test_specificity), avg(train_sensitivity), avg(test_sensitivity),\n","                  avg(train_mcc), avg(test_mcc)])\n","\n","clear_output()\n","print(\"For XGBClassifier:\\n\")\n","table = tabulate(xgbc_rows, headers, tablefmt='simple')\n","print(table)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["For XGBClassifier\n","\n","Random-Set    Classifier      Train-Accuracy    Test-Accuracy    Train-Specificity    Test-Specificity    Train-Sensitivity    Test-Sensitivity    Train-MCC    Test-MCC\n","------------  ------------  ----------------  ---------------  -------------------  ------------------  -------------------  ------------------  -----------  ----------\n","Set01         XGB                   0.864702         0.771816             0.873848            0.773442             0.871513            0.772824     0.729541    0.544111\n","Set02         XGB                   0.85481          0.750271             0.863482            0.752033             0.861124            0.751153     0.709756    0.500871\n","Set03         XGB                   0.857972         0.755736             0.865763            0.753568             0.863664            0.754601     0.716054    0.511754\n","Set04         XGB                   0.839245         0.740515             0.85227             0.744715             0.847838            0.742065     0.678818    0.481385\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2eWcELcSOnZd","executionInfo":{"status":"ok","timestamp":1606887666131,"user_tz":-360,"elapsed":366116,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"a1fd9bd4-c6ea-49be-c486-4e2b93880aac"},"source":["###  for AdaBoostClassifier\n","\n","adaBC = AdaBoostClassifier()\n","\n","train_accuracy=[]\n","train_specificity = []\n","train_sensitivity = []\n","train_mcc = []\n","test_accuracy=[]\n","test_specificity = []\n","test_sensitivity = []\n","test_mcc = []\n","adabc_rows = []\n","\n","for i, x in enumerate(xa_trains):\n","  for train_index, test_index in cv.split(x, ya_train):\n","      x_train, x_test = x[train_index], x[test_index]\n","      y_train, y_test = ya_train[train_index], ya_train[test_index]\n","      adaBC.fit(x_train, y_train.ravel())\n","      test_pred = adaBC.predict(x_test)\n","      train_pred = adaBC.predict(x_train)\n","\n","      ## Accuracy\n","      train_accuracy.append(accuracy_score(y_train, train_pred))\n","      test_accuracy.append(accuracy_score(y_test, test_pred))\n","\n","      ## confusion metrics\n","      tn, fp, fn, tp = confusion_matrix(y_train, train_pred).ravel()\n","      train_specificity.append(tn / (tn + fp)) # Specificity\n","      train_sensitivity.append(tp / (tp + fp)) # Sensitivity\n","      tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n","      test_specificity.append(tn / (tn + fp))\n","      test_sensitivity.append(tp / (tp + fp))\n","\n","      ## MCC\n","      train_mcc.append(matthews_corrcoef(y_train, train_pred))\n","      test_mcc.append(matthews_corrcoef(y_test, test_pred))\n","\n","  print(\"Random set -:\", i+1)\n","  print(\"Train-Accuracy = \", avg(train_accuracy))\n","  print(\"Test-Accuracy = \",avg(test_accuracy))\n","  print(\"Train-Specificity = \", avg(train_specificity))\n","  print(\"Test-Specificity = \", avg(test_specificity))\n","  print(\"Train-Sensitivity = \", avg(train_sensitivity))\n","  print(\"Test-Sensitivity = \", avg(test_sensitivity))\n","  print(\"Train-MCC = \", avg(train_mcc))\n","  print(\"Test-MCC = \", avg(test_mcc))\n","  print(\"\\n\\n\")\n","  adabc_rows.append([\"Set0\"+str(i+1),\"AdaBoost\", avg(train_accuracy), avg(test_accuracy), avg(train_specificity), avg(test_specificity), avg(train_sensitivity), avg(test_sensitivity),\n","                  avg(train_mcc), avg(test_mcc)])\n","\n","clear_output()\n","print(\"For AdaBoostClassifier:\\n\")\n","table = tabulate(adabc_rows, headers, tablefmt='simple')\n","print(table)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["For AdaBoostClassifier\n","\n","Random-Set    Classifier      Train-Accuracy    Test-Accuracy    Train-Specificity    Test-Specificity    Train-Sensitivity    Test-Sensitivity    Train-MCC    Test-MCC\n","------------  ------------  ----------------  ---------------  -------------------  ------------------  -------------------  ------------------  -----------  ----------\n","Set01         AdaBoost              0.791057         0.749322             0.78645             0.752846             0.788451            0.751758     0.582165    0.49901\n","Set02         AdaBoost              0.774627         0.727913             0.773171            0.730352             0.773772            0.729535     0.549289    0.45646\n","Set03         AdaBoost              0.778771         0.731978             0.777236            0.731707             0.777887            0.73215      0.557582    0.464476\n","Set04         AdaBoost              0.763567         0.717344             0.767717            0.724119             0.765321            0.720077     0.527264    0.435231\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TftJNtg5O_jO","executionInfo":{"status":"ok","timestamp":1606887697470,"user_tz":-360,"elapsed":397432,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"cb18b162-0ac4-4aa9-99b4-5c58a2d418f3"},"source":["###  for RandomForestClassifier\n","\n","rfC = RandomForestClassifier()\n","\n","train_accuracy=[]\n","train_specificity = []\n","train_sensitivity = []\n","train_mcc = []\n","test_accuracy=[]\n","test_specificity = []\n","test_sensitivity = []\n","test_mcc = []\n","rfc_rows = []\n","\n","for i, x in enumerate(xa_trains):\n","  for train_index, test_index in cv.split(x, ya_train):\n","      x_train, x_test = x[train_index], x[test_index]\n","      y_train, y_test = ya_train[train_index], ya_train[test_index]\n","      rfC.fit(x_train, y_train.ravel())\n","      test_pred = rfC.predict(x_test)\n","      train_pred = rfC.predict(x_train)\n","\n","      ## Accuracy\n","      train_accuracy.append(accuracy_score(y_train, train_pred))\n","      test_accuracy.append(accuracy_score(y_test, test_pred))\n","\n","      ## confusion metrics\n","      tn, fp, fn, tp = confusion_matrix(y_train, train_pred).ravel()\n","      train_specificity.append(tn / (tn + fp)) # Specificity\n","      train_sensitivity.append(tp / (tp + fp)) # Sensitivity\n","      tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n","      test_specificity.append(tn / (tn + fp))\n","      test_sensitivity.append(tp / (tp + fp))\n","\n","      ## MCC\n","      train_mcc.append(matthews_corrcoef(y_train, train_pred))\n","      test_mcc.append(matthews_corrcoef(y_test, test_pred))\n","\n","  print(\"Random set -:\", i+1)\n","  print(\"Train-Accuracy = \", avg(train_accuracy))\n","  print(\"Test-Accuracy = \",avg(test_accuracy))\n","  print(\"Train-Specificity = \", avg(train_specificity))\n","  print(\"Test-Specificity = \", avg(test_specificity))\n","  print(\"Train-Sensitivity = \", avg(train_sensitivity))\n","  print(\"Test-Sensitivity = \", avg(test_sensitivity))\n","  print(\"Train-MCC = \", avg(train_mcc))\n","  print(\"Test-MCC = \", avg(test_mcc))\n","  print(\"\\n\\n\")\n","  rfc_rows.append([\"Set0\"+str(i+1),\"RandomForest\", avg(train_accuracy), avg(test_accuracy), avg(train_specificity), avg(test_specificity), avg(train_sensitivity), avg(test_sensitivity),\n","                  avg(train_mcc), avg(test_mcc)])\n","\n","clear_output()\n","print(\"For RandomForestClassifier:\\n\")\n","table = tabulate(rfc_rows, headers, tablefmt='simple')\n","print(table)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["For RandomForestClassifier\n","\n","Random-Set    Classifier      Train-Accuracy    Test-Accuracy    Train-Specificity    Test-Specificity    Train-Sensitivity    Test-Sensitivity    Train-MCC    Test-MCC\n","------------  ------------  ----------------  ---------------  -------------------  ------------------  -------------------  ------------------  -----------  ----------\n","Set01         RandomForest                 1         0.734146                    1            0.733333                    1            0.734231            1    0.468597\n","Set02         RandomForest                 1         0.715312                    1            0.718157                    1            0.716771            1    0.430925\n","Set03         RandomForest                 1         0.716441                    1            0.719241                    1            0.717743            1    0.433167\n","Set04         RandomForest                 1         0.710298                    1            0.717073                    1            0.713203            1    0.420908\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FKGNOljHv3yH","executionInfo":{"status":"ok","timestamp":1606887697471,"user_tz":-360,"elapsed":397410,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"f26b3f98-c598-4425-90ed-20e157b81cb4"},"source":["table = tabulate(svc_rows, headers, tablefmt='simple')\n","print(table,\"\\n\")\n","table = tabulate(lg_rows, headers, tablefmt='simple')\n","print(table,\"\\n\")\n","table = tabulate(xgbc_rows, headers, tablefmt='simple')\n","print(table,\"\\n\")\n","table = tabulate(adabc_rows, headers, tablefmt='simple')\n","print(table,\"\\n\")\n","table = tabulate(rfc_rows, headers, tablefmt='simple')\n","print(table,\"\\n\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Random-Set    Classifier      Train-Accuracy    Test-Accuracy    Train-Specificity    Test-Specificity    Train-Sensitivity    Test-Sensitivity    Train-MCC    Test-MCC\n","------------  ------------  ----------------  ---------------  -------------------  ------------------  -------------------  ------------------  -----------  ----------\n","Set01         SVM                   0.869919         0.77019              0.875745            0.77019              0.87429             0.770323     0.739894    0.540518\n","Set02         SVM                   0.859756         0.757859             0.870461            0.762873             0.867569            0.76063      0.719719    0.515978\n","Set03         SVM                   0.855059         0.751581             0.866576            0.757724             0.863382            0.7549       0.710354    0.503512\n","Set04         SVM                   0.809299         0.707724             0.830047            0.722629             0.820203            0.711988     0.619222    0.415873 \n","\n","Random-Set    Classifier            Train-Accuracy    Test-Accuracy    Train-Specificity    Test-Specificity    Train-Sensitivity    Test-Sensitivity    Train-MCC    Test-MCC\n","------------  ------------------  ----------------  ---------------  -------------------  ------------------  -------------------  ------------------  -----------  ----------\n","Set01         LogisticRegression          0.805894         0.77019              0.802846            0.768564             0.804059            0.769666     0.611804    0.540814\n","Set02         LogisticRegression          0.798713         0.767344             0.799255            0.765583             0.799015            0.766798     0.597444    0.535087\n","Set03         LogisticRegression          0.797945         0.764408             0.798735            0.764408             0.798401            0.764614     0.595904    0.529107\n","Set04         LogisticRegression          0.771443         0.73977              0.774255            0.743631             0.772653            0.741335     0.542916    0.47983 \n","\n","Random-Set    Classifier      Train-Accuracy    Test-Accuracy    Train-Specificity    Test-Specificity    Train-Sensitivity    Test-Sensitivity    Train-MCC    Test-MCC\n","------------  ------------  ----------------  ---------------  -------------------  ------------------  -------------------  ------------------  -----------  ----------\n","Set01         XGB                   0.864702         0.771816             0.873848            0.773442             0.871513            0.772824     0.729541    0.544111\n","Set02         XGB                   0.85481          0.750271             0.863482            0.752033             0.861124            0.751153     0.709756    0.500871\n","Set03         XGB                   0.857972         0.755736             0.865763            0.753568             0.863664            0.754601     0.716054    0.511754\n","Set04         XGB                   0.839245         0.740515             0.85227             0.744715             0.847838            0.742065     0.678818    0.481385 \n","\n","Random-Set    Classifier      Train-Accuracy    Test-Accuracy    Train-Specificity    Test-Specificity    Train-Sensitivity    Test-Sensitivity    Train-MCC    Test-MCC\n","------------  ------------  ----------------  ---------------  -------------------  ------------------  -------------------  ------------------  -----------  ----------\n","Set01         AdaBoost              0.791057         0.749322             0.78645             0.752846             0.788451            0.751758     0.582165    0.49901\n","Set02         AdaBoost              0.774627         0.727913             0.773171            0.730352             0.773772            0.729535     0.549289    0.45646\n","Set03         AdaBoost              0.778771         0.731978             0.777236            0.731707             0.777887            0.73215      0.557582    0.464476\n","Set04         AdaBoost              0.763567         0.717344             0.767717            0.724119             0.765321            0.720077     0.527264    0.435231 \n","\n","Random-Set    Classifier      Train-Accuracy    Test-Accuracy    Train-Specificity    Test-Specificity    Train-Sensitivity    Test-Sensitivity    Train-MCC    Test-MCC\n","------------  ------------  ----------------  ---------------  -------------------  ------------------  -------------------  ------------------  -----------  ----------\n","Set01         RandomForest                 1         0.734146                    1            0.733333                    1            0.734231            1    0.468597\n","Set02         RandomForest                 1         0.715312                    1            0.718157                    1            0.716771            1    0.430925\n","Set03         RandomForest                 1         0.716441                    1            0.719241                    1            0.717743            1    0.433167\n","Set04         RandomForest                 1         0.710298                    1            0.717073                    1            0.713203            1    0.420908 \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UhsNeZO_0um3"},"source":[""],"execution_count":null,"outputs":[]}]}