{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assign_03_A.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNYJjJhUNKakNsBxEzwj8QI"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"03t-4pXDhImc","colab":{"base_uri":"https://localhost:8080/","height":527},"executionInfo":{"status":"error","timestamp":1608393881702,"user_tz":-360,"elapsed":36275,"user":{"displayName":"011 163","photoUrl":"","userId":"15001266537352458921"}},"outputId":"3da27258-c59e-4248-9a0a-a21e3a488e63"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \"\"\"\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a145c0899d7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    253\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs-auth-dance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m           \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"BUnd6gIQ44i8"},"source":["%cd /content/drive/My\\ Drive/Pattern\\ Lab/Datasets/Datasets\\ SL/classified_datasets\n","path = \"/content/drive/My\\ Drive/Pattern\\ Lab/Datasets/Datasets\\ SL/classified_datasets\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Atl0dezYkVH3"},"source":["# all library imports here\n","import pandas as pd\n","import numpy as np\n","import os\n","import pickle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_VSxpSQVkYhE"},"source":["a_file = open(\"index_dictionary.pkl\", \"rb\")\n","index_dictionary = pickle.load(a_file)\n","print(index_dictionary)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rLGiaJ2w0930"},"source":["import random\n","\n","def getList(dict): \n","    return list(dict.keys()) \n","\n","       \n","keyList = getList(index_dictionary)\n","print(type(keyList))\n","\n","random_feature = [] \n","\n","for i in range(4):\n","  random_feature.append(random.sample(keyList, 5))\n","\n","print(random_feature )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l8cP5DzQyAEQ"},"source":["# load dataset\n","Xa_train, Xa_test, ya_train, ya_test = np.load(\"xa_train.npy\"), np.load(\"xa_test.npy\"), np.load(\"ya_train.npy\"), np.load(\"ya_test.npy\")\n","Xc_train, Xc_test, yc_train, yc_test = np.load(\"xc_train.npy\"), np.load(\"xc_test.npy\"), np.load(\"yc_train.npy\"), np.load(\"yc_test.npy\")\n","Xd_train, Xd_test, yd_train, yd_test = np.load(\"xd_train.npy\"), np.load(\"xd_test.npy\"), np.load(\"yd_train.npy\"), np.load(\"yd_test.npy\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pbK2uOl3vwqV"},"source":["#pa_test = np.concatenate((pa_test, dt), axis=1)\n","for feature_groups in random_feature:\n","  #feature_groups = random_feature[0] \n","  no_of_features = 0\n","  for i in feature_groups:\n","    no_of_features = no_of_features + index_dictionary[i][1]-index_dictionary[i][0]+1\n","  print(no_of_features)\n","\n","  xa_train_n, xa_test_n, ya_train_n, ya_test_n = np.zeros((Xa_train.shape[0],no_of_features)), np.zeros((Xa_test.shape[0],no_of_features)), ya_train, ya_test\n","  starting_index = 0\n","  for i in feature_groups:\n","    ending_index = starting_index + index_dictionary[i][1]-index_dictionary[i][0]\n","    print(starting_index,ending_index)\n","    print(index_dictionary[i][1]+1, index_dictionary[i][0])\n","    xa_train_n[:,starting_index:ending_index+1] = Xa_train[:,index_dictionary[i][0]:index_dictionary[i][1]+1]\n","    xa_test_n[:,starting_index:ending_index+1] = Xa_test[:,index_dictionary[i][0]:index_dictionary[i][1]+1]\n","    starting_index = ending_index+1\n","  print(starting_index)"]},{"cell_type":"code","metadata":{"id":"u4W6tlWbr0aB"},"source":["#pa_test = np.concatenate((pa_test, dt), axis=1)\n","xa_trains = []\n","for i, feature_groups in enumerate(random_feature):\n","  #no_of_features = 0\n","  #for j in feature_groups:\n","   # no_of_features = no_of_features + index_dictionary[j][1]-index_dictionary[j][0]+1\n","  #print(no_of_features)\n","  xa_train_temp = np.concatenate([Xa_train[ : ,  index_dictionary[x][0] : index_dictionary[x][1]+1] for x in feature_groups], axis = 1)\n","  xa_trains.append(xa_train_temp)\n","  print(xa_trains[i].shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h1Se67yDyx-p"},"source":["from sklearn.model_selection import train_test_split\n","from sklearn import svm\n","import numpy as np\n","import pickle\n","import random\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import cross_val_score, cross_val_predict\n","from sklearn.metrics import confusion_matrix, matthews_corrcoef\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","\n","from tabulate import tabulate\n","from IPython.display import clear_output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g9LXghVbYMht"},"source":["def avg(avg_list):\n","  return sum(avg_list)/len(avg_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ttNexTG90g03"},"source":["# for SVM\n","cv = StratifiedKFold( n_splits=5, shuffle=True)\n","svc = SVC() # Support vector classifier(SVC)\n","\n","train_accuracy=[]\n","train_specificity = []\n","train_sensitivity = []\n","train_mcc = []\n","test_accuracy=[]\n","test_specificity = []\n","test_sensitivity = []\n","test_mcc = []\n","\n","svc_rows = []\n","headers = [\"Random-Set\", \"Classifier\", \"Train-Accuracy\", \"Test-Accuracy\", \"Train-Specificity\", \"Test-Specificity\", \"Train-Sensitivity\", \"Test-Sensitivity\", \"Train-MCC\", \"Test-MCC\"]\n","\n","for i, x in enumerate(xa_trains):\n","  for train_index, test_index in cv.split(x, ya_train):\n","      x_train, x_test = x[train_index], x[test_index]\n","      y_train, y_test = ya_train[train_index], ya_train[test_index]\n","      svc.fit(x_train, y_train.ravel())\n","      test_pred = svc.predict(x_test)\n","      train_pred = svc.predict(x_train)\n","\n","      ## Accuracy\n","      train_accuracy.append(accuracy_score(y_train, train_pred))\n","      test_accuracy.append(accuracy_score(y_test, test_pred))\n","\n","      ## confusion metrics\n","      tn, fp, fn, tp = confusion_matrix(y_train, train_pred).ravel()\n","      train_specificity.append(tn / (tn + fp)) # Specificity\n","      train_sensitivity.append(tp / (tp + fp)) # Sensitivity\n","      tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n","      test_specificity.append(tn / (tn + fp))\n","      test_sensitivity.append(tp / (tp + fp))\n","\n","      ## MCC\n","      train_mcc.append(matthews_corrcoef(y_train, train_pred))\n","      test_mcc.append(matthews_corrcoef(y_test, test_pred))\n","\n","  print(\"Random set -\", i+1)\n","  print(\"Train-Accuracy = \", avg(train_accuracy))\n","  print(\"Test-Accuracy = \",avg(test_accuracy))\n","  print(\"Train-Specificity = \", avg(train_specificity))\n","  print(\"Test-Specificity = \", avg(test_specificity))\n","  print(\"Train-Sensitivity = \", avg(train_sensitivity))\n","  print(\"Test-Sensitivity = \", avg(test_sensitivity))\n","  print(\"Train-MCC = \", avg(train_mcc))\n","  print(\"Test-MCC = \", avg(test_mcc))\n","  print(\"\\n\\n\")\n","  svc_rows.append([\"Set0\"+str(i+1), \"SVM\", avg(train_accuracy), avg(test_accuracy), avg(train_specificity), avg(test_specificity), avg(train_sensitivity), avg(test_sensitivity),\n","                  avg(train_mcc), avg(test_mcc)])\n","clear_output()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fsANFC7_LJkJ"},"source":["###  for LogisticRegression\n","\n","logisticRegression = LogisticRegression(max_iter=500)\n","#cv = StratifiedKFold( n_splits=5, shuffle=True)\n","\n","train_accuracy=[]\n","train_specificity = []\n","train_sensitivity = []\n","train_mcc = []\n","test_accuracy=[]\n","test_specificity = []\n","test_sensitivity = []\n","test_mcc = []\n","\n","lg_rows = []\n","\n","for i, x in enumerate(xa_trains):\n","  for train_index, test_index in cv.split(x, ya_train):\n","      x_train, x_test = x[train_index], x[test_index]\n","      y_train, y_test = ya_train[train_index], ya_train[test_index]\n","      logisticRegression.fit(x_train, y_train.ravel())\n","      test_pred = logisticRegression.predict(x_test)\n","      train_pred = logisticRegression.predict(x_train)\n","\n","      ## Accuracy\n","      train_accuracy.append(accuracy_score(y_train, train_pred))\n","      test_accuracy.append(accuracy_score(y_test, test_pred))\n","\n","      ## confusion metrics\n","      tn, fp, fn, tp = confusion_matrix(y_train, train_pred).ravel()\n","      train_specificity.append(tn / (tn + fp)) # Specificity\n","      train_sensitivity.append(tp / (tp + fp)) # Sensitivity\n","      tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n","      test_specificity.append(tn / (tn + fp))\n","      test_sensitivity.append(tp / (tp + fp))\n","\n","      ## MCC\n","      train_mcc.append(matthews_corrcoef(y_train, train_pred))\n","      test_mcc.append(matthews_corrcoef(y_test, test_pred))\n","\n","  print(\"Random set -\", i+1)\n","  print(\"Train-Accuracy = \", avg(train_accuracy))\n","  print(\"Test-Accuracy = \",avg(test_accuracy))\n","  print(\"Train-Specificity = \", avg(train_specificity))\n","  print(\"Test-Specificity = \", avg(test_specificity))\n","  print(\"Train-Sensitivity = \", avg(train_sensitivity))\n","  print(\"Test-Sensitivity = \", avg(test_sensitivity))\n","  print(\"Train-MCC = \", avg(train_mcc))\n","  print(\"Test-MCC = \", avg(test_mcc))\n","  print(\"\\n\\n\")\n","  lg_rows.append([\"Set0\"+str(i+1), \"LogisticRegression\", avg(train_accuracy), avg(test_accuracy), avg(train_specificity), avg(test_specificity), avg(train_sensitivity), avg(test_sensitivity),\n","\n","                  avg(train_mcc), avg(test_mcc)])\n","  \n","clear_output()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dlHRxjbdOFz4"},"source":["###  for XGBClassifier\n","\n","xgbC = XGBClassifier()\n","\n","train_accuracy=[]\n","train_specificity = []\n","train_sensitivity = []\n","train_mcc = []\n","test_accuracy=[]\n","test_specificity = []\n","test_sensitivity = []\n","test_mcc = []\n","xgbc_rows = []\n","for i, x in enumerate(xa_trains):\n","  for train_index, test_index in cv.split(x, ya_train):\n","      x_train, x_test = x[train_index], x[test_index]\n","      y_train, y_test = ya_train[train_index], ya_train[test_index]\n","      xgbC.fit(x_train, y_train.ravel())\n","      test_pred = xgbC.predict(x_test)\n","      train_pred = xgbC.predict(x_train)\n","\n","      ## Accuracy\n","      train_accuracy.append(accuracy_score(y_train, train_pred))\n","      test_accuracy.append(accuracy_score(y_test, test_pred))\n","\n","      ## confusion metrics\n","      tn, fp, fn, tp = confusion_matrix(y_train, train_pred).ravel()\n","      train_specificity.append(tn / (tn + fp)) # Specificity\n","      train_sensitivity.append(tp / (tp + fp)) # Sensitivity\n","      tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n","      test_specificity.append(tn / (tn + fp))\n","      test_sensitivity.append(tp / (tp + fp))\n","\n","      ## MCC\n","      train_mcc.append(matthews_corrcoef(y_train, train_pred))\n","      test_mcc.append(matthews_corrcoef(y_test, test_pred))\n","\n","  print(\"Random set -:\", i+1)\n","  print(\"Train-Accuracy = \", avg(train_accuracy))\n","  print(\"Test-Accuracy = \",avg(test_accuracy))\n","  print(\"Train-Specificity = \", avg(train_specificity))\n","  print(\"Test-Specificity = \", avg(test_specificity))\n","  print(\"Train-Sensitivity = \", avg(train_sensitivity))\n","  print(\"Test-Sensitivity = \", avg(test_sensitivity))\n","  print(\"Train-MCC = \", avg(train_mcc))\n","  print(\"Test-MCC = \", avg(test_mcc))\n","  print(\"\\n\\n\")\n","  xgbc_rows.append([\"Set0\"+str(i+1), \"XGB\", avg(train_accuracy), avg(test_accuracy), avg(train_specificity), avg(test_specificity), avg(train_sensitivity), avg(test_sensitivity),\n","                  avg(train_mcc), avg(test_mcc)])\n","\n","clear_output()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2eWcELcSOnZd"},"source":["###  for AdaBoostClassifier\n","\n","adaBC = AdaBoostClassifier()\n","\n","train_accuracy=[]\n","train_specificity = []\n","train_sensitivity = []\n","train_mcc = []\n","test_accuracy=[]\n","test_specificity = []\n","test_sensitivity = []\n","test_mcc = []\n","adabc_rows = []\n","\n","for i, x in enumerate(xa_trains):\n","  for train_index, test_index in cv.split(x, ya_train):\n","      x_train, x_test = x[train_index], x[test_index]\n","      y_train, y_test = ya_train[train_index], ya_train[test_index]\n","      adaBC.fit(x_train, y_train.ravel())\n","      test_pred = adaBC.predict(x_test)\n","      train_pred = adaBC.predict(x_train)\n","\n","      ## Accuracy\n","      train_accuracy.append(accuracy_score(y_train, train_pred))\n","      test_accuracy.append(accuracy_score(y_test, test_pred))\n","\n","      ## confusion metrics\n","      tn, fp, fn, tp = confusion_matrix(y_train, train_pred).ravel()\n","      train_specificity.append(tn / (tn + fp)) # Specificity\n","      train_sensitivity.append(tp / (tp + fp)) # Sensitivity\n","      tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n","      test_specificity.append(tn / (tn + fp))\n","      test_sensitivity.append(tp / (tp + fp))\n","\n","      ## MCC\n","      train_mcc.append(matthews_corrcoef(y_train, train_pred))\n","      test_mcc.append(matthews_corrcoef(y_test, test_pred))\n","\n","  print(\"Random set -:\", i+1)\n","  print(\"Train-Accuracy = \", avg(train_accuracy))\n","  print(\"Test-Accuracy = \",avg(test_accuracy))\n","  print(\"Train-Specificity = \", avg(train_specificity))\n","  print(\"Test-Specificity = \", avg(test_specificity))\n","  print(\"Train-Sensitivity = \", avg(train_sensitivity))\n","  print(\"Test-Sensitivity = \", avg(test_sensitivity))\n","  print(\"Train-MCC = \", avg(train_mcc))\n","  print(\"Test-MCC = \", avg(test_mcc))\n","  print(\"\\n\\n\")\n","  adabc_rows.append([\"Set0\"+str(i+1),\"AdaBoost\", avg(train_accuracy), avg(test_accuracy), avg(train_specificity), avg(test_specificity), avg(train_sensitivity), avg(test_sensitivity),\n","                  avg(train_mcc), avg(test_mcc)])\n","\n","clear_output()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TftJNtg5O_jO"},"source":["###  for RandomForestClassifier\n","\n","rfC = RandomForestClassifier()\n","\n","train_accuracy=[]\n","train_specificity = []\n","train_sensitivity = []\n","train_mcc = []\n","test_accuracy=[]\n","test_specificity = []\n","test_sensitivity = []\n","test_mcc = []\n","rfc_rows = []\n","\n","for i, x in enumerate(xa_trains):\n","  for train_index, test_index in cv.split(x, ya_train):\n","      x_train, x_test = x[train_index], x[test_index]\n","      y_train, y_test = ya_train[train_index], ya_train[test_index]\n","      rfC.fit(x_train, y_train.ravel())\n","      test_pred = rfC.predict(x_test)\n","      train_pred = rfC.predict(x_train)\n","\n","      ## Accuracy\n","      train_accuracy.append(accuracy_score(y_train, train_pred))\n","      test_accuracy.append(accuracy_score(y_test, test_pred))\n","\n","      ## confusion metrics\n","      tn, fp, fn, tp = confusion_matrix(y_train, train_pred).ravel()\n","      train_specificity.append(tn / (tn + fp)) # Specificity\n","      train_sensitivity.append(tp / (tp + fp)) # Sensitivity\n","      tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n","      test_specificity.append(tn / (tn + fp))\n","      test_sensitivity.append(tp / (tp + fp))\n","\n","      ## MCC\n","      train_mcc.append(matthews_corrcoef(y_train, train_pred))\n","      test_mcc.append(matthews_corrcoef(y_test, test_pred))\n","\n","  print(\"Random set -:\", i+1)\n","  print(\"Train-Accuracy = \", avg(train_accuracy))\n","  print(\"Test-Accuracy = \",avg(test_accuracy))\n","  print(\"Train-Specificity = \", avg(train_specificity))\n","  print(\"Test-Specificity = \", avg(test_specificity))\n","  print(\"Train-Sensitivity = \", avg(train_sensitivity))\n","  print(\"Test-Sensitivity = \", avg(test_sensitivity))\n","  print(\"Train-MCC = \", avg(train_mcc))\n","  print(\"Test-MCC = \", avg(test_mcc))\n","  print(\"\\n\\n\")\n","  rfc_rows.append([\"Set0\"+str(i+1),\"RandomForest\", avg(train_accuracy), avg(test_accuracy), avg(train_specificity), avg(test_specificity), avg(train_sensitivity), avg(test_sensitivity),\n","                  avg(train_mcc), avg(test_mcc)])\n","\n","clear_output()"],"execution_count":null,"outputs":[]}]}